{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d55e3f",
   "metadata": {},
   "source": [
    "# Pyspark MNIST example\n",
    "\n",
    "Based on: https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b28f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fcf07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c7ad6",
   "metadata": {},
   "source": [
    "### Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b007f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset as numpy arrays\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7cedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten and normalize\n",
    "train_images = train_images.reshape(-1, 784) / 255.0\n",
    "test_images = test_images.reshape(-1, 784) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77bfbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a4403",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746d94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:24:40.556033: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d082a",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244746be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2200 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.1125 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0745 - val_sparse_categorical_accuracy: 0.9771\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.0903 - val_sparse_categorical_accuracy: 0.9729\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.0647 - val_sparse_categorical_accuracy: 0.9813\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0722 - val_sparse_categorical_accuracy: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f6cd0ce80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=5,\n",
    "          validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3bba9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.4001436,  -1.7722523,  -1.8390056,  -0.6676021, -15.033716 ,\n",
       "         -5.494342 , -17.781248 ,  13.716407 ,  -6.966806 ,  -4.227466 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = test_images[:1]\n",
    "model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e700b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(test_img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b42b0",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f11a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf mnist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f9376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:25:18.972517: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a417c6",
   "metadata": {},
   "source": [
    "### Inspect saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a8ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mmnist_model\u001b[00m\r\n",
      "├── \u001b[01;34massets\u001b[00m\r\n",
      "├── keras_metadata.pb\r\n",
      "├── saved_model.pb\r\n",
      "└── \u001b[01;34mvariables\u001b[00m\r\n",
      "    ├── variables.data-00000-of-00001\r\n",
      "    └── variables.index\r\n",
      "\r\n",
      "2 directories, 4 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree mnist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677e377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\r\n",
      "  inputs['dense_input'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1, 784)\r\n",
      "      name: serving_default_dense_input:0\r\n",
      "The given SavedModel SignatureDef contains the following output(s):\r\n",
      "  outputs['dense_1'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1, 10)\r\n",
      "      name: StatefulPartitionedCall:0\r\n",
      "Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir mnist_model --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f013a4b",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c41008f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('mnist_model')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c7b84",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dbeeb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.4001436,  -1.7722523,  -1.8390056,  -0.6676021, -15.033716 ,\n",
       "         -5.494342 , -17.781248 ,  13.716407 ,  -6.966806 ,  -4.227466 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(test_images[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f4700",
   "metadata": {},
   "source": [
    "## PySpark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d0b1b",
   "metadata": {},
   "source": [
    "### Convert numpy array to Spark DataFrame (via Pandas DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49ff5203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array to pandas DataFrame\n",
    "test_pdf = pd.DataFrame(test_images)\n",
    "test_pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "182ee0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.7 s, sys: 0 ns, total: 50.7 s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 784 columns of float\n",
    "df = spark.createDataFrame(test_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "302c73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 230 ms, sys: 0 ns, total: 230 ms\n",
      "Wall time: 226 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "test_pdf['data'] = test_pdf.values.tolist()\n",
    "pdf = test_pdf[['data']]\n",
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5495901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 286 ms, sys: 0 ns, total: 286 ms\n",
      "Wall time: 369 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1c901",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c0ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/18 09:26:15 WARN TaskSetManager: Stage 0 contains a task of very large size (4315 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"mnist_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b444e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d4ca414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/18 09:26:19 WARN TaskSetManager: Stage 1 contains a task of very large size (4315 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"512\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6569d",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc8e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparkext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2556886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"mnist_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87d28256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = sparkext.tensorflow.Model(\"mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8e7805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leey/devpub/spark/python/pyspark/sql/pandas/functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://37fef848-ada5-4105-a520-1310d6ee6456/assets\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83dcb64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.write.mode(\"overwrite\").parquet(\"mnist_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12653e5",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4be4d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=[-11.509465217590332, -9.875249862670898, -6.1747612953186035, -5.414957523345947, 2.1675021648406982, -6.344727993011475, -19.208059310913086, -0.14956292510032654, -1.8437066078186035, 9.35737419128418])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01d6c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = df.take(1)[0].data\n",
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a47ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cce61c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
