{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6810cc-5982-4293-bfbd-c91ef0aca204",
   "metadata": {},
   "source": [
    "# Distributed model inference using TensorFlow Keras\n",
    "From: https://docs.databricks.com/_static/notebooks/deep-learning/keras-metadata.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf329ac8-0763-44bc-b0f6-b634b7dc480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import uuid\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    " \n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b0470-a21e-4778-a80e-b8f6ef792dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"image_data.parquet\"\n",
    "output_file_path = \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d08a7-66b9-444f-b362-d8df692aef1c",
   "metadata": {},
   "source": [
    "### Prepare trained model and data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da083168-137f-492c-8769-d8f1e2111756",
   "metadata": {},
   "source": [
    "Load the ResNet-50 Model and broadcast the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc715a-cdbc-4c49-93e9-58c9d88511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dddfa3-e8df-4e8e-8251-64457f1ebf80",
   "metadata": {},
   "source": [
    "Load the data and save the datasets to one Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0738bec-97d4-4946-8c49-5e6d07ff1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014644f4-2a45-4474-8afb-0daf90043253",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f470a-d308-4426-8ed0-33f95155bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(data_dir) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "files = files[:2048]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd883dc0-4846-4411-a4d6-4f5f252ac707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f94ee0-f1ea-47f6-a77e-be8da5d1b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "for file in files:\n",
    "    img = Image.open(file)\n",
    "    img = img.resize([224, 224])\n",
    "    data = np.asarray(img, dtype=\"float32\").reshape([224*224*3])\n",
    "\n",
    "    image_data.append({\"data\": data})\n",
    "\n",
    "pandas_df = pd.DataFrame(image_data, columns=['data'])\n",
    "pandas_df.to_parquet(file_name)\n",
    "# os.makedirs(dbfs_file_path)\n",
    "# shutil.copyfile(file_name, dbfs_file_path+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827ad56-1af0-41b7-be68-94bd203a2a70",
   "metadata": {},
   "source": [
    "### Load the data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc22d0-b88a-4906-bd47-bf247e34feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "df = spark.read.parquet(file_name)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adf1d9-1fa7-4456-ae32-cf7d1d43bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97173c07-a96e-4262-b60f-82865b997e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df.head()) > 0, \"`df` should not be empty\" # This line will fail if the vectorized reader runs out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78183b4-f003-43f7-9b5d-cbc5c8c0accb",
   "metadata": {},
   "source": [
    "### Run model inference via pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069a524-637f-4d80-b58d-0f8114b1a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image_data):\n",
    "    image = tf.image.convert_image_dtype(\n",
    "        image_data, dtype=tf.float32) * (2. / 255) - 1\n",
    "    image = tf.reshape(image, [224, 224, 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89661b65-f74b-44ad-8fae-ba782ece4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(ArrayType(FloatType()), PandasUDFType.SCALAR_ITER)\n",
    "def predict_batch_udf(image_batch_iter):\n",
    "    batch_size = 64\n",
    "    model = ResNet50(weights=None)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    for image_batch in image_batch_iter:\n",
    "        images = np.vstack(image_batch)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "        dataset = dataset.map(parse_image, num_parallel_calls=8).prefetch(\n",
    "            5000).batch(batch_size)\n",
    "        preds = model.predict(dataset)\n",
    "        yield pd.Series(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969800b6-b226-4a65-b322-1542232645e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(col(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710fedd-8934-4bfa-ab98-e4dfbba093d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.read.parquet(output_file_path)\n",
    "result_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21bbd0-94eb-4245-a14d-faf51735065c",
   "metadata": {},
   "source": [
    "### Model inference using sparkext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d11e0c-018c-4c9a-b908-6518aa0cc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "from sparkext.tensorflow import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575cb34-d175-4a18-a011-f65edefe6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f928cc-f4b9-42ea-82d8-87a11adb5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_udf = model_udf(model, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f262e7f-bb50-403a-8a2c-d44681a71a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path + \"_sparkext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac023dd-901e-4759-b780-18608bd7d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.read.parquet(output_file_path)\n",
    "result_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ed80e-b4d9-4ce0-b136-31479251bbca",
   "metadata": {},
   "source": [
    "### Model inference using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe8271-39f7-4811-890c-833191b0664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature  #, ModelSignature\n",
    "# from mlflow.types.schema import Schema, TensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e8e13-b08c-4b10-8e67-244b9d89d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.vstack(pandas_df['data'].head(10).to_numpy()).reshape(-1,224,224,3)\n",
    "predictions = model.predict(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714612c-18cb-40f9-a674-609c0c1a1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(train_images, model.predict(train_images))\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88401c26-c307-44c3-b651-5dbf9e3ee9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"resnet50_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec7652-24c6-4ce8-ad5a-423eb21c248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.save_model(tf_saved_model_dir=\"resnet50_model\", \n",
    "                             tf_meta_graph_tags=[\"serve\"], \n",
    "                             tf_signature_def_key=\"serving_default\",\n",
    "                             signature=signature,\n",
    "                             path=\"resnet50_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a74c2-e982-43d4-9575-9d9fee990b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_udf = mlflow.pyfunc.spark_udf(spark, model_uri=\"resnet50_mlflow\", result_type=\"array<float>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d42dd-71cc-4dab-9b68-122f45b2a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path + \"_mlflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97561f2c-bd92-49dd-a7de-1fb3d87b327a",
   "metadata": {},
   "source": [
    "### Model inference using Triton UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7ffdd-4452-4b3b-8188-f79d3ed3cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkext.triton import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e4e40-c370-42dd-a57f-5b2762f747f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110aa86-4299-4357-9fa9-13c91fa6b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_udf = model_udf(model, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9eef42-3020-4106-a3a5-b38d084de6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(col(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path + \"_sparkext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71662daf-ddee-439a-b76e-cca3e02f5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.read.parquet(output_file_path)\n",
    "result_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe0a8e-485c-471f-83af-91fd58a223a6",
   "metadata": {},
   "source": [
    "### Model inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6af27b2-ddc0-42ee-94cc-9ba5ffee6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda88b46-6300-4bf7-bc10-7403f4fbbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    model = ResNet50()\n",
    "    def predict(inputs):\n",
    "        return model.predict(inputs)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff0e851-563d-40b6-9d05-509c22b3b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             input_tensor_shapes=[[-1, 224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f733c38b-867d-48c1-b9a6-74a931561896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7c156f-e2b3-4837-9427-ccf3a5720412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bc50ad-eaf5-4fce-a354-5e17d65e2da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[6.505195E-9, 1.7941492E-8, 7.3108597E-10, 1.1247699E-10, 4.79342E-9, 2.2737908E-8, 3.2167613E-10, 1.1435722E-7, 1.27...|\n",
      "|[4.2848686E-10, 1.0501189E-9, 3.1230168E-11, 1.3761372E-11, 9.432232E-11, 1.0338126E-9, 6.3103607E-12, 3.308882E-9, 2...|\n",
      "|[7.1572096E-5, 8.101059E-5, 0.15235129, 8.115527E-4, 8.894753E-4, 1.09934204E-4, 9.9597084E-5, 1.14571274E-4, 3.26097...|\n",
      "|[7.686035E-6, 1.7426746E-4, 1.1772954E-4, 1.8596395E-4, 4.1134286E-4, 3.491203E-4, 1.0433701E-4, 1.8696323E-5, 6.0910...|\n",
      "|[1.9279746E-6, 3.6829217E-5, 4.2873737E-5, 1.1499453E-5, 1.7075143E-4, 7.1724586E-5, 2.947515E-4, 6.888676E-6, 2.1497...|\n",
      "|[9.317662E-6, 1.8610353E-4, 1.9132615E-6, 3.620203E-5, 1.3170729E-4, 1.9679925E-5, 8.671315E-5, 5.3577216E-5, 1.41209...|\n",
      "|[2.2904973E-9, 1.8563807E-7, 3.7782524E-8, 4.328655E-9, 2.4010673E-8, 3.031993E-8, 2.278328E-9, 5.471615E-7, 7.267979...|\n",
      "|[3.544495E-7, 2.3263521E-4, 2.9004717E-5, 1.4927215E-4, 1.8691399E-5, 1.308223E-5, 8.648211E-6, 1.4843575E-5, 1.85133...|\n",
      "|[3.6625543E-9, 1.0032581E-8, 6.429945E-9, 8.6145246E-10, 6.7753447E-9, 9.321761E-9, 1.8069093E-9, 1.2397666E-7, 3.547...|\n",
      "|[1.8757625E-7, 1.1658498E-5, 1.7828437E-6, 4.8823176E-7, 2.2108682E-6, 2.9799523E-6, 1.7844171E-6, 1.0092177E-5, 1.36...|\n",
      "|[3.1841147E-8, 1.4635783E-7, 6.790505E-8, 1.516204E-8, 9.188516E-8, 5.413924E-8, 3.0768328E-7, 3.540285E-7, 6.123218E...|\n",
      "|[4.2521663E-11, 2.2978304E-7, 9.685862E-10, 5.6210586E-10, 2.2864917E-9, 2.5362421E-8, 1.3557684E-10, 1.4310226E-8, 1...|\n",
      "|[2.6082546E-7, 1.3709212E-6, 5.8756457E-9, 5.5940292E-9, 1.5725604E-8, 1.3879378E-7, 2.1134239E-9, 4.4232672E-7, 2.04...|\n",
      "|[2.1746857E-8, 2.1431665E-6, 9.495906E-7, 8.145857E-8, 3.3457945E-7, 1.236013E-7, 2.422968E-7, 3.3534245E-6, 9.642162...|\n",
      "|[2.8634574E-7, 3.5815226E-6, 9.739259E-9, 1.9423852E-7, 2.0946365E-7, 3.9129495E-7, 5.0949062E-8, 4.342498E-7, 3.0297...|\n",
      "|[2.5571075E-7, 1.5090554E-6, 3.114841E-8, 8.7083E-9, 1.4752985E-7, 6.156743E-8, 4.721016E-8, 4.920814E-7, 7.676438E-8...|\n",
      "|[1.1907656E-7, 6.032677E-6, 2.338942E-9, 5.9698074E-8, 2.684504E-7, 5.941803E-7, 1.4735029E-7, 9.52672E-7, 5.591621E-...|\n",
      "|[2.2316216E-8, 8.005018E-8, 5.7965116E-10, 3.9534961E-10, 4.5881063E-9, 8.777951E-8, 3.2541542E-10, 1.2000612E-7, 9.3...|\n",
      "|[4.749759E-5, 3.952463E-5, 1.7216142E-5, 1.6187156E-5, 6.731411E-5, 1.4615358E-5, 9.6852345E-6, 1.0029117E-5, 7.08672...|\n",
      "|[2.757706E-7, 6.930172E-6, 3.0299177E-7, 2.407556E-7, 4.901006E-6, 1.39901495E-5, 1.7053627E-7, 1.7758472E-5, 7.31301...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89b02d-abb4-4dba-95af-b9c4077bcdb8",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108ea9c-bebe-4309-b789-56626af057e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8c0744-0558-4dac-bbfe-8bdde4b2af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={\n",
    "                \"/home/leey/devpub/leewyang/sparkext/examples/models\": {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                \"/home/leey/huggingface/cache\": {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07365c-0a14-49b3-9bd8-cfb35f48b089",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c17b6e-5481-44e3-abde-9b35bfc67ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5e2d206-cadb-4396-972e-7df75fc3adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name].astype(np_types[i.datatype]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        return response.as_numpy(model_meta.outputs[0].name)     # TODO: multiple outputs\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fabcaeb-5a44-42bb-8097-5dbc2d0cee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(triton_fn,\n",
    "                             triton_uri=\"localhost:8001\",\n",
    "                             model_name=\"resnet_50\",\n",
    "                             input_tensor_shapes=[[-1, 224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17f33c8-a0f0-4bce-91f8-5838ba9b12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5b9e99-a1cf-43d3-a795-c7271a917057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e595473d-1a5d-46a6-a6ba-89d2ea903de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[6.489258E-9, 1.7898222E-8, 7.299935E-10, 1.1227252E-10, 4.7806554E-9, 2.2703716E-8, 3.2097378E-10, 1.1415237E-7, 1.2...|\n",
      "|[4.2602602E-10, 1.0438928E-9, 3.1083403E-11, 1.36809565E-11, 9.381158E-11, 1.0262767E-9, 6.274671E-12, 3.2901801E-9, ...|\n",
      "|[7.147178E-5, 8.101019E-5, 0.1522393, 8.115217E-4, 8.892586E-4, 1.0974067E-4, 9.947035E-5, 1.1435235E-4, 3.254102E-5,...|\n",
      "|[7.670886E-6, 1.7386851E-4, 1.17416166E-4, 1.8527111E-4, 4.1024893E-4, 3.4824974E-4, 1.0403031E-4, 1.8668852E-5, 6.08...|\n",
      "|[1.9238792E-6, 3.6723904E-5, 4.27586E-5, 1.1463445E-5, 1.7015457E-4, 7.151512E-5, 2.9384825E-4, 6.869194E-6, 2.144309...|\n",
      "|[9.315408E-6, 1.8620396E-4, 1.9151057E-6, 3.6238518E-5, 1.3180489E-4, 1.9732926E-5, 8.680377E-5, 5.350722E-5, 1.41005...|\n",
      "|[2.285893E-9, 1.8518544E-7, 3.7634152E-8, 4.3115005E-9, 2.39319E-8, 3.025518E-8, 2.269411E-9, 5.457591E-7, 7.2500086E...|\n",
      "|[3.547147E-7, 2.3273179E-4, 2.9076344E-5, 1.4933306E-4, 1.86934E-5, 1.30879E-5, 8.665137E-6, 1.4864403E-5, 1.856118E-...|\n",
      "|[3.662709E-9, 1.0021377E-8, 6.4261094E-9, 8.61696E-10, 6.7733836E-9, 9.31382E-9, 1.8070857E-9, 1.2393333E-7, 3.544432...|\n",
      "|[1.8754403E-7, 1.1651085E-5, 1.7858914E-6, 4.881312E-7, 2.2108682E-6, 2.9811458E-6, 1.7833844E-6, 1.0098214E-5, 1.368...|\n",
      "|[3.1780747E-8, 1.463153E-7, 6.7825766E-8, 1.5160584E-8, 9.184145E-8, 5.416016E-8, 3.07715E-7, 3.530844E-7, 6.111766E-...|\n",
      "|[4.262361E-11, 2.3043174E-7, 9.734508E-10, 5.638362E-10, 2.2928133E-9, 2.5433026E-8, 1.3604662E-10, 1.436866E-8, 1.22...|\n",
      "|[2.6074562E-7, 1.3704689E-6, 5.8693455E-9, 5.5958593E-9, 1.571947E-8, 1.3883958E-7, 2.1105737E-9, 4.4209565E-7, 2.044...|\n",
      "|[2.1706077E-8, 2.141787E-6, 9.5052275E-7, 8.129279E-8, 3.3404822E-7, 1.2351325E-7, 2.4218957E-7, 3.3477043E-6, 9.6267...|\n",
      "|[2.8623282E-7, 3.5801822E-6, 9.726965E-9, 1.9417696E-7, 2.0930719E-7, 3.9114403E-7, 5.092941E-8, 4.3460756E-7, 3.0309...|\n",
      "|[2.5548357E-7, 1.5057877E-6, 3.1178306E-8, 8.700713E-9, 1.4741451E-7, 6.148997E-8, 4.7195304E-8, 4.917413E-7, 7.67435...|\n",
      "|[1.18944776E-7, 6.035168E-6, 2.3399276E-9, 5.96365E-8, 2.6831933E-7, 5.95226E-7, 1.4734887E-7, 9.526946E-7, 5.591226E...|\n",
      "|[2.234072E-8, 8.00994E-8, 5.7994565E-10, 3.955897E-10, 4.5930912E-9, 8.783902E-8, 3.2555963E-10, 1.2010545E-7, 9.3109...|\n",
      "|[4.754976E-5, 3.9541832E-5, 1.7229564E-5, 1.6211245E-5, 6.7283894E-5, 1.4620059E-5, 9.699675E-6, 1.00423185E-5, 7.095...|\n",
      "|[2.7494244E-7, 6.9185253E-6, 3.0235682E-7, 2.4009165E-7, 4.8877096E-6, 1.3948402E-5, 1.7010248E-7, 1.7709262E-5, 7.29...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc06b7e-f750-40b5-9208-a035db11d937",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbfcaa51-3b9f-43ff-a4a8-4b46766115b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d88639b-d934-4eb4-ae2f-cc13b9b10456",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cc28a-34d7-479c-be7e-9a380d39e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
