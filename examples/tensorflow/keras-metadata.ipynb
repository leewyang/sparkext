{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6810cc-5982-4293-bfbd-c91ef0aca204",
   "metadata": {},
   "source": [
    "# Distributed model inference using TensorFlow Keras\n",
    "From: https://docs.databricks.com/_static/notebooks/deep-learning/keras-metadata.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf329ac8-0763-44bc-b0f6-b634b7dc480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 14:02:10.988573: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-04 14:02:11.014948: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import uuid\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    " \n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950b0470-a21e-4778-a80e-b8f6ef792dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"image_data.parquet\"\n",
    "output_file_path = \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d08a7-66b9-444f-b362-d8df692aef1c",
   "metadata": {},
   "source": [
    "### Prepare trained model and data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da083168-137f-492c-8769-d8f1e2111756",
   "metadata": {},
   "source": [
    "Load the ResNet-50 Model and broadcast the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddc715a-cdbc-4c49-93e9-58c9d88511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dddfa3-e8df-4e8e-8251-64457f1ebf80",
   "metadata": {},
   "source": [
    "Load the data and save the datasets to one Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0738bec-97d4-4946-8c49-5e6d07ff1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014644f4-2a45-4474-8afb-0daf90043253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54f470a-d308-4426-8ed0-33f95155bb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(data_dir) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "files = files[:2048]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd883dc0-4846-4411-a4d6-4f5f252ac707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leey/.keras/datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f94ee0-f1ea-47f6-a77e-be8da5d1b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "for file in files:\n",
    "    img = Image.open(file)\n",
    "    img = img.resize([224, 224])\n",
    "    data = np.asarray(img, dtype=\"float32\").reshape([224*224*3])\n",
    "\n",
    "    image_data.append({\"data\": data})\n",
    "\n",
    "pandas_df = pd.DataFrame(image_data, columns=['data'])\n",
    "pandas_df.to_parquet(file_name)\n",
    "# os.makedirs(dbfs_file_path)\n",
    "# shutil.copyfile(file_name, dbfs_file_path+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827ad56-1af0-41b7-be68-94bd203a2a70",
   "metadata": {},
   "source": [
    "### Load the data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddc22d0-b88a-4906-bd47-bf247e34feeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:======================>                                    (3 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "df = spark.read.parquet(file_name)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7adf1d9-1fa7-4456-ae32-cf7d1d43bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97173c07-a96e-4262-b60f-82865b997e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert len(df.head()) > 0, \"`df` should not be empty\" # This line will fail if the vectorized reader runs out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865929b0-b016-4de4-996d-7f16176cf49c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model inference via pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67b3128-13c1-44f1-a0c0-7cf7a836fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image_data):\n",
    "    image = tf.image.convert_image_dtype(\n",
    "        image_data, dtype=tf.float32) * (2. / 255) - 1\n",
    "    image = tf.reshape(image, [224, 224, 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b33185f-6d1e-4ca9-9757-fdc3d736496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leey/devpub/spark/python/pyspark/sql/pandas/functions.py:399: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(ArrayType(FloatType()), PandasUDFType.SCALAR_ITER)\n",
    "def predict_batch_udf(image_batch_iter):\n",
    "    batch_size = 64\n",
    "    model = ResNet50(weights=None)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    for image_batch in image_batch_iter:\n",
    "        images = np.vstack(image_batch)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "        dataset = dataset.map(parse_image, num_parallel_calls=8).prefetch(\n",
    "            5000).batch(batch_size)\n",
    "        preds = model.predict(dataset)\n",
    "        yield pd.Series(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8c05da-db38-45ef-81d0-1f862f575ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.7195931E-4, 3.2735552E-4, 7.533328E-5, 1.9810574E-4, 6.6188135E-5, 4.304618E-4, 1.3097588E-5, 5.2791635E-5, 2.3571...|\n",
      "|[7.738322E-5, 5.935413E-4, 1.3075814E-4, 1.8000253E-4, 1.3001164E-4, 2.2790757E-4, 5.0780895E-5, 2.3768713E-4, 3.8676...|\n",
      "|[2.3994662E-5, 3.4409956E-4, 1.8440963E-4, 1.6311614E-4, 1.4301096E-4, 8.883273E-5, 2.6071444E-5, 2.3609246E-4, 1.481...|\n",
      "|[7.33013E-5, 2.6747186E-4, 1.2007599E-4, 2.0717822E-4, 8.630799E-5, 2.2318888E-4, 1.3459768E-5, 8.564859E-5, 1.482114...|\n",
      "|[5.592278E-5, 2.5165555E-4, 1.3106635E-4, 1.5746983E-4, 8.4952095E-5, 2.1269226E-4, 9.83865E-6, 1.6246884E-4, 1.24666...|\n",
      "|[1.1709497E-4, 3.0075156E-4, 9.33239E-5, 1.6481965E-4, 6.906736E-5, 4.821755E-4, 8.922642E-6, 5.9618797E-5, 1.72143E-...|\n",
      "|[1.1801151E-4, 2.1426812E-4, 5.9151847E-5, 1.1427055E-4, 5.1385836E-5, 4.3937864E-4, 4.607807E-6, 3.3783803E-5, 8.869...|\n",
      "|[1.04612736E-4, 2.7663654E-4, 9.435623E-5, 1.6525248E-4, 7.4158685E-5, 4.257633E-4, 8.704045E-6, 5.3063635E-5, 1.2789...|\n",
      "|[7.352998E-5, 3.3315457E-4, 7.0680355E-5, 1.7582536E-4, 7.606573E-5, 2.8071608E-4, 1.5708138E-5, 7.895344E-5, 1.63833...|\n",
      "|[5.4112577E-5, 3.4097856E-4, 4.273796E-5, 6.867077E-5, 4.2725427E-5, 3.6373304E-4, 4.102062E-6, 1.15471645E-4, 1.3269...|\n",
      "|[1.6299986E-5, 3.011269E-4, 1.0530894E-4, 1.0999596E-4, 6.247357E-5, 8.1669314E-5, 8.867516E-6, 1.9714379E-4, 9.89142...|\n",
      "|[2.4569267E-4, 5.179993E-4, 1.7478937E-4, 2.2669601E-4, 1.2160459E-4, 4.5433E-4, 3.953984E-5, 7.979992E-5, 3.3513832E...|\n",
      "|[9.029223E-5, 3.9454165E-4, 1.665605E-4, 1.9196334E-4, 1.1372031E-4, 2.0514896E-4, 2.7878115E-5, 1.4796885E-4, 3.3018...|\n",
      "|[8.730619E-6, 3.4874916E-4, 5.797578E-5, 4.9443646E-5, 5.4349573E-5, 4.1568164E-5, 1.4966195E-5, 6.196577E-4, 2.33120...|\n",
      "|[2.1702444E-5, 2.3885888E-4, 1.0117506E-4, 7.988898E-5, 7.155834E-5, 1.2449219E-4, 7.99208E-6, 2.611562E-4, 1.5751371...|\n",
      "|[8.29938E-5, 3.1705064E-4, 1.587315E-4, 2.3244774E-4, 9.55335E-5, 1.9356904E-4, 1.7146796E-5, 9.8108874E-5, 1.8489505...|\n",
      "|[6.3181215E-5, 2.6232892E-4, 1.0581372E-4, 2.0251807E-4, 6.83598E-5, 2.0704906E-4, 1.1209849E-5, 8.139733E-5, 1.70928...|\n",
      "|[1.5359989E-4, 3.3213175E-4, 7.3188654E-5, 1.3153376E-4, 6.174973E-5, 3.554963E-4, 1.0753482E-5, 6.729857E-5, 2.27700...|\n",
      "|[7.3694064E-5, 3.3086358E-4, 1.6089129E-4, 1.9742687E-4, 1.0419457E-4, 2.0769038E-4, 1.9587573E-5, 1.2341993E-4, 1.45...|\n",
      "|[6.0036982E-5, 3.690938E-4, 9.357083E-5, 1.2322696E-4, 7.118597E-5, 2.5646162E-4, 1.1585914E-5, 2.2628417E-4, 2.26159...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 38.8 ms, sys: 13.2 ms, total: 52 ms\n",
      "Wall time: 16.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(col(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40799f8e-443e-40ca-919b-391f901cb3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 92.6 ms, sys: 19.7 ms, total: 112 ms\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16726357-65d8-4d3d-aea1-6800101741cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6af27b2-ddc0-42ee-94cc-9ba5ffee6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda88b46-6300-4bf7-bc10-7403f4fbbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    model = ResNet50()\n",
    "    def predict(inputs):\n",
    "        inputs = inputs * (2. / 255) - 1\n",
    "        return model.predict(inputs)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cff0e851-563d-40b6-9d05-509c22b3b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             input_tensor_shapes=[[224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f733c38b-867d-48c1-b9a6-74a931561896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa7c156f-e2b3-4837-9427-ccf3a5720412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80bc50ad-eaf5-4fce-a354-5e17d65e2da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.7195931E-4, 3.2735552E-4, 7.533328E-5, 1.9810574E-4, 6.6188135E-5, 4.304618E-4, 1.3097588E-5, 5.2791635E-5, 2.3571...|\n",
      "|[7.738322E-5, 5.935413E-4, 1.3075814E-4, 1.8000253E-4, 1.3001164E-4, 2.2790757E-4, 5.0780895E-5, 2.3768713E-4, 3.8676...|\n",
      "|[2.3994662E-5, 3.4409956E-4, 1.8440963E-4, 1.6311614E-4, 1.4301096E-4, 8.883273E-5, 2.6071444E-5, 2.3609246E-4, 1.481...|\n",
      "|[7.33013E-5, 2.6747186E-4, 1.2007599E-4, 2.0717822E-4, 8.630799E-5, 2.2318888E-4, 1.3459768E-5, 8.564859E-5, 1.482114...|\n",
      "|[5.592278E-5, 2.5165555E-4, 1.3106635E-4, 1.5746983E-4, 8.4952095E-5, 2.1269226E-4, 9.83865E-6, 1.6246884E-4, 1.24666...|\n",
      "|[1.1709497E-4, 3.0075156E-4, 9.33239E-5, 1.6481965E-4, 6.906736E-5, 4.821755E-4, 8.922642E-6, 5.9618797E-5, 1.72143E-...|\n",
      "|[1.1801151E-4, 2.1426812E-4, 5.9151847E-5, 1.1427055E-4, 5.1385836E-5, 4.3937864E-4, 4.607807E-6, 3.3783803E-5, 8.869...|\n",
      "|[1.04612736E-4, 2.7663654E-4, 9.435623E-5, 1.6525248E-4, 7.4158685E-5, 4.257633E-4, 8.704045E-6, 5.3063635E-5, 1.2789...|\n",
      "|[7.352998E-5, 3.3315457E-4, 7.0680355E-5, 1.7582536E-4, 7.606573E-5, 2.8071608E-4, 1.5708138E-5, 7.895344E-5, 1.63833...|\n",
      "|[5.4112577E-5, 3.4097856E-4, 4.273796E-5, 6.867077E-5, 4.2725427E-5, 3.6373304E-4, 4.102062E-6, 1.15471645E-4, 1.3269...|\n",
      "|[1.6299986E-5, 3.011269E-4, 1.0530894E-4, 1.0999596E-4, 6.247357E-5, 8.1669314E-5, 8.867516E-6, 1.9714379E-4, 9.89142...|\n",
      "|[2.4569267E-4, 5.179993E-4, 1.7478937E-4, 2.2669601E-4, 1.2160459E-4, 4.5433E-4, 3.953984E-5, 7.979992E-5, 3.3513832E...|\n",
      "|[9.029223E-5, 3.9454165E-4, 1.665605E-4, 1.9196334E-4, 1.1372031E-4, 2.0514896E-4, 2.7878115E-5, 1.4796885E-4, 3.3018...|\n",
      "|[8.730619E-6, 3.4874916E-4, 5.797578E-5, 4.9443646E-5, 5.4349573E-5, 4.1568164E-5, 1.4966195E-5, 6.196577E-4, 2.33120...|\n",
      "|[2.1702444E-5, 2.3885888E-4, 1.0117506E-4, 7.988898E-5, 7.155834E-5, 1.2449219E-4, 7.99208E-6, 2.611562E-4, 1.5751371...|\n",
      "|[8.29938E-5, 3.1705064E-4, 1.587315E-4, 2.3244774E-4, 9.55335E-5, 1.9356904E-4, 1.7146796E-5, 9.8108874E-5, 1.8489505...|\n",
      "|[6.3181215E-5, 2.6232892E-4, 1.0581372E-4, 2.0251807E-4, 6.83598E-5, 2.0704906E-4, 1.1209849E-5, 8.139733E-5, 1.70928...|\n",
      "|[1.5359989E-4, 3.3213175E-4, 7.3188654E-5, 1.3153376E-4, 6.174973E-5, 3.554963E-4, 1.0753482E-5, 6.729857E-5, 2.27700...|\n",
      "|[7.3694064E-5, 3.3086358E-4, 1.6089129E-4, 1.9742687E-4, 1.0419457E-4, 2.0769038E-4, 1.9587573E-5, 1.2341993E-4, 1.45...|\n",
      "|[6.0036982E-5, 3.690938E-4, 9.357083E-5, 1.2322696E-4, 7.118597E-5, 2.5646162E-4, 1.1585914E-5, 2.2628417E-4, 2.26159...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 31.2 ms, sys: 9.76 ms, total: 41 ms\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41cace80-7a4b-4929-8e63-9c83f9745e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.7195931E-4, 3.2735552E-4, 7.533328E-5, 1.9810574E-4, 6.6188135E-5, 4.304618E-4, 1.3097588E-5, 5.2791635E-5, 2.3571...|\n",
      "|[7.738322E-5, 5.935413E-4, 1.3075814E-4, 1.8000253E-4, 1.3001164E-4, 2.2790757E-4, 5.0780895E-5, 2.3768713E-4, 3.8676...|\n",
      "|[2.3994662E-5, 3.4409956E-4, 1.8440963E-4, 1.6311614E-4, 1.4301096E-4, 8.883273E-5, 2.6071444E-5, 2.3609246E-4, 1.481...|\n",
      "|[7.33013E-5, 2.6747186E-4, 1.2007599E-4, 2.0717822E-4, 8.630799E-5, 2.2318888E-4, 1.3459768E-5, 8.564859E-5, 1.482114...|\n",
      "|[5.592278E-5, 2.5165555E-4, 1.3106635E-4, 1.5746983E-4, 8.4952095E-5, 2.1269226E-4, 9.83865E-6, 1.6246884E-4, 1.24666...|\n",
      "|[1.1709497E-4, 3.0075156E-4, 9.33239E-5, 1.6481965E-4, 6.906736E-5, 4.821755E-4, 8.922642E-6, 5.9618797E-5, 1.72143E-...|\n",
      "|[1.1801151E-4, 2.1426812E-4, 5.9151847E-5, 1.1427055E-4, 5.1385836E-5, 4.3937864E-4, 4.607807E-6, 3.3783803E-5, 8.869...|\n",
      "|[1.04612736E-4, 2.7663654E-4, 9.435623E-5, 1.6525248E-4, 7.4158685E-5, 4.257633E-4, 8.704045E-6, 5.3063635E-5, 1.2789...|\n",
      "|[7.352998E-5, 3.3315457E-4, 7.0680355E-5, 1.7582536E-4, 7.606573E-5, 2.8071608E-4, 1.5708138E-5, 7.895344E-5, 1.63833...|\n",
      "|[5.4112577E-5, 3.4097856E-4, 4.273796E-5, 6.867077E-5, 4.2725427E-5, 3.6373304E-4, 4.102062E-6, 1.15471645E-4, 1.3269...|\n",
      "|[1.6299986E-5, 3.011269E-4, 1.0530894E-4, 1.0999596E-4, 6.247357E-5, 8.1669314E-5, 8.867516E-6, 1.9714379E-4, 9.89142...|\n",
      "|[2.4569267E-4, 5.179993E-4, 1.7478937E-4, 2.2669601E-4, 1.2160459E-4, 4.5433E-4, 3.953984E-5, 7.979992E-5, 3.3513832E...|\n",
      "|[9.029223E-5, 3.9454165E-4, 1.665605E-4, 1.9196334E-4, 1.1372031E-4, 2.0514896E-4, 2.7878115E-5, 1.4796885E-4, 3.3018...|\n",
      "|[8.730619E-6, 3.4874916E-4, 5.797578E-5, 4.9443646E-5, 5.4349573E-5, 4.1568164E-5, 1.4966195E-5, 6.196577E-4, 2.33120...|\n",
      "|[2.1702444E-5, 2.3885888E-4, 1.0117506E-4, 7.988898E-5, 7.155834E-5, 1.2449219E-4, 7.99208E-6, 2.611562E-4, 1.5751371...|\n",
      "|[8.29938E-5, 3.1705064E-4, 1.587315E-4, 2.3244774E-4, 9.55335E-5, 1.9356904E-4, 1.7146796E-5, 9.8108874E-5, 1.8489505...|\n",
      "|[6.3181215E-5, 2.6232892E-4, 1.0581372E-4, 2.0251807E-4, 6.83598E-5, 2.0704906E-4, 1.1209849E-5, 8.139733E-5, 1.70928...|\n",
      "|[1.5359989E-4, 3.3213175E-4, 7.3188654E-5, 1.3153376E-4, 6.174973E-5, 3.554963E-4, 1.0753482E-5, 6.729857E-5, 2.27700...|\n",
      "|[7.3694064E-5, 3.3086358E-4, 1.6089129E-4, 1.9742687E-4, 1.0419457E-4, 2.0769038E-4, 1.9587573E-5, 1.2341993E-4, 1.45...|\n",
      "|[6.0036982E-5, 3.690938E-4, 9.357083E-5, 1.2322696E-4, 7.118597E-5, 2.5646162E-4, 1.1585914E-5, 2.2628417E-4, 2.26159...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 43.9 ms, sys: 3.76 ms, total: 47.7 ms\n",
      "Wall time: 8.93 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(\"data\").alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56a2ec8a-de09-4d7c-9666-1b3c76f10657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===========================================>              (6 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91 ms, sys: 15.2 ms, total: 106 ms\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(col(\"data\")).alias(\"prediction\"))\n",
    "predictions.write.mode(\"overwrite\").parquet(output_file_path + \"_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89b02d-abb4-4dba-95af-b9c4077bcdb8",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2bb6d-d3c2-4ce8-ade8-938fcb402543",
   "metadata": {},
   "source": [
    "For optimal performance., you should use a Triton inference server image that is compatible with the TensorFlow version used to train the model, per the [Framework Containers Support Matrix](https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html)\n",
    "\n",
    "For demonstration purposes, this notebook just uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments), using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n tf-gpu -c conda-forge python=3.8\n",
    "conda activate tf-gpu\n",
    "pip install tensorflow\n",
    "pip install conda-pack\n",
    "conda pack  \n",
    "\n",
    "cp tf-gpu.tar.gz ../models_tf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108ea9c-bebe-4309-b789-56626af057e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c8c0744-0558-4dac-bbfe-8bdde4b2af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={\n",
    "                \"/home/leey/devpub/leewyang/sparkext/examples/models\": {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                \"/home/leey/huggingface/cache\": {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07365c-0a14-49b3-9bd8-cfb35f48b089",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7c17b6e-5481-44e3-abde-9b35bfc67ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcd46360-6851-4a9d-8590-c086e001242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            inputs = inputs * (2. / 255) - 1  # normalization\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fabcaeb-5a44-42bb-8097-5dbc2d0cee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"resnet_50\"),\n",
    "                             input_tensor_shapes=[[224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b17f33c8-a0f0-4bce-91f8-5838ba9b12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e5b9e99-a1cf-43d3-a795-c7271a917057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e595473d-1a5d-46a6-a6ba-89d2ea903de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.71091E-4, 3.269849E-4, 7.52977E-5, 1.978806E-4, 6.605203E-5, 4.2928016E-4, 1.3055542E-5, 5.279775E-5, 2.3507486E-5...|\n",
      "|[7.660852E-5, 5.9129955E-4, 1.3076628E-4, 1.7964613E-4, 1.293718E-4, 2.2706043E-4, 5.056295E-5, 2.3749094E-4, 3.86420...|\n",
      "|[2.3824861E-5, 3.4220197E-4, 1.8398133E-4, 1.626118E-4, 1.4244742E-4, 8.818307E-5, 2.6096091E-5, 2.3705876E-4, 1.4838...|\n",
      "|[7.2949515E-5, 2.678199E-4, 1.2027239E-4, 2.0707237E-4, 8.63638E-5, 2.2211406E-4, 1.3493031E-5, 8.575731E-5, 1.485200...|\n",
      "|[5.5637167E-5, 2.522944E-4, 1.3117655E-4, 1.5718519E-4, 8.4829146E-5, 2.1113851E-4, 9.884539E-6, 1.6338409E-4, 1.2518...|\n",
      "|[1.1688133E-4, 3.0019053E-4, 9.321699E-5, 1.6447909E-4, 6.8965805E-5, 4.8260659E-4, 8.890777E-6, 5.9450405E-5, 1.7154...|\n",
      "|[1.17835014E-4, 2.1433561E-4, 5.9436883E-5, 1.1485722E-4, 5.157152E-5, 4.3828037E-4, 4.6302976E-6, 3.3906545E-5, 8.89...|\n",
      "|[1.04490515E-4, 2.7698986E-4, 9.411594E-5, 1.6424335E-4, 7.383655E-5, 4.2327016E-4, 8.706783E-6, 5.3202642E-5, 1.2829...|\n",
      "|[7.3509094E-5, 3.3301837E-4, 7.076255E-5, 1.7543026E-4, 7.5785305E-5, 2.797155E-4, 1.572387E-5, 7.908921E-5, 1.644873...|\n",
      "|[5.3753134E-5, 3.411723E-4, 4.271543E-5, 6.838312E-5, 4.2591262E-5, 3.6174894E-4, 4.097563E-6, 1.16135554E-4, 1.33269...|\n",
      "|[1.635044E-5, 3.0143987E-4, 1.05406274E-4, 1.1014204E-4, 6.2575215E-5, 8.174726E-5, 8.88502E-6, 1.9709046E-4, 9.90809...|\n",
      "|[2.447096E-4, 5.190383E-4, 1.7480852E-4, 2.2696143E-4, 1.2188917E-4, 4.5231511E-4, 3.9821916E-5, 8.025502E-5, 3.37593...|\n",
      "|[8.989249E-5, 3.939656E-4, 1.6749959E-4, 1.9200947E-4, 1.14533E-4, 2.0504597E-4, 2.8101236E-5, 1.488695E-4, 3.31279E-...|\n",
      "|[8.716478E-6, 3.4927382E-4, 5.7904286E-5, 4.9110706E-5, 5.438481E-5, 4.1528983E-5, 1.4933897E-5, 6.213248E-4, 2.33565...|\n",
      "|[2.1494814E-5, 2.3821845E-4, 1.0073942E-4, 7.92378E-5, 7.1249306E-5, 1.229611E-4, 7.950026E-6, 2.6144923E-4, 1.569021...|\n",
      "|[8.272572E-5, 3.1766781E-4, 1.5912925E-4, 2.3173426E-4, 9.5646836E-5, 1.9270073E-4, 1.7255206E-5, 9.8767494E-5, 1.857...|\n",
      "|[6.321312E-5, 2.625331E-4, 1.0585352E-4, 2.0170724E-4, 6.8228415E-5, 2.0702723E-4, 1.1237228E-5, 8.165265E-5, 1.71504...|\n",
      "|[1.529679E-4, 3.3189295E-4, 7.3057265E-5, 1.3102239E-4, 6.159667E-5, 3.5550012E-4, 1.072669E-5, 6.72448E-5, 2.2740476...|\n",
      "|[7.356311E-5, 3.3005315E-4, 1.6056173E-4, 1.9738385E-4, 1.0423906E-4, 2.069393E-4, 1.96991E-5, 1.2458375E-4, 1.464646...|\n",
      "|[5.9362512E-5, 3.673828E-4, 9.3447095E-5, 1.2214093E-4, 7.076716E-5, 2.5420298E-4, 1.1483302E-5, 2.2629664E-4, 2.2558...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 25.5 ms, sys: 948 Âµs, total: 26.5 ms\n",
      "Wall time: 9.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f66d468-e0b1-4589-8606-b3848063a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.711523E-4, 3.26866E-4, 7.52245E-5, 1.9781855E-4, 6.600293E-5, 4.2926118E-4, 1.3044922E-5, 5.2771757E-5, 2.3492035E...|\n",
      "|[7.663703E-5, 5.9194054E-4, 1.3089886E-4, 1.7965207E-4, 1.2942665E-4, 2.2708319E-4, 5.0572096E-5, 2.3747748E-4, 3.865...|\n",
      "|[2.3856559E-5, 3.422268E-4, 1.8405495E-4, 1.6263021E-4, 1.424253E-4, 8.8358385E-5, 2.6092113E-5, 2.3685934E-4, 1.4848...|\n",
      "|[7.303531E-5, 2.6780445E-4, 1.201413E-4, 2.070834E-4, 8.6422646E-5, 2.2223375E-4, 1.3498062E-5, 8.576895E-5, 1.485476...|\n",
      "|[5.5635584E-5, 2.5240038E-4, 1.3120404E-4, 1.5722473E-4, 8.4889776E-5, 2.1113818E-4, 9.889351E-6, 1.633997E-4, 1.2522...|\n",
      "|[1.1691067E-4, 3.0008654E-4, 9.324959E-5, 1.6453292E-4, 6.901493E-5, 4.824348E-4, 8.892891E-6, 5.9440066E-5, 1.716102...|\n",
      "|[1.1794032E-4, 2.1437294E-4, 5.946346E-5, 1.14867704E-4, 5.1572264E-5, 4.3846E-4, 4.631601E-6, 3.3929744E-5, 8.906181...|\n",
      "|[1.0447902E-4, 2.7690124E-4, 9.4181574E-5, 1.6444287E-4, 7.390345E-5, 4.2362334E-4, 8.705634E-6, 5.3165844E-5, 1.2830...|\n",
      "|[7.351322E-5, 3.3298018E-4, 7.0817194E-5, 1.7550253E-4, 7.583716E-5, 2.798263E-4, 1.572767E-5, 7.904404E-5, 1.6454924...|\n",
      "|[5.3726526E-5, 3.4142923E-4, 4.2720192E-5, 6.839058E-5, 4.2620613E-5, 3.619454E-4, 4.097141E-6, 1.1616112E-4, 1.33245...|\n",
      "|[1.635904E-5, 3.0147735E-4, 1.053717E-4, 1.0999146E-4, 6.2550156E-5, 8.181967E-5, 8.878469E-6, 1.9710399E-4, 9.915118...|\n",
      "|[2.4510594E-4, 5.193074E-4, 1.7508323E-4, 2.2725816E-4, 1.2203578E-4, 4.5301963E-4, 3.988046E-5, 8.036305E-5, 3.38231...|\n",
      "|[9.002103E-5, 3.9403E-4, 1.6738962E-4, 1.9195724E-4, 1.1450087E-4, 2.0550354E-4, 2.8089527E-5, 1.4876515E-4, 3.315191...|\n",
      "|[8.709206E-6, 3.490904E-4, 5.7886635E-5, 4.9038485E-5, 5.4367276E-5, 4.150977E-5, 1.4912511E-5, 6.218132E-4, 2.337753...|\n",
      "|[2.1484686E-5, 2.3790421E-4, 1.0062774E-4, 7.91598E-5, 7.126339E-5, 1.230162E-4, 7.937979E-6, 2.6127222E-4, 1.5676595...|\n",
      "|[8.279622E-5, 3.1778423E-4, 1.5904069E-4, 2.3183269E-4, 9.569356E-5, 1.927286E-4, 1.7261431E-5, 9.877241E-5, 1.859588...|\n",
      "|[6.32343E-5, 2.6237662E-4, 1.057753E-4, 2.0170519E-4, 6.821298E-5, 2.071044E-4, 1.1226044E-5, 8.1606515E-5, 1.7141409...|\n",
      "|[1.5303968E-4, 3.3193594E-4, 7.3050745E-5, 1.3101005E-4, 6.1587554E-5, 3.55623E-4, 1.0726182E-5, 6.7218694E-5, 2.2732...|\n",
      "|[7.365815E-5, 3.3020784E-4, 1.6056605E-4, 1.9723056E-4, 1.0423198E-4, 2.0708317E-4, 1.9703672E-5, 1.2452844E-4, 1.464...|\n",
      "|[5.9369515E-5, 3.6729706E-4, 9.3409515E-5, 1.2213789E-4, 7.076384E-5, 2.542748E-4, 1.1472075E-5, 2.2621559E-4, 2.2555...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 10.5 ms, sys: 9.2 ms, total: 19.8 ms\n",
      "Wall time: 5.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(\"data\").alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "632c4c3a-fa52-4c3d-b71e-7526286e353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=====================>                                    (3 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 ms, sys: 3.08 ms, total: 27.6 ms\n",
      "Wall time: 25.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(col(\"data\")).alias(\"prediction\"))\n",
    "predictions.write.mode(\"overwrite\").parquet(output_file_path + \"_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc06b7e-f750-40b5-9208-a035db11d937",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbfcaa51-3b9f-43ff-a4a8-4b46766115b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d88639b-d934-4eb4-ae2f-cc13b9b10456",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cc28a-34d7-479c-be7e-9a380d39e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
