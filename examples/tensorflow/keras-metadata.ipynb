{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6810cc-5982-4293-bfbd-c91ef0aca204",
   "metadata": {},
   "source": [
    "# Distributed model inference using TensorFlow Keras\n",
    "From: https://docs.databricks.com/_static/notebooks/deep-learning/keras-metadata.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf329ac8-0763-44bc-b0f6-b634b7dc480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import uuid\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    " \n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b0470-a21e-4778-a80e-b8f6ef792dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"image_data.parquet\"\n",
    "output_file_path = \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d08a7-66b9-444f-b362-d8df692aef1c",
   "metadata": {},
   "source": [
    "### Prepare trained model and data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da083168-137f-492c-8769-d8f1e2111756",
   "metadata": {},
   "source": [
    "Load the ResNet-50 Model and broadcast the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc715a-cdbc-4c49-93e9-58c9d88511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dddfa3-e8df-4e8e-8251-64457f1ebf80",
   "metadata": {},
   "source": [
    "Load the data and save the datasets to one Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0738bec-97d4-4946-8c49-5e6d07ff1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014644f4-2a45-4474-8afb-0daf90043253",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f470a-d308-4426-8ed0-33f95155bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(data_dir) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "files = files[:2048]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd883dc0-4846-4411-a4d6-4f5f252ac707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f94ee0-f1ea-47f6-a77e-be8da5d1b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "for file in files:\n",
    "    img = Image.open(file)\n",
    "    img = img.resize([224, 224])\n",
    "    data = np.asarray(img, dtype=\"float32\").reshape([224*224*3])\n",
    "\n",
    "    image_data.append({\"data\": data})\n",
    "\n",
    "pandas_df = pd.DataFrame(image_data, columns=['data'])\n",
    "pandas_df.to_parquet(file_name)\n",
    "# os.makedirs(dbfs_file_path)\n",
    "# shutil.copyfile(file_name, dbfs_file_path+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827ad56-1af0-41b7-be68-94bd203a2a70",
   "metadata": {},
   "source": [
    "### Load the data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc22d0-b88a-4906-bd47-bf247e34feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "df = spark.read.parquet(file_name)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adf1d9-1fa7-4456-ae32-cf7d1d43bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97173c07-a96e-4262-b60f-82865b997e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df.head()) > 0, \"`df` should not be empty\" # This line will fail if the vectorized reader runs out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78183b4-f003-43f7-9b5d-cbc5c8c0accb",
   "metadata": {},
   "source": [
    "### Run model inference via pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069a524-637f-4d80-b58d-0f8114b1a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image_data):\n",
    "    image = tf.image.convert_image_dtype(\n",
    "        image_data, dtype=tf.float32) * (2. / 255) - 1\n",
    "    image = tf.reshape(image, [224, 224, 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89661b65-f74b-44ad-8fae-ba782ece4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(ArrayType(FloatType()), PandasUDFType.SCALAR_ITER)\n",
    "def predict_batch_udf(image_batch_iter):\n",
    "    batch_size = 64\n",
    "    model = ResNet50(weights=None)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    for image_batch in image_batch_iter:\n",
    "        images = np.vstack(image_batch)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "        dataset = dataset.map(parse_image, num_parallel_calls=8).prefetch(\n",
    "            5000).batch(batch_size)\n",
    "        preds = model.predict(dataset)\n",
    "        yield pd.Series(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969800b6-b226-4a65-b322-1542232645e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(col(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710fedd-8934-4bfa-ab98-e4dfbba093d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.read.parquet(output_file_path)\n",
    "result_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21bbd0-94eb-4245-a14d-faf51735065c",
   "metadata": {},
   "source": [
    "### Model inference using sparkext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d11e0c-018c-4c9a-b908-6518aa0cc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "from sparkext.tensorflow import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575cb34-d175-4a18-a011-f65edefe6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f928cc-f4b9-42ea-82d8-87a11adb5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_udf = model_udf(model, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f262e7f-bb50-403a-8a2c-d44681a71a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path + \"_sparkext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac023dd-901e-4759-b780-18608bd7d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.read.parquet(output_file_path)\n",
    "result_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ed80e-b4d9-4ce0-b136-31479251bbca",
   "metadata": {},
   "source": [
    "### Model inference using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe8271-39f7-4811-890c-833191b0664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature  #, ModelSignature\n",
    "# from mlflow.types.schema import Schema, TensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e8e13-b08c-4b10-8e67-244b9d89d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.vstack(pandas_df['data'].head(10).to_numpy()).reshape(-1,224,224,3)\n",
    "predictions = model.predict(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714612c-18cb-40f9-a674-609c0c1a1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(train_images, model.predict(train_images))\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88401c26-c307-44c3-b651-5dbf9e3ee9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"resnet50_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec7652-24c6-4ce8-ad5a-423eb21c248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.save_model(tf_saved_model_dir=\"resnet50_model\", \n",
    "                             tf_meta_graph_tags=[\"serve\"], \n",
    "                             tf_signature_def_key=\"serving_default\",\n",
    "                             signature=signature,\n",
    "                             path=\"resnet50_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a74c2-e982-43d4-9575-9d9fee990b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_udf = mlflow.pyfunc.spark_udf(spark, model_uri=\"resnet50_mlflow\", result_type=\"array<float>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d42dd-71cc-4dab-9b68-122f45b2a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path + \"_mlflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97561f2c-bd92-49dd-a7de-1fb3d87b327a",
   "metadata": {},
   "source": [
    "### Model inference using Triton UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7ffdd-4452-4b3b-8188-f79d3ed3cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkext.triton import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e4e40-c370-42dd-a57f-5b2762f747f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110aa86-4299-4357-9fa9-13c91fa6b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_udf = model_udf(model, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9eef42-3020-4106-a3a5-b38d084de6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(col(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path + \"_sparkext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71662daf-ddee-439a-b76e-cca3e02f5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.read.parquet(output_file_path)\n",
    "result_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe0a8e-485c-471f-83af-91fd58a223a6",
   "metadata": {},
   "source": [
    "### Model inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6af27b2-ddc0-42ee-94cc-9ba5ffee6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda88b46-6300-4bf7-bc10-7403f4fbbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    model = ResNet50()\n",
    "    def predict(inputs):\n",
    "        return model.predict(inputs)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff0e851-563d-40b6-9d05-509c22b3b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             input_tensor_shapes=[[-1, 224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f733c38b-867d-48c1-b9a6-74a931561896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7c156f-e2b3-4837-9427-ccf3a5720412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bc50ad-eaf5-4fce-a354-5e17d65e2da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[6.480268E-9, 1.7902835E-8, 7.2895295E-10, 1.12287755E-10, 4.777694E-9, 2.2727333E-8, 3.2138614E-10, 1.1390412E-7, 1....|\n",
      "|[4.272546E-10, 1.0472946E-9, 3.108161E-11, 1.3740103E-11, 9.3929885E-11, 1.0310459E-9, 6.280175E-12, 3.2855128E-9, 2....|\n",
      "|[7.145851E-5, 8.087193E-5, 0.15172856, 8.129367E-4, 8.880329E-4, 1.0974148E-4, 9.9298115E-5, 1.1457807E-4, 3.2580836E...|\n",
      "|[7.687008E-6, 1.7460868E-4, 1.17645766E-4, 1.8629865E-4, 4.112672E-4, 3.5050482E-4, 1.04423976E-4, 1.8672385E-5, 6.10...|\n",
      "|[1.9156582E-6, 3.662862E-5, 4.240978E-5, 1.1411563E-5, 1.6928356E-4, 7.110861E-5, 2.9225656E-4, 6.846987E-6, 2.140841...|\n",
      "|[9.34794E-6, 1.864951E-4, 1.9097943E-6, 3.6263013E-5, 1.3185784E-4, 1.9736157E-5, 8.671819E-5, 5.3662665E-5, 1.414319...|\n",
      "|[2.3047342E-9, 1.8695232E-7, 3.7952518E-8, 4.3551283E-9, 2.4147294E-8, 3.0573922E-8, 2.2895523E-9, 5.5021445E-7, 7.30...|\n",
      "|[3.551709E-7, 2.3246289E-4, 2.8988514E-5, 1.4955194E-4, 1.8652188E-5, 1.3078138E-5, 8.683609E-6, 1.4898999E-5, 1.8562...|\n",
      "|[3.6834173E-9, 1.0076402E-8, 6.4294188E-9, 8.6534396E-10, 6.805393E-9, 9.362281E-9, 1.8166754E-9, 1.2439368E-7, 3.562...|\n",
      "|[1.8750605E-7, 1.1651735E-5, 1.7778036E-6, 4.8806584E-7, 2.2022184E-6, 2.9770395E-6, 1.7784955E-6, 1.0075075E-5, 1.36...|\n",
      "|[3.210844E-8, 1.476246E-7, 6.8195625E-8, 1.5303936E-8, 9.2581935E-8, 5.448698E-8, 3.098004E-7, 3.567145E-7, 6.183706E...|\n",
      "|[4.238289E-11, 2.287005E-7, 9.661714E-10, 5.61037E-10, 2.2782083E-9, 2.5290596E-8, 1.3540037E-10, 1.4266135E-8, 1.220...|\n",
      "|[2.6148393E-7, 1.3732212E-6, 5.893772E-9, 5.6110516E-9, 1.5766325E-8, 1.3923523E-7, 2.1172322E-9, 4.4309337E-7, 2.049...|\n",
      "|[2.1618545E-8, 2.1352118E-6, 9.432678E-7, 8.108845E-8, 3.3194368E-7, 1.2274002E-7, 2.4183137E-7, 3.329495E-6, 9.60973...|\n",
      "|[2.863582E-7, 3.576562E-6, 9.731476E-9, 1.9435001E-7, 2.0897413E-7, 3.9102582E-7, 5.082442E-8, 4.3359535E-7, 3.031883...|\n",
      "|[2.5549693E-7, 1.504187E-6, 3.102297E-8, 8.692343E-9, 1.4716966E-7, 6.146457E-8, 4.7177423E-8, 4.919846E-7, 7.678933E...|\n",
      "|[1.1920198E-7, 6.0400503E-6, 2.338984E-9, 5.9811185E-8, 2.6852666E-7, 5.9499786E-7, 1.4760849E-7, 9.5241387E-7, 5.604...|\n",
      "|[2.2277664E-8, 7.9962504E-8, 5.7809274E-10, 3.9487594E-10, 4.578171E-9, 8.772838E-8, 3.2476033E-10, 1.1969809E-7, 9.2...|\n",
      "|[4.7353675E-5, 3.9353836E-5, 1.711638E-5, 1.6131495E-5, 6.690701E-5, 1.4568128E-5, 9.6411295E-6, 1.0027828E-5, 7.0824...|\n",
      "|[2.7380855E-7, 6.8894674E-6, 3.0036017E-7, 2.394066E-7, 4.8667816E-6, 1.3894562E-5, 1.6980842E-7, 1.7628712E-5, 7.267...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89b02d-abb4-4dba-95af-b9c4077bcdb8",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108ea9c-bebe-4309-b789-56626af057e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8c0744-0558-4dac-bbfe-8bdde4b2af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={\n",
    "                \"/home/leey/devpub/leewyang/sparkext/examples/models\": {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                \"/home/leey/huggingface/cache\": {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07365c-0a14-49b3-9bd8-cfb35f48b089",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c17b6e-5481-44e3-abde-9b35bfc67ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd46360-6851-4a9d-8590-c086e001242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fabcaeb-5a44-42bb-8097-5dbc2d0cee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(triton_fn,\n",
    "                             triton_uri=\"localhost:8001\",\n",
    "                             model_name=\"resnet_50\",\n",
    "                             input_tensor_shapes=[[-1, 224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17f33c8-a0f0-4bce-91f8-5838ba9b12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5b9e99-a1cf-43d3-a795-c7271a917057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e595473d-1a5d-46a6-a6ba-89d2ea903de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[6.4928676E-9, 1.7909096E-8, 7.3115214E-10, 1.1236475E-10, 4.781937E-9, 2.2758408E-8, 3.216114E-10, 1.1415651E-7, 1.2...|\n",
      "|[4.2570847E-10, 1.0446737E-9, 3.1041343E-11, 1.3694482E-11, 9.367803E-11, 1.0271425E-9, 6.2756176E-12, 3.2876208E-9, ...|\n",
      "|[7.170488E-5, 8.105519E-5, 0.15266123, 8.1522577E-4, 8.923165E-4, 1.10131026E-4, 9.962701E-5, 1.1484663E-4, 3.260079E...|\n",
      "|[7.697718E-6, 1.748849E-4, 1.17513E-4, 1.8603323E-4, 4.1148433E-4, 3.5065506E-4, 1.04553015E-4, 1.8722472E-5, 6.11295...|\n",
      "|[1.9293225E-6, 3.68381E-5, 4.2936168E-5, 1.1517309E-5, 1.7104512E-4, 7.176816E-5, 2.9497486E-4, 6.8992535E-6, 2.15252...|\n",
      "|[9.326582E-6, 1.8598133E-4, 1.9122865E-6, 3.617167E-5, 1.3149905E-4, 1.9696772E-5, 8.657683E-5, 5.3720647E-5, 1.41466...|\n",
      "|[2.289872E-9, 1.8584811E-7, 3.7737067E-8, 4.3232413E-9, 2.4009156E-8, 3.0414167E-8, 2.2724682E-9, 5.470038E-7, 7.2693...|\n",
      "|[3.5799363E-7, 2.3359575E-4, 2.9146482E-5, 1.5003516E-4, 1.8786555E-5, 1.3122273E-5, 8.714284E-6, 1.4911332E-5, 1.855...|\n",
      "|[3.686295E-9, 1.0074239E-8, 6.4369456E-9, 8.6663965E-10, 6.820603E-9, 9.380128E-9, 1.8183998E-9, 1.2448956E-7, 3.5634...|\n",
      "|[1.8714223E-7, 1.1634808E-5, 1.7785524E-6, 4.875195E-7, 2.205429E-6, 2.9767173E-6, 1.7843491E-6, 1.0071421E-5, 1.3648...|\n",
      "|[3.2113455E-8, 1.4760289E-7, 6.838318E-8, 1.5293896E-8, 9.2663726E-8, 5.4584753E-8, 3.1002443E-7, 3.5701936E-7, 6.178...|\n",
      "|[4.2604902E-11, 2.2973828E-7, 9.687476E-10, 5.6181676E-10, 2.2795479E-9, 2.536597E-8, 1.3578189E-10, 1.4323097E-8, 1....|\n",
      "|[2.6089805E-7, 1.3706791E-6, 5.8761995E-9, 5.6002256E-9, 1.5738069E-8, 1.3894538E-7, 2.114736E-9, 4.422794E-7, 2.0442...|\n",
      "|[2.173726E-8, 2.1413405E-6, 9.5058925E-7, 8.150342E-8, 3.3484858E-7, 1.2365415E-7, 2.432614E-7, 3.353201E-6, 9.648999...|\n",
      "|[2.8604336E-7, 3.57685E-6, 9.724485E-9, 1.9405876E-7, 2.0908965E-7, 3.9079933E-7, 5.086537E-8, 4.338223E-7, 3.0293822...|\n",
      "|[2.5626636E-7, 1.5096784E-6, 3.1275743E-8, 8.7378975E-9, 1.4803535E-7, 6.169084E-8, 4.739863E-8, 4.936946E-7, 7.70185...|\n",
      "|[1.1944422E-7, 6.0548023E-6, 2.347144E-9, 5.994079E-8, 2.6928674E-7, 5.966678E-7, 1.478532E-7, 9.558322E-7, 5.618496E...|\n",
      "|[2.2289502E-8, 7.985985E-8, 5.7902355E-10, 3.949539E-10, 4.58126E-9, 8.767242E-8, 3.2503206E-10, 1.1977265E-7, 9.2800...|\n",
      "|[4.7490987E-5, 3.9459333E-5, 1.7202066E-5, 1.6169819E-5, 6.716709E-5, 1.4589655E-5, 9.674418E-6, 1.0047012E-5, 7.0946...|\n",
      "|[2.7491322E-7, 6.909238E-6, 3.0198893E-7, 2.403016E-7, 4.8781E-6, 1.3935617E-5, 1.7009121E-7, 1.7736447E-5, 7.3028314...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc06b7e-f750-40b5-9208-a035db11d937",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbfcaa51-3b9f-43ff-a4a8-4b46766115b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d88639b-d934-4eb4-ae2f-cc13b9b10456",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cc28a-34d7-479c-be7e-9a380d39e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
