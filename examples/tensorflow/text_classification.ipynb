{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd2accf-5877-4136-a243-7a33a13ce2b4",
   "metadata": {},
   "source": [
    "# Pyspark TensorFlow Inference\n",
    "\n",
    "## Text classification\n",
    "Based on: https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0f5df-502f-444e-b2ee-1122e1dea870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364ad5f-b269-45b5-ab8b-d8f34fb642b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229c1b6-3967-46b5-9ea8-68f4b42dd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    \"aclImdb_v1\", url, untar=True, cache_dir=\".\", cache_subdir=\"\"\n",
    ")\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8038ae-8bc1-46bf-ae4c-6da08886c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12faaa3f-3441-4361-b9eb-4317e8c2c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cc0cc-65d0-4e17-9ee8-222390df45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = os.path.join(train_dir, \"pos/1181_9.txt\")\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2277f58-78c8-4a12-bc98-5103e7c81a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83de92-ebb3-4170-b2bf-25265c6a6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c30568-daa8-4b2b-b30a-577c984a8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e863eb6-4bd7-4da0-b10d-d951b5ee52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593e2e5-df51-4fbf-b4be-c786e740ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fd61d-3926-4296-889a-b2a375a1b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb141709-fcc1-4cee-bc98-9c89aaba8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e80ea9-536a-4ebc-8b35-1eca73dbba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e5d81-7dae-4b08-b520-ca45501b9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f243f5-edd3-4e1c-bddc-abc1cc6673ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37e95c-515c-4edb-a1ee-fc47be5df4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9208a-39ac-4e6c-a603-61038cdf3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf90d4b-8dae-44b2-b32b-80cb0092c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a5aba-8a00-458f-be25-0aae9f55de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f4495-102d-4244-9b42-1ba9976a366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc95d22-935f-4091-b0ee-da95174eb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9059b93-7666-46db-bf15-517c4c205df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5959f-1bd8-48da-9815-8239599519b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656afe07-354f-4ff2-8e3e-d02bad6c5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d0f13-d0b8-4d78-9ddc-ede5ed402446",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7484c3-3cdf-46d5-b95d-80316f0e6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51178e-fe0b-40ca-9260-2190fb52d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0a42c-437e-41bb-99e7-d58cb8036a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "  layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939539b-a600-48b1-a55e-3f1087f4a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  \"The movie was great!\",\n",
    "  \"The movie was okay.\",\n",
    "  \"The movie was terrible...\"\n",
    "]\n",
    "\n",
    "export_model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b40a59-8d3b-44ec-a4f7-92c5742a0c1c",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa1770-2bf9-436b-af32-16b64fc97490",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22cc32-2708-4808-8e76-99024da87a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model.save('text_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add8a92-bb90-415b-ae21-417a6b722a8b",
   "metadata": {},
   "source": [
    "### Inspect saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dda184-8288-4de2-95a9-41d0a9744b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756f01d-dcef-4132-a0e6-4231792356de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir text_model --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0461f74-fdd0-4f30-9f44-0be7ad00d9b0",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf2c7f-5e86-4ff8-984e-dd0ed7a3ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register callables as custom objects before loading\n",
    "custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = tf.keras.models.load_model('text_model')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a4f7e-fa45-4d21-b103-fe3718bc0f10",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531680b2-42ef-4205-9a38-6995aee9f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ae387-1587-4175-b4b2-66586e4668f7",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0c37f-de28-4b94-adb6-ea43b937afb4",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea1c53-b0ac-48d4-9316-697149c410ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sparkext\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59cad5-25a5-47ec-a1d8-631b868bc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using huggingface IMDB parquet for now, since conversion above isn't working\n",
    "dataset = Path(\"../huggingface/imdb_test\").absolute().as_posix()\n",
    "df = spark.read.parquet(dataset).repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783aa84-98c1-4920-a501-1c6b8c993727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5b934-5bb5-4658-900e-9b970d7bfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    import re\n",
    "    import string\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    def custom_standardization(input_data):\n",
    "        lowercase = tf.strings.lower(input_data)\n",
    "        stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "        return tf.strings.regex_replace(\n",
    "            stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "        )\n",
    "    \n",
    "    max_features = 10000\n",
    "    sequence_length = 250\n",
    "\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_features,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    \n",
    "    custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91517d9-db4e-4d36-8f23-dfd1632c4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: must use absolute path to model, since executors have their own current working directories\n",
    "model_path = Path(\"text_model\").absolute().as_posix()\n",
    "print(f\"model: {model_path}\")\n",
    "\n",
    "model = sparkext.tensorflow.Model(model_path, model_loader) \\\n",
    "                .setInputCol(\"lines\") \\\n",
    "                .setOutputCol(\"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bc2f6-8409-47c1-a002-9342bd5337cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee5583-cd16-4497-957d-d1c1388e233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7c104-d32c-4189-bdad-7ed463e39315",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f16a23-e89b-40b8-850f-2ebee3a14192",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55396dc-cddb-479f-bb57-f1307980c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from sparkext.tensorflow import model_udf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be145cad-56e0-48cd-bd8e-06792e066b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using huggingface IMDB parquet for now, since conversion above isn't working\n",
    "dataset = Path(\"../huggingface/imdb_test\").absolute().as_posix()\n",
    "df = spark.read.parquet(dataset).repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e3fbc-6fa2-407f-98a4-07cefc227661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a844a-136c-4729-9d65-0fbc7e306e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    # since this function runs on the executor, any required imports should be added inside the function.\n",
    "    import re\n",
    "    import string\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    def custom_standardization(input_data):\n",
    "        lowercase = tf.strings.lower(input_data)\n",
    "        stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "        return tf.strings.regex_replace(\n",
    "            stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "        )\n",
    "    \n",
    "    max_features = 10000\n",
    "    sequence_length = 250\n",
    "\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_features,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    \n",
    "    custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcda3a-8825-46d9-8d42-7dd86b9ccaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute path to model, since executors have their own current working directories\n",
    "model_path = Path(\"text_model\").absolute().as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58cadf-f766-4e07-b1d7-1ab06bb00350",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(model_path, model_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a830d1a-6be3-4be8-bb1e-1ce548fba005",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(col(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4f987-e466-4167-8613-ee0b8de573ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ad0f0-c11e-49d6-a53d-eeb8c411c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5450dff-e019-4ef5-a1d4-ad46c9da41ab",
   "metadata": {},
   "source": [
    "## Inference using MLFlow UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41917753-9eee-4e53-890b-4b179fa5051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.sql.functions import col\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c4167-2bd4-4a79-88a2-47135fea7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using huggingface IMDB parquet for now, since conversion above isn't working\n",
    "dataset = Path(\"../huggingface/imdb_test\").absolute().as_posix()\n",
    "df = spark.read.parquet(dataset).repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1ab2e-0f42-4b58-af20-1ded31328cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d697c1-5690-4dd0-a166-7e2381128424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute path to model, since executors have their own current working directories\n",
    "model_path = Path(\"text_model\").absolute().as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcec8c-edf7-48e1-92dc-783c3f9016cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "    )\n",
    "\n",
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ee846-e57b-4dda-be93-64adeba92e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "examples = np.array([\n",
    "  \"The movie was great!\",\n",
    "  \"The movie was okay.\",\n",
    "  \"The movie was terrible.\"\n",
    "])\n",
    "\n",
    "model.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea480af-796e-458e-8764-b648f2d581a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature, ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11f774-860d-4981-b89a-7367b5ce2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(examples, model.predict(examples))\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37b734-0dbc-4523-891f-7890b61ce9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = Schema([TensorSpec(np.dtype(np.str), (-1,), \"input\")])\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1,), \"output\")])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4643f1-37df-47d5-b800-cab6f923ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d7fa0-1be0-4bea-b5f5-e8fb1bdaa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"text_model_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169db6d1-072a-4c61-95fa-17824ea749eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.save_model(tf_saved_model_dir=model_path,\n",
    "                             tf_meta_graph_tags=[\"serve\"],\n",
    "                             tf_signature_def_key=\"serving_default\",\n",
    "                             signature=signature,\n",
    "                             path=\"text_model_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acce7f0-4599-41c5-b45e-38d4dc6cf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_infer = mlflow.pyfunc.load_model(\"text_model_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf56a85-0ee0-4470-bf46-3a623dda349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_infer.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7b7ea-49c6-4d4c-8506-3eb488aadf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_infer.predict({\"input\": examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204336a0-ddbc-4c14-b946-3faf50d1a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(col(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e695de-0f7e-4918-aaf1-45efc66ee823",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef458c8-9d2f-440d-b82d-9ca75fd7364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ac416-a37f-4f0b-8c77-628f0fcede69",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d515c2-ce53-4af5-a936-ae91fdecea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0d567a-0ef8-4a93-8235-e89ace2c82ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# note: using huggingface IMDB parquet for now, since conversion above isn't working\n",
    "df = spark.read.parquet(\"/home/leey/devpub/leewyang/sparkext/examples/huggingface/imdb_test\").repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7a8395-e2ae-4c3c-bf57-763dfde600ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                         (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                               lines|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happened\" next. We will never know for sure wh...|\n",
      "|I found myself getting increasingly angry as this movie progressed.<br /><br />Basically, Dr. Cra...|\n",
      "|The comparisons between the 1995 version and this are inevitable. Sadly, this version falls far s...|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before blathering on about it...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gentlemen. It was funny, twisted and comple...|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far. Lots of excuses...|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zaniness was thrown it w...|\n",
      "|Oh but this is woeful. One good actor after another turns in lamentable dialogue in half hearted ...|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. All is not well in Washington state and Or...|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of \"Magnolia...|\n",
      "|Tycus is one of the worst films direct to video films that I see ever.<br /><br />I am not amazin...|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin music into the chair) 4/10 Taker Vs. He...|\n",
      "|If you like bad movies (and you must to watch this one) here's a good one. Not quite as funny as ...|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspiration for famous mov...|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the friend that worked at the factory with t...|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the poorest excuses for an adaptation, ever...|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated super-prod...|\n",
      "|This is just about one of the dumbest things I've ever seen. Maybe not a worst movie ever contend...|\n",
      "|And you know why? Because they thought (or at least made horror fans think) that a bunch of obnox...|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently widowed Karen Tunny ...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0524cf-3a75-4fb8-8025-f0654acce13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    # since this function runs on the executor, any required imports should be added inside the function.\n",
    "    import re\n",
    "    import string\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    def custom_standardization(input_data):\n",
    "        lowercase = tf.strings.lower(input_data)\n",
    "        stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "        return tf.strings.regex_replace(\n",
    "            stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "        )\n",
    "\n",
    "    max_features = 10000\n",
    "    sequence_length = 250\n",
    "\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_features,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "\n",
    "    custom_objects = {\"vectorize_layer\": vectorize_layer,\n",
    "                      \"custom_standardization\": custom_standardization}\n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(\n",
    "            \"/home/leey/devpub/leewyang/sparkext/examples/tensorflow/text_model\")\n",
    "\n",
    "    def predict(inputs):\n",
    "        return model.predict(inputs)\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d603644-d938-4c87-aa8a-2512251638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=FloatType(),\n",
    "                             batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b480622-8dc1-4879-933e-c43112768630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 ms, sys: 4.07 ms, total: 14.3 ms\n",
      "Wall time: 80.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.withColumn(\"preds\", classify(struct(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b0a262-387e-4a5e-a60e-b9b8ee456199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 ms, sys: 1.02 ms, total: 3.58 ms\n",
      "Wall time: 8.76 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.withColumn(\"preds\", classify(\"lines\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef9e431-59f5-4b29-9f79-ae16a9cfb0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.87 ms, sys: 478 Âµs, total: 3.35 ms\n",
      "Wall time: 14.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.withColumn(\"preds\", classify(col(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d9758c-132a-4e94-be18-710ef5f8c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 165 ms, sys: 31.6 ms, total: 197 ms\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a325ee2-3268-414a-bb75-a5fcf794f512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+------------+\n",
      "|                                                                           lines|       preds|\n",
      "+--------------------------------------------------------------------------------+------------+\n",
      "|...But not this one! I always wanted to know \"what happened\" next. We will ne...|   0.5685876|\n",
      "|I found myself getting increasingly angry as this movie progressed.<br /><br ...|  0.19131866|\n",
      "|The comparisons between the 1995 version and this are inevitable. Sadly, this...|  0.08580024|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before bl...|0.0034280755|\n",
      "|Don't get me wrong, I love the TV series of League Of Gentlemen. It was funny...|3.9646143E-4|\n",
      "|Made it through the first half an hour and deserved a medal for getting that ...|  0.09948175|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zani...|  0.19058977|\n",
      "|Oh but this is woeful. One good actor after another turns in lamentable dialo...| 0.023020605|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. All is not well in Was...|   0.4481477|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me ...| 0.004405332|\n",
      "|Tycus is one of the worst films direct to video films that I see ever.<br /><...|  0.21889879|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin music into the chai...|  0.27235904|\n",
      "|If you like bad movies (and you must to watch this one) here's a good one. No...|   0.6267755|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspir...| 0.033862766|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the friend that worked a...|   0.6772268|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the poorest excuses for...| 0.010492308|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these bi...|0.0153977005|\n",
      "|This is just about one of the dumbest things I've ever seen. Maybe not a wors...| 0.017894838|\n",
      "|And you know why? Because they thought (or at least made horror fans think) t...|  0.13149439|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently ...| 0.015252625|\n",
      "+--------------------------------------------------------------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54a90574-7cbb-487b-b7a8-dcda0e6e301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3bfea-a825-46eb-b8c2-921a932c0089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
