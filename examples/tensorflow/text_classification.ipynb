{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd2accf-5877-4136-a243-7a33a13ce2b4",
   "metadata": {},
   "source": [
    "# Pyspark TensorFlow Inference\n",
    "\n",
    "## Text classification\n",
    "Based on: https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0f5df-502f-444e-b2ee-1122e1dea870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364ad5f-b269-45b5-ab8b-d8f34fb642b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229c1b6-3967-46b5-9ea8-68f4b42dd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    \"aclImdb_v1\", url, untar=True, cache_dir=\".\", cache_subdir=\"\"\n",
    ")\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8038ae-8bc1-46bf-ae4c-6da08886c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12faaa3f-3441-4361-b9eb-4317e8c2c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cc0cc-65d0-4e17-9ee8-222390df45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = os.path.join(train_dir, \"pos/1181_9.txt\")\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2277f58-78c8-4a12-bc98-5103e7c81a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83de92-ebb3-4170-b2bf-25265c6a6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c30568-daa8-4b2b-b30a-577c984a8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e863eb6-4bd7-4da0-b10d-d951b5ee52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593e2e5-df51-4fbf-b4be-c786e740ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fd61d-3926-4296-889a-b2a375a1b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb141709-fcc1-4cee-bc98-9c89aaba8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e80ea9-536a-4ebc-8b35-1eca73dbba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e5d81-7dae-4b08-b520-ca45501b9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f243f5-edd3-4e1c-bddc-abc1cc6673ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37e95c-515c-4edb-a1ee-fc47be5df4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9208a-39ac-4e6c-a603-61038cdf3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf90d4b-8dae-44b2-b32b-80cb0092c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a5aba-8a00-458f-be25-0aae9f55de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f4495-102d-4244-9b42-1ba9976a366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc95d22-935f-4091-b0ee-da95174eb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9059b93-7666-46db-bf15-517c4c205df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5959f-1bd8-48da-9815-8239599519b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656afe07-354f-4ff2-8e3e-d02bad6c5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d0f13-d0b8-4d78-9ddc-ede5ed402446",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7484c3-3cdf-46d5-b95d-80316f0e6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51178e-fe0b-40ca-9260-2190fb52d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0a42c-437e-41bb-99e7-d58cb8036a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "  layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939539b-a600-48b1-a55e-3f1087f4a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  \"The movie was great!\",\n",
    "  \"The movie was okay.\",\n",
    "  \"The movie was terrible...\"\n",
    "]\n",
    "\n",
    "export_model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b40a59-8d3b-44ec-a4f7-92c5742a0c1c",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa1770-2bf9-436b-af32-16b64fc97490",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22cc32-2708-4808-8e76-99024da87a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model.save('text_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add8a92-bb90-415b-ae21-417a6b722a8b",
   "metadata": {},
   "source": [
    "### Inspect saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dda184-8288-4de2-95a9-41d0a9744b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756f01d-dcef-4132-a0e6-4231792356de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir text_model --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0461f74-fdd0-4f30-9f44-0be7ad00d9b0",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf2c7f-5e86-4ff8-984e-dd0ed7a3ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register callables as custom objects before loading\n",
    "custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = tf.keras.models.load_model('text_model')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a4f7e-fa45-4d21-b103-fe3718bc0f10",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531680b2-42ef-4205-9a38-6995aee9f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ae387-1587-4175-b4b2-66586e4668f7",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0c37f-de28-4b94-adb6-ea43b937afb4",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea1c53-b0ac-48d4-9316-697149c410ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sparkext\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59cad5-25a5-47ec-a1d8-631b868bc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using huggingface IMDB parquet for now, since conversion above isn't working\n",
    "dataset = Path(\"../huggingface/imdb_test\").absolute().as_posix()\n",
    "df = spark.read.parquet(dataset).repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783aa84-98c1-4920-a501-1c6b8c993727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5b934-5bb5-4658-900e-9b970d7bfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    import re\n",
    "    import string\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    def custom_standardization(input_data):\n",
    "        lowercase = tf.strings.lower(input_data)\n",
    "        stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "        return tf.strings.regex_replace(\n",
    "            stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "        )\n",
    "    \n",
    "    max_features = 10000\n",
    "    sequence_length = 250\n",
    "\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_features,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    \n",
    "    custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91517d9-db4e-4d36-8f23-dfd1632c4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: must use absolute path to model, since executors have their own current working directories\n",
    "model_path = Path(\"text_model\").absolute().as_posix()\n",
    "print(f\"model: {model_path}\")\n",
    "\n",
    "model = sparkext.tensorflow.Model(model_path, model_loader) \\\n",
    "                .setInputCol(\"lines\") \\\n",
    "                .setOutputCol(\"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bc2f6-8409-47c1-a002-9342bd5337cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee5583-cd16-4497-957d-d1c1388e233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7c104-d32c-4189-bdad-7ed463e39315",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f16a23-e89b-40b8-850f-2ebee3a14192",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55396dc-cddb-479f-bb57-f1307980c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from sparkext.tensorflow import model_udf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be145cad-56e0-48cd-bd8e-06792e066b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using huggingface IMDB parquet for now, since conversion above isn't working\n",
    "dataset = Path(\"../huggingface/imdb_test\").absolute().as_posix()\n",
    "df = spark.read.parquet(dataset).repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e3fbc-6fa2-407f-98a4-07cefc227661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a844a-136c-4729-9d65-0fbc7e306e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    # since this function runs on the executor, any required imports should be added inside the function.\n",
    "    import re\n",
    "    import string\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    def custom_standardization(input_data):\n",
    "        lowercase = tf.strings.lower(input_data)\n",
    "        stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "        return tf.strings.regex_replace(\n",
    "            stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "        )\n",
    "    \n",
    "    max_features = 10000\n",
    "    sequence_length = 250\n",
    "\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_features,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    \n",
    "    custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcda3a-8825-46d9-8d42-7dd86b9ccaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute path to model, since executors have their own current working directories\n",
    "model_path = Path(\"text_model\").absolute().as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58cadf-f766-4e07-b1d7-1ab06bb00350",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(model_path, model_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a830d1a-6be3-4be8-bb1e-1ce548fba005",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(col(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4f987-e466-4167-8613-ee0b8de573ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ad0f0-c11e-49d6-a53d-eeb8c411c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ac416-a37f-4f0b-8c77-628f0fcede69",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d515c2-ce53-4af5-a936-ae91fdecea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.udf import model_udf\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0d567a-0ef8-4a93-8235-e89ace2c82ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# note: using huggingface IMDB parquet for now, since conversion above isn't working\n",
    "df = spark.read.parquet(\"/home/leey/devpub/leewyang/sparkext/examples/huggingface/imdb_test\").repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7a8395-e2ae-4c3c-bf57-763dfde600ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                            (5 + 5) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                               lines|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|Since THE MAGUS is a confusing puzzle that really has no solution, one should sit back and enjoy ...|\n",
      "|The movie has started, the wheels spin, your car has entered a race against the Fox.... You're be...|\n",
      "|I watched this movie to see the direction one of the most promising young talents in movies was g...|\n",
      "|A less than redemptive hunka junk that is mercifully free from the ravages of competence. Some No...|\n",
      "|While the dog was cute, the film was not. It wasn't the premise, or the theme that was a problem....|\n",
      "|The opening scene makes you feel like you're watching a high school play. But I've seen high scho...|\n",
      "|This movie starts off promisingly enough, but it gets a little to convoluted and caught up in its...|\n",
      "|I think this is a great, classic monster film for the family. The mole, what a machine! The tall ...|\n",
      "|This is another one of Hitchcock's highest rated movies and rightfully so. This is a tale of two ...|\n",
      "|Not being a movie aficionado, I am not familiar with the names of leading Directors, Scriptwriter...|\n",
      "|The horror. The film about the Nazis - the Germans. The murderers of babies, young girls rapists ...|\n",
      "|This film is a cash in. A cash in reliant on a rousing theme tune created for an earlier classic....|\n",
      "|When i was told about this movie i wasn't too happy to see it, although by the end credits, turne...|\n",
      "|Robert DeNiro and Eddie Murphy, what a team. While Rene Russo, William Shanter, and that guy from...|\n",
      "|OSS 117 was fun from start to finish.<br /><br />It's difficult to define why one film touches or...|\n",
      "|Really!Here the French cinema hits rock bottom ,and compared to it, the least appealing of the Am...|\n",
      "|I rarely write reviews but this film simply demands more attention than it gets as it contains th...|\n",
      "|Eric Bogosian's ability to roll from character to character in this 'one man show' exhibits his t...|\n",
      "|\"When a Killer Calls\" is an unusually nasty slasher flick, with some very unpleasant and unsettli...|\n",
      "|My wife and I never got into the movie.We thought it was way to sloooowwww and to many subtitles....|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0524cf-3a75-4fb8-8025-f0654acce13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # since this function runs on the executor, any required imports should be added inside the function.\n",
    "    import re\n",
    "    import string\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    def custom_standardization(input_data):\n",
    "        lowercase = tf.strings.lower(input_data)\n",
    "        stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "        return tf.strings.regex_replace(\n",
    "            stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "        )\n",
    "    \n",
    "    max_features = 10000\n",
    "    sequence_length = 250\n",
    "\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_features,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    \n",
    "    custom_objects = {\"vectorize_layer\": vectorize_layer, \"custom_standardization\": custom_standardization}\n",
    "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "        model = tf.keras.models.load_model(\"/home/leey/devpub/leewyang/sparkext/examples/tensorflow/text_model\")\n",
    "\n",
    "    def predict(inputs):\n",
    "        return model.predict(inputs)\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d603644-d938-4c87-aa8a-2512251638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(model_fn, \n",
    "                     input_tensor_shapes=[[-1,1]], \n",
    "                     return_type=ArrayType(FloatType()), \n",
    "                     batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b0a262-387e-4a5e-a60e-b9b8ee456199",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(struct(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d9758c-132a-4e94-be18-710ef5f8c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 191 ms, sys: 30.1 ms, total: 221 ms\n",
      "Wall time: 7.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a325ee2-3268-414a-bb75-a5fcf794f512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+-------------+\n",
      "|                                                                           lines|        preds|\n",
      "+--------------------------------------------------------------------------------+-------------+\n",
      "|Since THE MAGUS is a confusing puzzle that really has no solution, one should...| [0.43107176]|\n",
      "|The movie has started, the wheels spin, your car has entered a race against t...|  [0.7550323]|\n",
      "|I watched this movie to see the direction one of the most promising young tal...| [0.29135826]|\n",
      "|A less than redemptive hunka junk that is mercifully free from the ravages of...|  [0.2121423]|\n",
      "|While the dog was cute, the film was not. It wasn't the premise, or the theme...|  [0.1502041]|\n",
      "|The opening scene makes you feel like you're watching a high school play. But...|[0.026165824]|\n",
      "|This movie starts off promisingly enough, but it gets a little to convoluted ...|  [0.2671374]|\n",
      "|I think this is a great, classic monster film for the family. The mole, what ...| [0.53532904]|\n",
      "|This is another one of Hitchcock's highest rated movies and rightfully so. Th...| [0.55443954]|\n",
      "|Not being a movie aficionado, I am not familiar with the names of leading Dir...| [0.84496784]|\n",
      "|The horror. The film about the Nazis - the Germans. The murderers of babies, ...|  [0.3320742]|\n",
      "|This film is a cash in. A cash in reliant on a rousing theme tune created for...|[0.039317273]|\n",
      "|When i was told about this movie i wasn't too happy to see it, although by th...|  [0.8622266]|\n",
      "|Robert DeNiro and Eddie Murphy, what a team. While Rene Russo, William Shante...| [0.85911685]|\n",
      "|OSS 117 was fun from start to finish.<br /><br />It's difficult to define why...|  [0.9188473]|\n",
      "|Really!Here the French cinema hits rock bottom ,and compared to it, the least...| [0.20901166]|\n",
      "|I rarely write reviews but this film simply demands more attention than it ge...|  [0.9118146]|\n",
      "|Eric Bogosian's ability to roll from character to character in this 'one man ...| [0.85111463]|\n",
      "|\"When a Killer Calls\" is an unusually nasty slasher flick, with some very unp...| [0.38925764]|\n",
      "|My wife and I never got into the movie.We thought it was way to sloooowwww an...| [0.72780013]|\n",
      "+--------------------------------------------------------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f6667f-4895-45b3-9d2c-1f6e16739a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/23 17:04:27 WARN Dispatcher: Message RemoteProcessDisconnected(192.168.86.223:45664) dropped. Could not find BlockManagerEndpoint1.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d84a60-455d-4804-92a5-b3144b483a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
