{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66834048-5285-44a9-a031-e2e6e3347442",
   "metadata": {},
   "source": [
    "From: https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01162f42-0637-4dfe-8d7d-b577e4ffd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3e1b7-58cd-45f9-9fee-85f25a31c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326b072-a53c-40c4-a6cb-bd4d3d644d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
    "                        extract=True, cache_dir='.')\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98480ef-d13d-44c0-a227-e9a22f9bf2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efce25-a835-4cbd-b8a2-1418ba2c1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the original dataset, `'AdoptionSpeed'` of `4` indicates\n",
    "# a pet was not adopted.\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop unused features.\n",
    "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d403cf-9ae7-4780-9fac-13d920d8b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = np.split(dataframe.sample(frac=1), [int(0.8*len(dataframe)), int(0.9*len(dataframe))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206a56e-5403-42a9-805e-e037044e7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train), 'training examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ade5f-ac8a-47ca-a021-071239dfe97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels = df.pop('target')\n",
    "    df = {key: value[:, tf.newaxis] for key, value in dataframe.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec57c9-080e-4626-9e03-acf309cf3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbf268-4508-4eb8-abe1-acf1dbb97bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['Age'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09dc4b-3a2a-44f5-b41c-821ec30b87b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "    # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb91dc-360a-4a89-a9ea-bebc1ddbf1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_count_col = train_features['PhotoAmt']\n",
    "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
    "layer(photo_count_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623b612-e924-472b-9ef4-c7f14f9f53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a layer that turns strings into integer indices.\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    # Otherwise, create a layer that turns integer values into integer indices.\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Encode the integer indices.\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "    # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40e9ee-20a5-4a42-8543-c267f99af55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type_col = train_features['Type']\n",
    "test_type_layer = get_category_encoding_layer(name='Type',\n",
    "                                              dataset=train_ds,\n",
    "                                              dtype='string')\n",
    "test_type_layer(test_type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63a5cc-71f4-428e-9299-a8018edc7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_age_col = train_features['Age']\n",
    "test_age_layer = get_category_encoding_layer(name='Age',\n",
    "                                             dataset=train_ds,\n",
    "                                             dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "test_age_layer(test_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b040b0e-d8ca-4cf0-917c-dd9a272e1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df498e-4dd1-467a-8741-e1f5e15932a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical features.\n",
    "for header in ['PhotoAmt', 'Fee']:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12579f-34fb-40b0-a16a-3e13cfea8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
    "\n",
    "encoding_layer = get_category_encoding_layer(name='Age',\n",
    "                                             dataset=train_ds,\n",
    "                                             dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff286eb-7ad7-4d3a-8fa4-c729692d1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1']\n",
    "\n",
    "for header in categorical_cols:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                 dataset=train_ds,\n",
    "                                                 dtype='string',\n",
    "                                                 max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79247436-32d8-4738-a656-3f288c77001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc85d3e-6d1e-4167-9516-b1182e880542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b54d91-26f3-4232-ac33-895599bd6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `rankdir='LR'` to make the graph horizontal.\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9836c8-3c1a-41ad-8833-a946bafcfb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccebaa-fc24-4a58-a032-222cef8fdf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1724a4e-fdaa-4169-8740-05bf18cb3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_pet_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604ca70-e0af-4cdb-8046-53e37f4b6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8be0a1-e16b-4509-8cbc-357def8bb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2a2d5-fd4d-4320-bacc-fd4571cec709",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    'Type': 'Cat',\n",
    "    'Age': 3,\n",
    "    'Breed1': 'Tabby',\n",
    "    'Gender': 'Male',\n",
    "    'Color1': 'Black',\n",
    "    'Color2': 'White',\n",
    "    'MaturitySize': 'Small',\n",
    "    'FurLength': 'Short',\n",
    "    'Vaccinated': 'No',\n",
    "    'Sterilized': 'No',\n",
    "    'Health': 'Healthy',\n",
    "    'Fee': 100,\n",
    "    'PhotoAmt': 2,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = reloaded_model.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbfe69-93ed-4452-8985-c6685e0726c3",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64fd7b-3d1e-40f8-ab64-b5c13f8bbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8215b-5068-41b4-849c-1c3ea7bb108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"datasets/petfinder-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbde99-cf65-4c15-a163-754a0201a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f9a2b-e5a2-44d1-aeaf-7cba33f5d692",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00ef7e-2a88-487c-bd14-e6e9a25695d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparkext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df7267-7c32-47f9-9639-63a4f85b4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"datasets/petfinder-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96214d-f07f-455f-b67b-919b43e53a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1284dc-d618-4033-8be1-56517bdbb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae550e74-5a28-4523-85a1-5e7ad4793dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove label column\n",
    "columns.remove(\"target\")\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5acb76-c238-45d2-add7-f5e16e40f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sparkext.tensorflow.Model(\"my_pet_classifier\") \\\n",
    "                .setInputCols(columns) \\\n",
    "                .setOutputCol(\"pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0c290-6ca1-4815-a6e2-b7f903c0b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = my_model.transform(df)\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848bea4-0852-4452-aba8-321029a709fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e6455-1182-4994-8319-e660c0c32314",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519774f-36b9-439c-9aa7-edbe9ef9dac7",
   "metadata": {},
   "source": [
    "### Spark DataFrame column names match model input names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83010d31-8e49-4452-b074-4d013a51506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"datasets/petfinder-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2d73b-a4f3-4e61-a1c6-bba48370926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a0318-25e1-430f-9896-91262459c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6ac27-3e6a-4d3a-807c-82c4368f106b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove label column\n",
    "columns.remove(\"target\")\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf55047-2297-49c4-a3cd-c3036635ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkext.tensorflow import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfc6e9-0f50-4a21-9f79-cc6f99bdfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to pass the list of columns into the model_udf\n",
    "classify = model_udf(\"my_pet_classifier\", input_columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff2ec9-bdd9-4e3c-a01b-98e07db7d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"preds\", classify(*columns)).show(truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49897b0-f62a-475b-986e-85e80a237bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = df.withColumn(\"preds\", classify(*columns)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a234497-a8e7-405d-8fc1-5192eb1eac39",
   "metadata": {},
   "source": [
    "### Simulate Spark DataFrame column names not matching model input names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3922595-15d1-4d85-ae04-9e225671abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumnRenamed(\"Type\", \"species\") \\\n",
    "        .withColumnRenamed(\"Age\", \"years\") \\\n",
    "        .withColumnRenamed(\"Breed1\", \"breed\") \\\n",
    "        .withColumnRenamed(\"Gender\", \"sex\") \\\n",
    "        .withColumnRenamed(\"Color1\", \"main_color\") \\\n",
    "        .withColumnRenamed(\"Color2\", \"secondary_color\") \\\n",
    "        .withColumnRenamed(\"MaturitySize\", \"full_size\") \\\n",
    "        .withColumnRenamed(\"FurLength\", \"fur_length\") \\\n",
    "        .withColumnRenamed(\"Vaccinated\", \"immunized\") \\\n",
    "        .withColumnRenamed(\"Sterilized\", \"spayed\") \\\n",
    "        .withColumnRenamed(\"Health\", \"health\") \\\n",
    "        .withColumnRenamed(\"Fee\", \"cost\") \\\n",
    "        .withColumnRenamed(\"PhotoAmt\",\"photos\") \\\n",
    "        .withColumnRenamed(\"target\", \"adopted\")\n",
    "df2.show(truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55866e-8285-46b3-b2a2-763047efa924",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_columns = df2.columns\n",
    "spark_columns.remove('adopted')\n",
    "spark_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5db958-d8a5-4049-9dde-0f7c4cc283c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User must provide ordered list of equivalent model input names \n",
    "model_columns = ['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n",
    "model_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c0d69-44b2-4d3d-8c56-182348fc6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the list of model input names into the `model_udf` helper\n",
    "classify = model_udf(\"my_pet_classifier\", input_columns=model_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd4c68-be7d-4996-808a-569f44a61b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the list of Spark columns as the Spark SQL selectors\n",
    "df2.withColumn(\"preds\", classify(*spark_columns)).show(truncate=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3e424-2920-44eb-afa0-885e40b620ed",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c21296c-20ed-43f8-921a-c85a820d1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from typing import Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b38f3a-70ea-4746-9f52-c50087401508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"datasets/petfinder-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39cffe3b-c9df-472b-8a2c-6f7e7a4f9d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------------------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+\n",
      "|Type|Age|              Breed1|Gender|Color1|  Color2|MaturitySize|FurLength|Vaccinated|Sterilized| Health|Fee|PhotoAmt|target|\n",
      "+----+---+--------------------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+\n",
      "| Cat|  3|               Tabby|  Male| Black|   White|       Small|    Short|        No|        No|Healthy|100|       1|     1|\n",
      "| Cat|  1|Domestic Medium Hair|  Male| Black|   Brown|      Medium|   Medium|  Not Sure|  Not Sure|Healthy|  0|       2|     1|\n",
      "| Dog|  1|         Mixed Breed|  Male| Brown|   White|      Medium|   Medium|       Yes|        No|Healthy|  0|       7|     1|\n",
      "| Dog|  4|         Mixed Breed|Female| Black|   Brown|      Medium|    Short|       Yes|        No|Healthy|150|       8|     1|\n",
      "| Dog|  1|         Mixed Breed|  Male| Black|No Color|      Medium|    Short|        No|        No|Healthy|  0|       3|     1|\n",
      "+----+---+--------------------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c27243-7c74-4045-aaf1-f75a322c0530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt', 'target']\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47508b14-97fa-42ee-a7d0-6175e6408283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n"
     ]
    }
   ],
   "source": [
    "# remove label column\n",
    "columns.remove(\"target\")\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45665acf-50c8-445b-a985-b3dabd734709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import tensorflow as tf\n",
    "    model = tf.keras.models.load_model('/home/leey/devpub/leewyang/sparkext/examples/tensorflow/my_pet_classifier')\n",
    "    \n",
    "    def predict(inputs: Union[np.ndarray, Dict[str, np.ndarray]]) -> Union[np.ndarray, Dict[str, np.ndarray]]:\n",
    "        return model.predict(inputs)\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815e3b5f-7914-4235-85fa-50153dcd3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to pass the list of columns into the model_udf\n",
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             input_names=columns,\n",
    "                             return_type=FloatType(),\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ebcfbe-e000-4af7-af06-48d0473ed823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/14 08:39:56 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+----------+\n",
      "|Type|Age|    Breed1|Gender|Color1|  Color2|MaturitySize|FurLength|Vaccinated|Sterilized| Health|Fee|PhotoAmt|target|     preds|\n",
      "+----+---+----------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+----------+\n",
      "| Cat|  3|     Tabby|  Male| Black|   White|       Small|    Short|        No|        No|Healthy|100|       1|     1| 1.4765713|\n",
      "| Cat|  1|Domesti...|  Male| Black|   Brown|      Medium|   Medium|  Not Sure|  Not Sure|Healthy|  0|       2|     1| 1.2110844|\n",
      "| Dog|  1|Mixed B...|  Male| Brown|   White|      Medium|   Medium|       Yes|        No|Healthy|  0|       7|     1| 2.2120945|\n",
      "| Dog|  4|Mixed B...|Female| Black|   Brown|      Medium|    Short|       Yes|        No|Healthy|150|       8|     1| 0.5492995|\n",
      "| Dog|  1|Mixed B...|  Male| Black|No Color|      Medium|    Short|        No|        No|Healthy|  0|       3|     1| 1.6435666|\n",
      "| Cat|  3|Domesti...|Female| Cream|    Gray|      Medium|    Short|        No|        No|Healthy|  0|       2|     1| 1.5799563|\n",
      "| Cat| 12|Domesti...|  Male| Black|No Color|      Medium|     Long|        No|  Not Sure|Healthy|300|       3|     1| 1.1496277|\n",
      "| Cat|  2|Domesti...|Female|  Gray|No Color|      Medium|   Medium|        No|        No|Healthy|  0|       6|     1|  2.420511|\n",
      "| Cat| 12|Domesti...|Female| Black|   White|      Medium|   Medium|  Not Sure|  Not Sure|Healthy|  0|       2|     0|-0.0839...|\n",
      "| Dog|  2|Mixed B...|  Male| Black|   Brown|      Medium|    Short|        No|        No|Healthy|  0|       7|     1| 2.0866542|\n",
      "| Cat|  3|Domesti...|Female| Black|   Brown|       Large|     Long|       Yes|        No|Healthy| 50|       2|     1| 1.8891008|\n",
      "| Dog|  2|Mixed B...|  Male| Brown|   Cream|      Medium|     Long|       Yes|        No|Healthy|  0|       1|     1| 1.7332487|\n",
      "| Dog|  3|Mixed B...|Female| Brown|   Cream|      Medium|   Medium|  Not Sure|  Not Sure|Healthy|  0|       2|     1|0.45149392|\n",
      "| Dog| 78|   Terrier|  Male| Black|   White|      Medium|   Medium|  Not Sure|  Not Sure|Healthy|  0|       2|     0| 0.8297243|\n",
      "| Cat|  6|Domesti...|Female| Brown|No Color|       Small|    Short|       Yes|       Yes|Healthy|  0|       1|     1|0.13204241|\n",
      "| Dog|  8|Mixed B...|Female| Brown|No Color|      Medium|    Short|        No|       Yes|Healthy| 10|       2|     0|-0.2933...|\n",
      "| Dog|  2|Mixed B...|Female| Black|No Color|      Medium|    Short|        No|        No|Healthy|  0|       8|     1| 1.8891062|\n",
      "| Dog| 12|Mixed B...|Female| Brown|   White|      Medium|   Medium|        No|       Yes|Healthy|  0|       7|     1| 0.2566943|\n",
      "| Dog| 10|Mixed B...|Female| Black|   Brown|      Medium|   Medium|       Yes|       Yes|Healthy|  0|       0|     0|-0.2786...|\n",
      "| Cat|  3|Domesti...|  Male| Brown|   White|       Small|    Short|        No|        No|Healthy|  0|      19|     1|  3.683622|\n",
      "+----+---+----------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"preds\", classify(struct(*columns))).show(truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f3c8ce-283b-464b-9e91-0ca7f110f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 6.49 ms, total: 144 ms\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = df.withColumn(\"preds\", classify(struct(*columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03990c76-7198-49a7-bb5d-6870be915fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.9 ms, sys: 0 ns, total: 74.9 ms\n",
      "Wall time: 6.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = df.withColumn(\"preds\", classify(struct(*columns))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e81619-8ef1-4fa5-9e03-3fef73b37b77",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e418f02-7616-4478-af12-b0df196613fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from typing import Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe8dc3e6-f1b1-4a24-85f4-0a5ecabef4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"datasets/petfinder-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce92f041-930f-48ed-9a03-19f6c249ca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------------------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+\n",
      "|Type|Age|              Breed1|Gender|Color1|  Color2|MaturitySize|FurLength|Vaccinated|Sterilized| Health|Fee|PhotoAmt|target|\n",
      "+----+---+--------------------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+\n",
      "| Cat|  3|               Tabby|  Male| Black|   White|       Small|    Short|        No|        No|Healthy|100|       1|     1|\n",
      "| Cat|  1|Domestic Medium Hair|  Male| Black|   Brown|      Medium|   Medium|  Not Sure|  Not Sure|Healthy|  0|       2|     1|\n",
      "| Dog|  1|         Mixed Breed|  Male| Brown|   White|      Medium|   Medium|       Yes|        No|Healthy|  0|       7|     1|\n",
      "| Dog|  4|         Mixed Breed|Female| Black|   Brown|      Medium|    Short|       Yes|        No|Healthy|150|       8|     1|\n",
      "| Dog|  1|         Mixed Breed|  Male| Black|No Color|      Medium|    Short|        No|        No|Healthy|  0|       3|     1|\n",
      "+----+---+--------------------+------+------+--------+------------+---------+----------+----------+-------+---+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cfb3f34-a215-4781-91bf-2bec85e15633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt', 'target']\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b315ee72-62af-476b-a994-0dba72d5f96e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n"
     ]
    }
   ],
   "source": [
    "# remove label column\n",
    "columns.remove(\"target\")\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fcde9-14b9-4733-9dac-8bf34a20a1a8",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7fb146c-5319-4831-85f7-f2f3c084b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"64M\",\n",
    "            volumes={\"/home/leey/devpub/leewyang/sparkext/examples/models\": {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "            \n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e6f20-f06c-4f4c-ada1-c562e078ed4b",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da004eca-f7ad-4ee3-aa88-a6a20c1b72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffb020e-dc93-456b-bee6-405611eee1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to pass the list of columns into the model_udf\n",
    "classify = predict_batch_udf(triton_fn,\n",
    "                             triton_uri=\"localhost:8001\",\n",
    "                             model_name=\"my_pet_classifier\",\n",
    "                             input_names=columns,\n",
    "                             input_tensor_shapes=[[-1, 1], [-1, 1], [-1, 1], [-1, 1], [-1, 1],\n",
    "                                                  [-1, 1], [-1, 1], [-1, 1], [-1, 1], [-1, 1], \n",
    "                                                  [-1, 1], [-1, 1], [-1, 1]],\n",
    "                             return_type=FloatType(),\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7657f820-5ec2-4ac8-a107-4b58773d204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/14 08:40:42 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 10) (192.168.86.223 executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 294, in predict\n",
      "    preds = predict_fn(inputs)\n",
      "  File \"/tmp/ipykernel_31619/2226899954.py\", line 34, in predict\n",
      "  File \"/home/leey/.pyenv/versions/spark_dev/lib/python3.9/site-packages/tritonclient/grpc/__init__.py\", line 1322, in infer\n",
      "    raise_error_grpc(rpc_error)\n",
      "  File \"/home/leey/.pyenv/versions/spark_dev/lib/python3.9/site-packages/tritonclient/grpc/__init__.py\", line 62, in raise_error_grpc\n",
      "    raise get_error_grpc(rpc_error) from None\n",
      "tritonclient.utils.InferenceServerException: [StatusCode.INTERNAL] [_Derived_]{{function_node __inference_signature_wrapper_21132}} {{function_node __inference_signature_wrapper_21132}} Op type not registered 'DenseBincount' in binary running on leey-dt. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "\t [[StatefulPartitionedCall_11]]\n",
      "\t [[StatefulPartitionedCall_11/_201]]\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:108)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:52)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:889)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:889)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1490)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "22/09/14 08:40:42 ERROR TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 294, in predict\n    preds = predict_fn(inputs)\n  File \"/tmp/ipykernel_31619/2226899954.py\", line 34, in predict\n  File \"/home/leey/.pyenv/versions/spark_dev/lib/python3.9/site-packages/tritonclient/grpc/__init__.py\", line 1322, in infer\n    raise_error_grpc(rpc_error)\n  File \"/home/leey/.pyenv/versions/spark_dev/lib/python3.9/site-packages/tritonclient/grpc/__init__.py\", line 62, in raise_error_grpc\n    raise get_error_grpc(rpc_error) from None\ntritonclient.utils.InferenceServerException: [StatusCode.INTERNAL] [_Derived_]{{function_node __inference_signature_wrapper_21132}} {{function_node __inference_signature_wrapper_21132}} Op type not registered 'DenseBincount' in binary running on leey-dt. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n\t [[{{node StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall_11]]\n\t [[StatefulPartitionedCall_11/_201]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# FAILS: Op type not registered 'DenseBincount'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/pyspark/sql/dataframe.py:858\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncate=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be either bool or int.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(truncate)\n\u001b[1;32m    856\u001b[0m     )\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/pyspark/sql/utils.py:205\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    201\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 294, in predict\n    preds = predict_fn(inputs)\n  File \"/tmp/ipykernel_31619/2226899954.py\", line 34, in predict\n  File \"/home/leey/.pyenv/versions/spark_dev/lib/python3.9/site-packages/tritonclient/grpc/__init__.py\", line 1322, in infer\n    raise_error_grpc(rpc_error)\n  File \"/home/leey/.pyenv/versions/spark_dev/lib/python3.9/site-packages/tritonclient/grpc/__init__.py\", line 62, in raise_error_grpc\n    raise get_error_grpc(rpc_error) from None\ntritonclient.utils.InferenceServerException: [StatusCode.INTERNAL] [_Derived_]{{function_node __inference_signature_wrapper_21132}} {{function_node __inference_signature_wrapper_21132}} Op type not registered 'DenseBincount' in binary running on leey-dt. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n\t [[{{node StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall_11]]\n\t [[StatefulPartitionedCall_11/_201]]\n"
     ]
    }
   ],
   "source": [
    "# FAILS: Op type not registered 'DenseBincount'\n",
    "df.withColumn(\"preds\", classify(struct(*columns))).show(truncate=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63135aa0-b44c-4dda-8050-8cad320afe88",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914f44f-677f-4db3-be09-783df8d11b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57ee98-b962-42d9-bfb1-61ba449ea9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4856c6-7a1f-43f5-b19b-de44c6b60464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
