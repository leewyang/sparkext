{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d55e3f",
   "metadata": {},
   "source": [
    "# Pyspark TensorFlow Inference\n",
    "\n",
    "## Image classification\n",
    "Based on: https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b28f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c7ad6",
   "metadata": {},
   "source": [
    "### Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b007f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset as numpy arrays\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7cedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten and normalize\n",
    "train_images = train_images.reshape(-1, 784) / 255.0\n",
    "test_images = test_images.reshape(-1, 784) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77bfbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a4403",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746d94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 14:34:39.763901: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d082a",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244746be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2207 - sparse_categorical_accuracy: 0.9333 - val_loss: 0.1030 - val_sparse_categorical_accuracy: 0.9672\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.0855 - val_sparse_categorical_accuracy: 0.9736\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0692 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.0692 - val_sparse_categorical_accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.0803 - val_sparse_categorical_accuracy: 0.9767\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.0709 - val_sparse_categorical_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc39ec54f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=5,\n",
    "          validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d3bba9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.358786 ,  -7.1993732,  -3.222292 ,  -1.5091399, -12.832173 ,\n",
       "         -8.094815 , -19.598206 ,  12.633436 ,  -6.5144963,  -2.5135467]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = test_images[:1]\n",
    "model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e700b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(test_img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b42b0",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f11a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"rm -rf mnist_model\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f9376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 14:35:18.049458: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a417c6",
   "metadata": {},
   "source": [
    "### Inspect saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a8ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_model\n",
      "├── assets\n",
      "├── keras_metadata.pb\n",
      "├── saved_model.pb\n",
      "└── variables\n",
      "    ├── variables.data-00000-of-00001\n",
      "    └── variables.index\n",
      "\n",
      "2 directories, 4 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"tree mnist_model\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "677e377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['dense_input'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 784)\n",
      "      name: serving_default_dense_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense_1'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 10)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"saved_model_cli show --dir mnist_model --tag_set serve --signature_def serving_default\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f013a4b",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c41008f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('mnist_model')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256662e8-30f1-437f-88b7-4534a7e76907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 784) dtype=float32 (created by layer 'dense_input')>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c7b84",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dbeeb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.358786 ,  -7.1993732,  -3.222292 ,  -1.5091399, -12.832173 ,\n",
       "         -8.094815 , -19.598206 ,  12.633436 ,  -6.5144963,  -2.5135467]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(test_images[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f4700",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fcf07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
    "# from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d0b1b",
   "metadata": {},
   "source": [
    "### Convert numpy array to Spark DataFrame (via Pandas DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49ff5203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array to pandas DataFrame\n",
    "test_pdf = pd.DataFrame(test_images)\n",
    "test_pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "182ee0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.9 s, sys: 0 ns, total: 50.9 s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 784 columns of float\n",
    "df = spark.createDataFrame(test_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302c73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 218 ms, sys: 0 ns, total: 218 ms\n",
      "Wall time: 215 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "test_pdf['data'] = test_pdf.values.tolist()\n",
    "pdf = test_pdf[['data']]\n",
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5495901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 311 ms, sys: 0 ns, total: 311 ms\n",
      "Wall time: 413 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.createDataFrame(pdf).repartition(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1c901",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57c0ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/07 14:36:15 WARN TaskSetManager: Stage 0 contains a task of very large size (4315 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"mnist_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b444e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d4ca414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/07 14:36:19 WARN TaskSetManager: Stage 3 contains a task of very large size (4315 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6569d",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcc8e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparkext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2556886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"mnist_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87d28256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sparkext.tensorflow.Model(\"mnist_model\") \\\n",
    "            .setInputCol(\"data\") \\\n",
    "            .setOutputCol(\"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e7805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model on driver from mnist_model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "ModelSummary(num_params=407050, inputs=[TensorSummary(shape=[None, 784], dtype=tf.float32, name='dense_input')], outputs=[TensorSummary(shape=[None, 10], dtype=tf.float32, name='dense_1/BiasAdd:0')]) -> array<float>\n",
      "INFO:tensorflow:Assets written to: ram://8be8f697-cbed-4522-983b-1e6695d992b8/assets\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83dcb64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.write.mode(\"overwrite\").parquet(\"mnist_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12653e5",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "413c4de6-f2b3-486c-85e1-6a1f7543a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4be4d975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 791 ms, sys: 0 ns, total: 791 ms\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c3a8538-7759-4cfe-9454-dbcd14a14552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-14.681986808776855,\n",
       " -8.035789489746094,\n",
       " -8.756430625915527,\n",
       " -0.6912011504173279,\n",
       " -14.260246276855469,\n",
       " 15.426255226135254,\n",
       " -6.493452072143555,\n",
       " -16.083724975585938,\n",
       " -6.774261474609375,\n",
       " -1.4227932691574097]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01d6c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preds[0].data\n",
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a47ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb875a3-f790-42e1-97d4-3d5b49387bd6",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2058354e-13ae-4899-8e2d-fe75d7e6bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9d3bb89-cd12-4b51-9b45-2ef96602a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"mnist_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9ec612c-0664-4fa7-ae85-e4c39cd348b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(data,ArrayType(DoubleType,true),true)))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b04bfeec-2de5-4813-a7be-6ed51ba44dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkext.tensorflow import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "168de22f-3033-4db7-ba51-8b9199735034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model on driver from mnist_model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "ModelSummary(num_params=407050, inputs=[TensorSummary(shape=[None, 784], dtype=tf.float32, name='dense_input')], outputs=[TensorSummary(shape=[None, 10], dtype=tf.float32, name='dense_1/BiasAdd:0')]) -> array<float>\n"
     ]
    }
   ],
   "source": [
    "mnist = model_udf(\"mnist_model\", batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23e14e8f-396a-42ba-8866-00f64002d180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e7565c0c-6b63-4f56-91b2-fe8e508434d0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 782 ms, sys: 90.2 ms, total: 872 ms\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(col(\"data\"))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4b24c-c188-4b6d-adf5-44182be6f181",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94edf3b7-7598-40b4-92a3-410d5c0ee0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-14.681986808776855,\n",
       " -8.035789489746094,\n",
       " -8.756430625915527,\n",
       " -0.6912011504173279,\n",
       " -14.260246276855469,\n",
       " 15.426255226135254,\n",
       " -6.493452072143555,\n",
       " -16.083724975585938,\n",
       " -6.774261474609375,\n",
       " -1.4227932691574097]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bbc483c-8fcd-40d2-9c04-85b74301615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87bfc410-d79d-4b30-bd60-90a9d68570c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preds[0].data\n",
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "643c9b37-972b-4629-85f9-604f2dc3ce8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
