{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96e58e7-51d0-486f-85ad-51dc18735e15",
   "metadata": {},
   "source": [
    "# Scratch Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ac9c4-bc91-411d-b4e2-df61647df06f",
   "metadata": {},
   "source": [
    "## Create pandas/spark dataframes for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2657a5e-ff67-44b9-8205-a7f00db8ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf, spark_partition_id, struct\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e58d6b-f00e-48ad-8af1-7c5b3805c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "pdf = pd.DataFrame(data, columns=['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e016b1-1ea6-4676-9b86-dd191eb969e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_scalar = pdf\n",
    "df_scalar = spark.createDataFrame(pdf_scalar)\n",
    "\n",
    "pdf_tensor = pd.DataFrame()\n",
    "pdf_tensor['t1'] = pdf_scalar.values.tolist()\n",
    "df_tensor1 = spark.createDataFrame(pdf_tensor)\n",
    "\n",
    "pdf_tensor['t2'] = pdf_scalar.drop(columns='d').values.tolist()\n",
    "df_tensor2 = spark.createDataFrame(pdf_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91522a3-a2ee-4121-a3da-eefebb15fb43",
   "metadata": {},
   "source": [
    "### pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe674677-acc5-4827-bb86-5c370999a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3c00b-0f6a-48ab-a215-ce2c0467f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000a092-e40b-4b96-8f12-b69466ca04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pdf_scalar['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02ea27-6328-4df9-a1c6-2064c59c683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bdf79e-3d12-4c7c-b0ab-02845cc54d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1ce6c-cdeb-4038-8ed9-2342d271b3a4",
   "metadata": {},
   "source": [
    "### spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69d10c-2c7f-485b-9610-bdfa3bd22e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e972fc7-4704-4851-93f0-697cafb058ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658892b-d0ee-49fa-8d0d-06c1d96f70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8bf27-59b2-4828-a842-b03fbc7cd260",
   "metadata": {},
   "source": [
    "### spark partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada81fd-e88c-4f2f-807b-b827ae804b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id\n",
    "df.withColumn(\"partition_id\", spark_partition_id()).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad360fb-c816-4026-b906-3d0d95ef454d",
   "metadata": {},
   "source": [
    "## Test tensor columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b577952-9edc-4463-bc2c-71b29d125d4c",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8a15f-81ad-467f-906c-706b68e19837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175304f0-b76d-4301-b21c-2c4b4298c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_tensor2.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e4086-04c9-47a4-b470-2a1abfea15ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e30d7a-9143-46ca-bc0f-1f3c1a158da8",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=ArrayType(DoubleType()) | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa8b0f-b9c4-4565-9efa-e0b204b8827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c9d84-87d4-4efd-bfaf-3ec3ca6760ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=ArrayType(DoubleType()))\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9ac9e-3bc7-4668-befa-7f7507afe07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21161bb-277f-4cb8-86b4-da54d0adba09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pDF -> pS | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2bbf9-55e1-42eb-bcbd-cc5c4e3be058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd3d73-3e09-4803-b3cd-4c4bebf54f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_tensor2.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d4bfa-44ef-40bd-a2cb-c559e2123a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ef869-d875-4664-8d79-98200ffad5c0",
   "metadata": {},
   "source": [
    "### pDF -> pS | returnType=ArrayType(DoubleType()) | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b651bd-977c-47d9-ae24-5e50fd40aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a0187-e1bb-4eaa-adcd-2e38fe4d2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=ArrayType(DoubleType()))\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c65670-b50e-44db-8a05-4da71ced8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754200f4-00c7-433e-91dc-fc78c012d513",
   "metadata": {},
   "source": [
    "### Union[pDF, pS] -> Union[pDF, pS] | returnType=StructType() | return pS => FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd79653-af9b-402c-8593-66fabf8a9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3089081-0ea4-4b18-8560-beb0d946e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_tensor2.schema)\n",
    "# def predict(inputs: Iterator[Union[pd.DataFrame, pd.Series]]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "# def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "# def predict(inputs: Iterator[pd.Series]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f0f1f-8f2f-45f5-9f1a-3275ccafb57e",
   "metadata": {},
   "source": [
    "## Test scalar columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0d3ca-69dc-4e2d-bbcc-ed1d37e831f2",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc79165-ce6b-489a-a56c-71169e2290be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1510180-016c-4a56-9427-25b437ad3a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_scalar.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722dee2-ecc9-4f5a-8e3c-7dba759a7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ad717-87a4-44a8-87c8-b01302143c29",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=DoubleType() | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f043b8-9755-4fe7-bb42-18eae5452d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916afdf-8f38-4fd0-8dfa-3f898174a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=DoubleType())\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d655206-ca3e-4a5c-a337-38f90213d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc1abd-933e-4571-a735-c26ccf6e8d19",
   "metadata": {},
   "source": [
    "### pDF -> pS | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da96e84-94c8-4c99-8831-544e855c7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7a314-f511-42f0-aff5-cc5a894b6f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_scalar.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babeda32-112d-4d6d-89fb-8f7ad24bc4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e69ae2-0802-40d5-8d8c-918b8c1b6457",
   "metadata": {},
   "source": [
    "### pDF -> pS | returnType=DoubleType() | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead95954-f7a3-48e7-bd44-15d3b2a3d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7564de-9a76-474a-9666-6b7d875b17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=DoubleType())\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d0f75-25d9-418e-9487-d7a8befc890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa8769-8a26-4cdd-9728-c304874c1b2f",
   "metadata": {},
   "source": [
    "### Union[pDF, pS] -> Union[pDF, pS] | returnType=StructType) | return pS => FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dcc5c-b4c1-49e2-889f-87ab6037442d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_scalar.schema)\n",
    "def predict(inputs: Iterator[Union[pd.DataFrame, pd.Series]]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717ffa6-110c-4881-8c23-e69b16974609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341934d-625f-4f71-85bf-350a290275f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "from pyspark.sql.pandas.typehints import infer_eval_type\n",
    "from typing import get_type_hints, Any, Callable, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b8f77-a22b-4377-bae0-79a99eb92386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_iterator_annotation(\n",
    "    annotation: Any, parameter_check_func: Optional[Callable[[Any], bool]] = None\n",
    ") -> bool:\n",
    "    name = getattr(annotation, \"_name\", getattr(annotation, \"__name__\", None))\n",
    "    return name == \"Iterator\" and (\n",
    "        parameter_check_func is None or all(map(parameter_check_func, annotation.__args__))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357203ee-f2ad-47c8-bed1-b0f0dc14caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_union_annotation(\n",
    "    annotation: Any, parameter_check_func: Optional[Callable[[Any], bool]] = None\n",
    ") -> bool:\n",
    "    import typing\n",
    "\n",
    "    # Note that we cannot rely on '__origin__' in other type hints as it has changed from version\n",
    "    # to version. For example, it's abc.Iterator in Python 3.7 but typing.Iterator in Python 3.6.\n",
    "    origin = getattr(annotation, \"__origin__\", None)\n",
    "    return origin == typing.Union and (\n",
    "        parameter_check_func is None or all(map(parameter_check_func, annotation.__args__))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33785c-39a2-4495-842b-08885d6b5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tuple_annotation(\n",
    "    annotation: Any, parameter_check_func: Optional[Callable[[Any], bool]] = None\n",
    ") -> bool:\n",
    "    # Tuple has _name but other types have __name__\n",
    "    # Check if the name is Tuple first. After that, check the generic types.\n",
    "    name = getattr(annotation, \"_name\", getattr(annotation, \"__name__\", None))\n",
    "    return name == \"Tuple\" and (\n",
    "        parameter_check_func is None or all(map(parameter_check_func, annotation.__args__))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab214bb-8e14-4b63-b3a7-294f86c75c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: Iterator[Union[pd.Series, pd.DataFrame]]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd7ca3-afee-4546-a0b4-c05f786d4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = signature(predict)\n",
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f075a-38b0-4475-b0e9-5da48a337a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_hints = get_type_hints(predict)\n",
    "type_hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4066b-1ea0-49e6-9591-a29ef46febee",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {}\n",
    "for param in sig.parameters.values():\n",
    "    if param.annotation is not param.empty:\n",
    "        annotations[param.name] = type_hints.get(param.name, param.annotation)\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce3e70-3a83-418a-b062-19e683994850",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sig = [\n",
    "    annotations[parameter] for parameter in sig.parameters if parameter in annotations]\n",
    "parameters_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe5863-75a4-40ac-9ddd-fb84230cdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_annotation = type_hints.get(\"return\", sig.return_annotation)\n",
    "return_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857dda63-60ed-4bda-b852-9618e4a52826",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_series_or_frame = all(\n",
    "    a == pd.Series\n",
    "    or a == pd.DataFrame  # Series\n",
    "    or check_union_annotation(  # DataFrame  # Union[DataFrame, Series]\n",
    "        a, parameter_check_func=lambda na: na == pd.Series or na == pd.DataFrame\n",
    "    )\n",
    "    for a in parameters_sig\n",
    ") and (return_annotation == pd.Series or return_annotation == pd.DataFrame)\n",
    "is_series_or_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e74b04-8bcb-423b-82ec-6f50ed11321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_iterator_tuple_series_or_frame = (\n",
    "    len(parameters_sig) == 1\n",
    "    and check_iterator_annotation(  # Iterator\n",
    "        parameters_sig[0],\n",
    "        parameter_check_func=lambda a: check_tuple_annotation(  # Tuple\n",
    "            a,\n",
    "            parameter_check_func=lambda ta: (\n",
    "                ta == Ellipsis\n",
    "                or ta == pd.Series  # ...\n",
    "                or ta == pd.DataFrame  # Series\n",
    "                or check_union_annotation(  # DataFrame  # Union[DataFrame, Series]\n",
    "                    ta, parameter_check_func=lambda na: (na == pd.Series or na == pd.DataFrame)\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    and check_iterator_annotation(\n",
    "        return_annotation, parameter_check_func=lambda a: a == pd.DataFrame or a == pd.Series\n",
    "    )\n",
    ")\n",
    "is_iterator_tuple_series_or_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a17191-d9f6-4de9-b6dd-5ec13e2d8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_iterator_series_or_frame = (\n",
    "    len(parameters_sig) == 1\n",
    "    and check_iterator_annotation(\n",
    "        parameters_sig[0],\n",
    "        parameter_check_func=lambda a: (\n",
    "            a == pd.Series\n",
    "            or a == pd.DataFrame  # Series\n",
    "            or check_union_annotation(  # DataFrame  # Union[DataFrame, Series]\n",
    "                a, parameter_check_func=lambda ua: ua == pd.Series or ua == pd.DataFrame\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    and check_iterator_annotation(\n",
    "        return_annotation, parameter_check_func=lambda a: a == pd.DataFrame or a == pd.Series\n",
    "    )\n",
    ")\n",
    "is_iterator_series_or_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bac7e8-2c6d-4702-842d-b396f00f98d9",
   "metadata": {},
   "source": [
    "### pS -> pS | returnType=ArrayType(DoubleType()) | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a724d0-91d4-431c-b370-23306cfbce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029256e6-8320-4dad-91cf-01e6db08493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93759c1e-83f8-4d17-a4ac-90a5d58c3957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=ArrayType(DoubleType()))\n",
    "def predict(inputs: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        # print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        # print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        print(\"===== batch[0]:\\n{}\".format(batch[0]))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f08667-baa0-48f3-b6a1-4006d4d8e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(array(columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c172c-6462-4226-843e-59905c5e3941",
   "metadata": {},
   "source": [
    "## Test caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae1db9-8ab6-4985-8d7c-4684da85f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from pyspark.ml.functions import batch_infer_udf\n",
    "from pyspark.sql.functions import struct, pandas_udf\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129f2b5-c3da-4cf4-8b22-fdf9d4a158e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "\n",
    "# 4 scalar columns\n",
    "pdf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7dc28-3246-4ead-b76b-442a792f9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    # emulate loading a model, this should only be invoked once (per worker process)\n",
    "    fake_output = np.random.random()\n",
    "\n",
    "    def predict(inputs):\n",
    "        return [fake_output for i in inputs]\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221a5af-5060-46ee-adc3-d25b457023bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = batch_infer_udf(predict_batch_fn, return_type=DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd887b1-bbca-4a7f-ad3e-fa1e458d41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# results should be the same\n",
    "df1 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952c941-125e-442b-8c22-d82f6e0957d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793aa60a-d1f7-4234-b21e-84c37e1155cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6e8f2-12fc-4069-bb1d-5fba62e4c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79589fbe-ac5a-40c5-bf07-c0341c1818dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc851cbd-bfe4-4d62-bb24-389610ebb7ff",
   "metadata": {},
   "source": [
    "## Test executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb93652-3adf-419e-bd05-a0695932afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from pyspark.ml.functions import batch_infer_udf\n",
    "from pyspark.sql.functions import struct, pandas_udf\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d3b4f-726c-4d82-855c-afaf5670a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "\n",
    "# 4 scalar columns\n",
    "pdf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe89306-d7fa-4bb7-8657-3b34212b6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfn(it):\n",
    "    import tensorflow as tf\n",
    "    print(\">>>> {}\".format(tf.__version__))\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "    # Create some tensors\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52acb13-205b-478c-abb9-8283b99475c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.foreachPartition(myfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9112497-f078-4eeb-b220-a052a326b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=FloatType())\n",
    "def myudf(it: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for part in it:\n",
    "        import tensorflow as tf\n",
    "        print(tf.__version__)\n",
    "        yield part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d53a7b-02df-4820-b5b1-72258b2f429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = df.withColumn(\"preds\", struct(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f40c5b-36fe-472e-9ec6-9b49cc2785cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67dc70-b052-4b39-a3a3-3cdb49ce6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== df1:\\n{}\".format(df1))\n",
    "print(\"==== df2:\\n{}\".format(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0fe5b-4936-4dbe-911b-6b22838d0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id\n",
    "df.withColumn(\"partition_id\", spark_partition_id()).withColumn(\"preds\", identity(struct(\"a\"))).groupBy(\"partition_id\", \"preds\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c3115-3e7f-4ca3-b26a-7b053812c09e",
   "metadata": {},
   "source": [
    "## Test zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c7d410-8151-40eb-a82a-333f04204292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7a992a7-1771-41d3-8068-2cb86d03bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.Series([0,1,2,3,4,5,6,7,8])\n",
    "bar = pd.Series(['a','b','c','d','e','f','g','h','i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fe40800-65b0-4ff2-87ec-22d0ad3c9131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0\n",
       " 1    1\n",
       " 2    2\n",
       " 3    3\n",
       " 4    4\n",
       " 5    5\n",
       " 6    6\n",
       " 7    7\n",
       " 8    8\n",
       " dtype: int64,\n",
       " 0    a\n",
       " 1    b\n",
       " 2    c\n",
       " 3    d\n",
       " 4    e\n",
       " 5    f\n",
       " 6    g\n",
       " 7    h\n",
       " 8    i\n",
       " dtype: object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = (foo, bar)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "887736f7-9733-4a19-ae7a-71a93d33cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, batch_size):\n",
    "    acc = []\n",
    "    for i, x in enumerate(zip(*iterable)):\n",
    "        acc += x\n",
    "        if i % batch_size == 0:\n",
    "            yield acc\n",
    "            acc = []\n",
    "    yield acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "577f4821-2209-4dcd-9361-794aa7ec48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import more_itertools\n",
    "\n",
    "def batch(iterable, batch_size):\n",
    "    for x in more_itertools.chunked(zip(*iterable), batch_size):\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6f9ecfb-0859-4f4d-b618-33e694c8589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'a'), (1, 'b')]\n",
      "====\n",
      "[(2, 'c'), (3, 'd')]\n",
      "====\n",
      "[(4, 'e'), (5, 'f')]\n",
      "====\n",
      "[(6, 'g'), (7, 'h')]\n",
      "====\n",
      "[(8, 'i')]\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "for x in batch(test, 2):\n",
    "    print(x)\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39599309-4dfe-402f-8957-feceeb03422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.concat(test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4d00ab4-ed45-492c-9481-18c9526cac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  a\n",
       "1  1  b\n",
       "2  2  c\n",
       "3  3  d\n",
       "4  4  e\n",
       "5  5  f\n",
       "6  6  g\n",
       "7  7  h\n",
       "8  8  i"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "/home/leey/devpub/leewyang/spark/python/pyspark/context.py:642: RuntimeWarning: Unable to cleanly shutdown Spark JVM process. It is possible that the process has crashed, been killed or may also be in a zombie state.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c0ab7-e335-4179-ab73-057e376291c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
