{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96e58e7-51d0-486f-85ad-51dc18735e15",
   "metadata": {},
   "source": [
    "# Scratch Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ac9c4-bc91-411d-b4e2-df61647df06f",
   "metadata": {},
   "source": [
    "## Create pandas/spark dataframes for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2657a5e-ff67-44b9-8205-a7f00db8ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf, spark_partition_id, struct\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e58d6b-f00e-48ad-8af1-7c5b3805c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "pdf = pd.DataFrame(data, columns=['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e016b1-1ea6-4676-9b86-dd191eb969e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_scalar = pdf\n",
    "df_scalar = spark.createDataFrame(pdf_scalar)\n",
    "\n",
    "pdf_tensor = pd.DataFrame()\n",
    "pdf_tensor['t1'] = pdf_scalar.values.tolist()\n",
    "df_tensor1 = spark.createDataFrame(pdf_tensor)\n",
    "\n",
    "pdf_tensor['t2'] = pdf_scalar.drop(columns='d').values.tolist()\n",
    "df_tensor2 = spark.createDataFrame(pdf_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91522a3-a2ee-4121-a3da-eefebb15fb43",
   "metadata": {},
   "source": [
    "### pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe674677-acc5-4827-bb86-5c370999a15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>980.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>984.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>988.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>992.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>996.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         a      b      c      d\n",
       "0      0.0    1.0    2.0    3.0\n",
       "1      4.0    5.0    6.0    7.0\n",
       "2      8.0    9.0   10.0   11.0\n",
       "3     12.0   13.0   14.0   15.0\n",
       "4     16.0   17.0   18.0   19.0\n",
       "..     ...    ...    ...    ...\n",
       "245  980.0  981.0  982.0  983.0\n",
       "246  984.0  985.0  986.0  987.0\n",
       "247  988.0  989.0  990.0  991.0\n",
       "248  992.0  993.0  994.0  995.0\n",
       "249  996.0  997.0  998.0  999.0\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff3c00b-0f6a-48ab-a215-ce2c0467f85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0]</td>\n",
       "      <td>[0.0, 1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4.0, 5.0, 6.0, 7.0]</td>\n",
       "      <td>[4.0, 5.0, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[8.0, 9.0, 10.0, 11.0]</td>\n",
       "      <td>[8.0, 9.0, 10.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12.0, 13.0, 14.0, 15.0]</td>\n",
       "      <td>[12.0, 13.0, 14.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[16.0, 17.0, 18.0, 19.0]</td>\n",
       "      <td>[16.0, 17.0, 18.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>[980.0, 981.0, 982.0, 983.0]</td>\n",
       "      <td>[980.0, 981.0, 982.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>[984.0, 985.0, 986.0, 987.0]</td>\n",
       "      <td>[984.0, 985.0, 986.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>[988.0, 989.0, 990.0, 991.0]</td>\n",
       "      <td>[988.0, 989.0, 990.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>[992.0, 993.0, 994.0, 995.0]</td>\n",
       "      <td>[992.0, 993.0, 994.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>[996.0, 997.0, 998.0, 999.0]</td>\n",
       "      <td>[996.0, 997.0, 998.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               t1                     t2\n",
       "0            [0.0, 1.0, 2.0, 3.0]        [0.0, 1.0, 2.0]\n",
       "1            [4.0, 5.0, 6.0, 7.0]        [4.0, 5.0, 6.0]\n",
       "2          [8.0, 9.0, 10.0, 11.0]       [8.0, 9.0, 10.0]\n",
       "3        [12.0, 13.0, 14.0, 15.0]     [12.0, 13.0, 14.0]\n",
       "4        [16.0, 17.0, 18.0, 19.0]     [16.0, 17.0, 18.0]\n",
       "..                            ...                    ...\n",
       "245  [980.0, 981.0, 982.0, 983.0]  [980.0, 981.0, 982.0]\n",
       "246  [984.0, 985.0, 986.0, 987.0]  [984.0, 985.0, 986.0]\n",
       "247  [988.0, 989.0, 990.0, 991.0]  [988.0, 989.0, 990.0]\n",
       "248  [992.0, 993.0, 994.0, 995.0]  [992.0, 993.0, 994.0]\n",
       "249  [996.0, 997.0, 998.0, 999.0]  [996.0, 997.0, 998.0]\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a000a092-e40b-4b96-8f12-b69466ca04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pdf_scalar['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f02ea27-6328-4df9-a1c6-2064c59c683c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3bdf79e-3d12-4c7c-b0ab-02845cc54d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = pdf_scalar['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf2523d-c210-4f02-a0cd-dbdacf571725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdf803d9-bfec-4448-9db6-e746d3e9bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(n=1):\n",
    "    for i in range(0, len(foo), n):\n",
    "        yield foo.iloc[i:i+n], bar.iloc[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9291afa-cb14-4e1e-867a-ac239a90c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0    0.0\n",
      "1    4.0\n",
      "Name: a, dtype: float64, 0    1.0\n",
      "1    5.0\n",
      "Name: b, dtype: float64)\n",
      "(2     8.0\n",
      "3    12.0\n",
      "Name: a, dtype: float64, 2     9.0\n",
      "3    13.0\n",
      "Name: b, dtype: float64)\n",
      "(4    16.0\n",
      "5    20.0\n",
      "Name: a, dtype: float64, 4    17.0\n",
      "5    21.0\n",
      "Name: b, dtype: float64)\n",
      "(6    24.0\n",
      "7    28.0\n",
      "Name: a, dtype: float64, 6    25.0\n",
      "7    29.0\n",
      "Name: b, dtype: float64)\n",
      "(8    32.0\n",
      "9    36.0\n",
      "Name: a, dtype: float64, 8    33.0\n",
      "9    37.0\n",
      "Name: b, dtype: float64)\n",
      "(10    40.0\n",
      "11    44.0\n",
      "Name: a, dtype: float64, 10    41.0\n",
      "11    45.0\n",
      "Name: b, dtype: float64)\n",
      "(12    48.0\n",
      "13    52.0\n",
      "Name: a, dtype: float64, 12    49.0\n",
      "13    53.0\n",
      "Name: b, dtype: float64)\n",
      "(14    56.0\n",
      "15    60.0\n",
      "Name: a, dtype: float64, 14    57.0\n",
      "15    61.0\n",
      "Name: b, dtype: float64)\n",
      "(16    64.0\n",
      "17    68.0\n",
      "Name: a, dtype: float64, 16    65.0\n",
      "17    69.0\n",
      "Name: b, dtype: float64)\n",
      "(18    72.0\n",
      "19    76.0\n",
      "Name: a, dtype: float64, 18    73.0\n",
      "19    77.0\n",
      "Name: b, dtype: float64)\n",
      "(20    80.0\n",
      "21    84.0\n",
      "Name: a, dtype: float64, 20    81.0\n",
      "21    85.0\n",
      "Name: b, dtype: float64)\n",
      "(22    88.0\n",
      "23    92.0\n",
      "Name: a, dtype: float64, 22    89.0\n",
      "23    93.0\n",
      "Name: b, dtype: float64)\n",
      "(24     96.0\n",
      "25    100.0\n",
      "Name: a, dtype: float64, 24     97.0\n",
      "25    101.0\n",
      "Name: b, dtype: float64)\n",
      "(26    104.0\n",
      "27    108.0\n",
      "Name: a, dtype: float64, 26    105.0\n",
      "27    109.0\n",
      "Name: b, dtype: float64)\n",
      "(28    112.0\n",
      "29    116.0\n",
      "Name: a, dtype: float64, 28    113.0\n",
      "29    117.0\n",
      "Name: b, dtype: float64)\n",
      "(30    120.0\n",
      "31    124.0\n",
      "Name: a, dtype: float64, 30    121.0\n",
      "31    125.0\n",
      "Name: b, dtype: float64)\n",
      "(32    128.0\n",
      "33    132.0\n",
      "Name: a, dtype: float64, 32    129.0\n",
      "33    133.0\n",
      "Name: b, dtype: float64)\n",
      "(34    136.0\n",
      "35    140.0\n",
      "Name: a, dtype: float64, 34    137.0\n",
      "35    141.0\n",
      "Name: b, dtype: float64)\n",
      "(36    144.0\n",
      "37    148.0\n",
      "Name: a, dtype: float64, 36    145.0\n",
      "37    149.0\n",
      "Name: b, dtype: float64)\n",
      "(38    152.0\n",
      "39    156.0\n",
      "Name: a, dtype: float64, 38    153.0\n",
      "39    157.0\n",
      "Name: b, dtype: float64)\n",
      "(40    160.0\n",
      "41    164.0\n",
      "Name: a, dtype: float64, 40    161.0\n",
      "41    165.0\n",
      "Name: b, dtype: float64)\n",
      "(42    168.0\n",
      "43    172.0\n",
      "Name: a, dtype: float64, 42    169.0\n",
      "43    173.0\n",
      "Name: b, dtype: float64)\n",
      "(44    176.0\n",
      "45    180.0\n",
      "Name: a, dtype: float64, 44    177.0\n",
      "45    181.0\n",
      "Name: b, dtype: float64)\n",
      "(46    184.0\n",
      "47    188.0\n",
      "Name: a, dtype: float64, 46    185.0\n",
      "47    189.0\n",
      "Name: b, dtype: float64)\n",
      "(48    192.0\n",
      "49    196.0\n",
      "Name: a, dtype: float64, 48    193.0\n",
      "49    197.0\n",
      "Name: b, dtype: float64)\n",
      "(50    200.0\n",
      "51    204.0\n",
      "Name: a, dtype: float64, 50    201.0\n",
      "51    205.0\n",
      "Name: b, dtype: float64)\n",
      "(52    208.0\n",
      "53    212.0\n",
      "Name: a, dtype: float64, 52    209.0\n",
      "53    213.0\n",
      "Name: b, dtype: float64)\n",
      "(54    216.0\n",
      "55    220.0\n",
      "Name: a, dtype: float64, 54    217.0\n",
      "55    221.0\n",
      "Name: b, dtype: float64)\n",
      "(56    224.0\n",
      "57    228.0\n",
      "Name: a, dtype: float64, 56    225.0\n",
      "57    229.0\n",
      "Name: b, dtype: float64)\n",
      "(58    232.0\n",
      "59    236.0\n",
      "Name: a, dtype: float64, 58    233.0\n",
      "59    237.0\n",
      "Name: b, dtype: float64)\n",
      "(60    240.0\n",
      "61    244.0\n",
      "Name: a, dtype: float64, 60    241.0\n",
      "61    245.0\n",
      "Name: b, dtype: float64)\n",
      "(62    248.0\n",
      "63    252.0\n",
      "Name: a, dtype: float64, 62    249.0\n",
      "63    253.0\n",
      "Name: b, dtype: float64)\n",
      "(64    256.0\n",
      "65    260.0\n",
      "Name: a, dtype: float64, 64    257.0\n",
      "65    261.0\n",
      "Name: b, dtype: float64)\n",
      "(66    264.0\n",
      "67    268.0\n",
      "Name: a, dtype: float64, 66    265.0\n",
      "67    269.0\n",
      "Name: b, dtype: float64)\n",
      "(68    272.0\n",
      "69    276.0\n",
      "Name: a, dtype: float64, 68    273.0\n",
      "69    277.0\n",
      "Name: b, dtype: float64)\n",
      "(70    280.0\n",
      "71    284.0\n",
      "Name: a, dtype: float64, 70    281.0\n",
      "71    285.0\n",
      "Name: b, dtype: float64)\n",
      "(72    288.0\n",
      "73    292.0\n",
      "Name: a, dtype: float64, 72    289.0\n",
      "73    293.0\n",
      "Name: b, dtype: float64)\n",
      "(74    296.0\n",
      "75    300.0\n",
      "Name: a, dtype: float64, 74    297.0\n",
      "75    301.0\n",
      "Name: b, dtype: float64)\n",
      "(76    304.0\n",
      "77    308.0\n",
      "Name: a, dtype: float64, 76    305.0\n",
      "77    309.0\n",
      "Name: b, dtype: float64)\n",
      "(78    312.0\n",
      "79    316.0\n",
      "Name: a, dtype: float64, 78    313.0\n",
      "79    317.0\n",
      "Name: b, dtype: float64)\n",
      "(80    320.0\n",
      "81    324.0\n",
      "Name: a, dtype: float64, 80    321.0\n",
      "81    325.0\n",
      "Name: b, dtype: float64)\n",
      "(82    328.0\n",
      "83    332.0\n",
      "Name: a, dtype: float64, 82    329.0\n",
      "83    333.0\n",
      "Name: b, dtype: float64)\n",
      "(84    336.0\n",
      "85    340.0\n",
      "Name: a, dtype: float64, 84    337.0\n",
      "85    341.0\n",
      "Name: b, dtype: float64)\n",
      "(86    344.0\n",
      "87    348.0\n",
      "Name: a, dtype: float64, 86    345.0\n",
      "87    349.0\n",
      "Name: b, dtype: float64)\n",
      "(88    352.0\n",
      "89    356.0\n",
      "Name: a, dtype: float64, 88    353.0\n",
      "89    357.0\n",
      "Name: b, dtype: float64)\n",
      "(90    360.0\n",
      "91    364.0\n",
      "Name: a, dtype: float64, 90    361.0\n",
      "91    365.0\n",
      "Name: b, dtype: float64)\n",
      "(92    368.0\n",
      "93    372.0\n",
      "Name: a, dtype: float64, 92    369.0\n",
      "93    373.0\n",
      "Name: b, dtype: float64)\n",
      "(94    376.0\n",
      "95    380.0\n",
      "Name: a, dtype: float64, 94    377.0\n",
      "95    381.0\n",
      "Name: b, dtype: float64)\n",
      "(96    384.0\n",
      "97    388.0\n",
      "Name: a, dtype: float64, 96    385.0\n",
      "97    389.0\n",
      "Name: b, dtype: float64)\n",
      "(98    392.0\n",
      "99    396.0\n",
      "Name: a, dtype: float64, 98    393.0\n",
      "99    397.0\n",
      "Name: b, dtype: float64)\n",
      "(100    400.0\n",
      "101    404.0\n",
      "Name: a, dtype: float64, 100    401.0\n",
      "101    405.0\n",
      "Name: b, dtype: float64)\n",
      "(102    408.0\n",
      "103    412.0\n",
      "Name: a, dtype: float64, 102    409.0\n",
      "103    413.0\n",
      "Name: b, dtype: float64)\n",
      "(104    416.0\n",
      "105    420.0\n",
      "Name: a, dtype: float64, 104    417.0\n",
      "105    421.0\n",
      "Name: b, dtype: float64)\n",
      "(106    424.0\n",
      "107    428.0\n",
      "Name: a, dtype: float64, 106    425.0\n",
      "107    429.0\n",
      "Name: b, dtype: float64)\n",
      "(108    432.0\n",
      "109    436.0\n",
      "Name: a, dtype: float64, 108    433.0\n",
      "109    437.0\n",
      "Name: b, dtype: float64)\n",
      "(110    440.0\n",
      "111    444.0\n",
      "Name: a, dtype: float64, 110    441.0\n",
      "111    445.0\n",
      "Name: b, dtype: float64)\n",
      "(112    448.0\n",
      "113    452.0\n",
      "Name: a, dtype: float64, 112    449.0\n",
      "113    453.0\n",
      "Name: b, dtype: float64)\n",
      "(114    456.0\n",
      "115    460.0\n",
      "Name: a, dtype: float64, 114    457.0\n",
      "115    461.0\n",
      "Name: b, dtype: float64)\n",
      "(116    464.0\n",
      "117    468.0\n",
      "Name: a, dtype: float64, 116    465.0\n",
      "117    469.0\n",
      "Name: b, dtype: float64)\n",
      "(118    472.0\n",
      "119    476.0\n",
      "Name: a, dtype: float64, 118    473.0\n",
      "119    477.0\n",
      "Name: b, dtype: float64)\n",
      "(120    480.0\n",
      "121    484.0\n",
      "Name: a, dtype: float64, 120    481.0\n",
      "121    485.0\n",
      "Name: b, dtype: float64)\n",
      "(122    488.0\n",
      "123    492.0\n",
      "Name: a, dtype: float64, 122    489.0\n",
      "123    493.0\n",
      "Name: b, dtype: float64)\n",
      "(124    496.0\n",
      "125    500.0\n",
      "Name: a, dtype: float64, 124    497.0\n",
      "125    501.0\n",
      "Name: b, dtype: float64)\n",
      "(126    504.0\n",
      "127    508.0\n",
      "Name: a, dtype: float64, 126    505.0\n",
      "127    509.0\n",
      "Name: b, dtype: float64)\n",
      "(128    512.0\n",
      "129    516.0\n",
      "Name: a, dtype: float64, 128    513.0\n",
      "129    517.0\n",
      "Name: b, dtype: float64)\n",
      "(130    520.0\n",
      "131    524.0\n",
      "Name: a, dtype: float64, 130    521.0\n",
      "131    525.0\n",
      "Name: b, dtype: float64)\n",
      "(132    528.0\n",
      "133    532.0\n",
      "Name: a, dtype: float64, 132    529.0\n",
      "133    533.0\n",
      "Name: b, dtype: float64)\n",
      "(134    536.0\n",
      "135    540.0\n",
      "Name: a, dtype: float64, 134    537.0\n",
      "135    541.0\n",
      "Name: b, dtype: float64)\n",
      "(136    544.0\n",
      "137    548.0\n",
      "Name: a, dtype: float64, 136    545.0\n",
      "137    549.0\n",
      "Name: b, dtype: float64)\n",
      "(138    552.0\n",
      "139    556.0\n",
      "Name: a, dtype: float64, 138    553.0\n",
      "139    557.0\n",
      "Name: b, dtype: float64)\n",
      "(140    560.0\n",
      "141    564.0\n",
      "Name: a, dtype: float64, 140    561.0\n",
      "141    565.0\n",
      "Name: b, dtype: float64)\n",
      "(142    568.0\n",
      "143    572.0\n",
      "Name: a, dtype: float64, 142    569.0\n",
      "143    573.0\n",
      "Name: b, dtype: float64)\n",
      "(144    576.0\n",
      "145    580.0\n",
      "Name: a, dtype: float64, 144    577.0\n",
      "145    581.0\n",
      "Name: b, dtype: float64)\n",
      "(146    584.0\n",
      "147    588.0\n",
      "Name: a, dtype: float64, 146    585.0\n",
      "147    589.0\n",
      "Name: b, dtype: float64)\n",
      "(148    592.0\n",
      "149    596.0\n",
      "Name: a, dtype: float64, 148    593.0\n",
      "149    597.0\n",
      "Name: b, dtype: float64)\n",
      "(150    600.0\n",
      "151    604.0\n",
      "Name: a, dtype: float64, 150    601.0\n",
      "151    605.0\n",
      "Name: b, dtype: float64)\n",
      "(152    608.0\n",
      "153    612.0\n",
      "Name: a, dtype: float64, 152    609.0\n",
      "153    613.0\n",
      "Name: b, dtype: float64)\n",
      "(154    616.0\n",
      "155    620.0\n",
      "Name: a, dtype: float64, 154    617.0\n",
      "155    621.0\n",
      "Name: b, dtype: float64)\n",
      "(156    624.0\n",
      "157    628.0\n",
      "Name: a, dtype: float64, 156    625.0\n",
      "157    629.0\n",
      "Name: b, dtype: float64)\n",
      "(158    632.0\n",
      "159    636.0\n",
      "Name: a, dtype: float64, 158    633.0\n",
      "159    637.0\n",
      "Name: b, dtype: float64)\n",
      "(160    640.0\n",
      "161    644.0\n",
      "Name: a, dtype: float64, 160    641.0\n",
      "161    645.0\n",
      "Name: b, dtype: float64)\n",
      "(162    648.0\n",
      "163    652.0\n",
      "Name: a, dtype: float64, 162    649.0\n",
      "163    653.0\n",
      "Name: b, dtype: float64)\n",
      "(164    656.0\n",
      "165    660.0\n",
      "Name: a, dtype: float64, 164    657.0\n",
      "165    661.0\n",
      "Name: b, dtype: float64)\n",
      "(166    664.0\n",
      "167    668.0\n",
      "Name: a, dtype: float64, 166    665.0\n",
      "167    669.0\n",
      "Name: b, dtype: float64)\n",
      "(168    672.0\n",
      "169    676.0\n",
      "Name: a, dtype: float64, 168    673.0\n",
      "169    677.0\n",
      "Name: b, dtype: float64)\n",
      "(170    680.0\n",
      "171    684.0\n",
      "Name: a, dtype: float64, 170    681.0\n",
      "171    685.0\n",
      "Name: b, dtype: float64)\n",
      "(172    688.0\n",
      "173    692.0\n",
      "Name: a, dtype: float64, 172    689.0\n",
      "173    693.0\n",
      "Name: b, dtype: float64)\n",
      "(174    696.0\n",
      "175    700.0\n",
      "Name: a, dtype: float64, 174    697.0\n",
      "175    701.0\n",
      "Name: b, dtype: float64)\n",
      "(176    704.0\n",
      "177    708.0\n",
      "Name: a, dtype: float64, 176    705.0\n",
      "177    709.0\n",
      "Name: b, dtype: float64)\n",
      "(178    712.0\n",
      "179    716.0\n",
      "Name: a, dtype: float64, 178    713.0\n",
      "179    717.0\n",
      "Name: b, dtype: float64)\n",
      "(180    720.0\n",
      "181    724.0\n",
      "Name: a, dtype: float64, 180    721.0\n",
      "181    725.0\n",
      "Name: b, dtype: float64)\n",
      "(182    728.0\n",
      "183    732.0\n",
      "Name: a, dtype: float64, 182    729.0\n",
      "183    733.0\n",
      "Name: b, dtype: float64)\n",
      "(184    736.0\n",
      "185    740.0\n",
      "Name: a, dtype: float64, 184    737.0\n",
      "185    741.0\n",
      "Name: b, dtype: float64)\n",
      "(186    744.0\n",
      "187    748.0\n",
      "Name: a, dtype: float64, 186    745.0\n",
      "187    749.0\n",
      "Name: b, dtype: float64)\n",
      "(188    752.0\n",
      "189    756.0\n",
      "Name: a, dtype: float64, 188    753.0\n",
      "189    757.0\n",
      "Name: b, dtype: float64)\n",
      "(190    760.0\n",
      "191    764.0\n",
      "Name: a, dtype: float64, 190    761.0\n",
      "191    765.0\n",
      "Name: b, dtype: float64)\n",
      "(192    768.0\n",
      "193    772.0\n",
      "Name: a, dtype: float64, 192    769.0\n",
      "193    773.0\n",
      "Name: b, dtype: float64)\n",
      "(194    776.0\n",
      "195    780.0\n",
      "Name: a, dtype: float64, 194    777.0\n",
      "195    781.0\n",
      "Name: b, dtype: float64)\n",
      "(196    784.0\n",
      "197    788.0\n",
      "Name: a, dtype: float64, 196    785.0\n",
      "197    789.0\n",
      "Name: b, dtype: float64)\n",
      "(198    792.0\n",
      "199    796.0\n",
      "Name: a, dtype: float64, 198    793.0\n",
      "199    797.0\n",
      "Name: b, dtype: float64)\n",
      "(200    800.0\n",
      "201    804.0\n",
      "Name: a, dtype: float64, 200    801.0\n",
      "201    805.0\n",
      "Name: b, dtype: float64)\n",
      "(202    808.0\n",
      "203    812.0\n",
      "Name: a, dtype: float64, 202    809.0\n",
      "203    813.0\n",
      "Name: b, dtype: float64)\n",
      "(204    816.0\n",
      "205    820.0\n",
      "Name: a, dtype: float64, 204    817.0\n",
      "205    821.0\n",
      "Name: b, dtype: float64)\n",
      "(206    824.0\n",
      "207    828.0\n",
      "Name: a, dtype: float64, 206    825.0\n",
      "207    829.0\n",
      "Name: b, dtype: float64)\n",
      "(208    832.0\n",
      "209    836.0\n",
      "Name: a, dtype: float64, 208    833.0\n",
      "209    837.0\n",
      "Name: b, dtype: float64)\n",
      "(210    840.0\n",
      "211    844.0\n",
      "Name: a, dtype: float64, 210    841.0\n",
      "211    845.0\n",
      "Name: b, dtype: float64)\n",
      "(212    848.0\n",
      "213    852.0\n",
      "Name: a, dtype: float64, 212    849.0\n",
      "213    853.0\n",
      "Name: b, dtype: float64)\n",
      "(214    856.0\n",
      "215    860.0\n",
      "Name: a, dtype: float64, 214    857.0\n",
      "215    861.0\n",
      "Name: b, dtype: float64)\n",
      "(216    864.0\n",
      "217    868.0\n",
      "Name: a, dtype: float64, 216    865.0\n",
      "217    869.0\n",
      "Name: b, dtype: float64)\n",
      "(218    872.0\n",
      "219    876.0\n",
      "Name: a, dtype: float64, 218    873.0\n",
      "219    877.0\n",
      "Name: b, dtype: float64)\n",
      "(220    880.0\n",
      "221    884.0\n",
      "Name: a, dtype: float64, 220    881.0\n",
      "221    885.0\n",
      "Name: b, dtype: float64)\n",
      "(222    888.0\n",
      "223    892.0\n",
      "Name: a, dtype: float64, 222    889.0\n",
      "223    893.0\n",
      "Name: b, dtype: float64)\n",
      "(224    896.0\n",
      "225    900.0\n",
      "Name: a, dtype: float64, 224    897.0\n",
      "225    901.0\n",
      "Name: b, dtype: float64)\n",
      "(226    904.0\n",
      "227    908.0\n",
      "Name: a, dtype: float64, 226    905.0\n",
      "227    909.0\n",
      "Name: b, dtype: float64)\n",
      "(228    912.0\n",
      "229    916.0\n",
      "Name: a, dtype: float64, 228    913.0\n",
      "229    917.0\n",
      "Name: b, dtype: float64)\n",
      "(230    920.0\n",
      "231    924.0\n",
      "Name: a, dtype: float64, 230    921.0\n",
      "231    925.0\n",
      "Name: b, dtype: float64)\n",
      "(232    928.0\n",
      "233    932.0\n",
      "Name: a, dtype: float64, 232    929.0\n",
      "233    933.0\n",
      "Name: b, dtype: float64)\n",
      "(234    936.0\n",
      "235    940.0\n",
      "Name: a, dtype: float64, 234    937.0\n",
      "235    941.0\n",
      "Name: b, dtype: float64)\n",
      "(236    944.0\n",
      "237    948.0\n",
      "Name: a, dtype: float64, 236    945.0\n",
      "237    949.0\n",
      "Name: b, dtype: float64)\n",
      "(238    952.0\n",
      "239    956.0\n",
      "Name: a, dtype: float64, 238    953.0\n",
      "239    957.0\n",
      "Name: b, dtype: float64)\n",
      "(240    960.0\n",
      "241    964.0\n",
      "Name: a, dtype: float64, 240    961.0\n",
      "241    965.0\n",
      "Name: b, dtype: float64)\n",
      "(242    968.0\n",
      "243    972.0\n",
      "Name: a, dtype: float64, 242    969.0\n",
      "243    973.0\n",
      "Name: b, dtype: float64)\n",
      "(244    976.0\n",
      "245    980.0\n",
      "Name: a, dtype: float64, 244    977.0\n",
      "245    981.0\n",
      "Name: b, dtype: float64)\n",
      "(246    984.0\n",
      "247    988.0\n",
      "Name: a, dtype: float64, 246    985.0\n",
      "247    989.0\n",
      "Name: b, dtype: float64)\n",
      "(248    992.0\n",
      "249    996.0\n",
      "Name: a, dtype: float64, 248    993.0\n",
      "249    997.0\n",
      "Name: b, dtype: float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "for x in batch(2):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec6f74b-e0fe-4b2a-81ed-5087b1cbfc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baz = pd.concat((foo,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1904b4a8-f9d9-4624-b74b-4277699ede7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        4.0\n",
       "2        8.0\n",
       "3       12.0\n",
       "4       16.0\n",
       "       ...  \n",
       "245    980.0\n",
       "246    984.0\n",
       "247    988.0\n",
       "248    992.0\n",
       "249    996.0\n",
       "Name: a, Length: 250, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baz.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a3526ba-b66a-4425-b270-025d4c67df55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.],\n",
       "       [  4.],\n",
       "       [  8.],\n",
       "       [ 12.],\n",
       "       [ 16.],\n",
       "       [ 20.],\n",
       "       [ 24.],\n",
       "       [ 28.],\n",
       "       [ 32.],\n",
       "       [ 36.],\n",
       "       [ 40.],\n",
       "       [ 44.],\n",
       "       [ 48.],\n",
       "       [ 52.],\n",
       "       [ 56.],\n",
       "       [ 60.],\n",
       "       [ 64.],\n",
       "       [ 68.],\n",
       "       [ 72.],\n",
       "       [ 76.],\n",
       "       [ 80.],\n",
       "       [ 84.],\n",
       "       [ 88.],\n",
       "       [ 92.],\n",
       "       [ 96.],\n",
       "       [100.],\n",
       "       [104.],\n",
       "       [108.],\n",
       "       [112.],\n",
       "       [116.],\n",
       "       [120.],\n",
       "       [124.],\n",
       "       [128.],\n",
       "       [132.],\n",
       "       [136.],\n",
       "       [140.],\n",
       "       [144.],\n",
       "       [148.],\n",
       "       [152.],\n",
       "       [156.],\n",
       "       [160.],\n",
       "       [164.],\n",
       "       [168.],\n",
       "       [172.],\n",
       "       [176.],\n",
       "       [180.],\n",
       "       [184.],\n",
       "       [188.],\n",
       "       [192.],\n",
       "       [196.],\n",
       "       [200.],\n",
       "       [204.],\n",
       "       [208.],\n",
       "       [212.],\n",
       "       [216.],\n",
       "       [220.],\n",
       "       [224.],\n",
       "       [228.],\n",
       "       [232.],\n",
       "       [236.],\n",
       "       [240.],\n",
       "       [244.],\n",
       "       [248.],\n",
       "       [252.],\n",
       "       [256.],\n",
       "       [260.],\n",
       "       [264.],\n",
       "       [268.],\n",
       "       [272.],\n",
       "       [276.],\n",
       "       [280.],\n",
       "       [284.],\n",
       "       [288.],\n",
       "       [292.],\n",
       "       [296.],\n",
       "       [300.],\n",
       "       [304.],\n",
       "       [308.],\n",
       "       [312.],\n",
       "       [316.],\n",
       "       [320.],\n",
       "       [324.],\n",
       "       [328.],\n",
       "       [332.],\n",
       "       [336.],\n",
       "       [340.],\n",
       "       [344.],\n",
       "       [348.],\n",
       "       [352.],\n",
       "       [356.],\n",
       "       [360.],\n",
       "       [364.],\n",
       "       [368.],\n",
       "       [372.],\n",
       "       [376.],\n",
       "       [380.],\n",
       "       [384.],\n",
       "       [388.],\n",
       "       [392.],\n",
       "       [396.],\n",
       "       [400.],\n",
       "       [404.],\n",
       "       [408.],\n",
       "       [412.],\n",
       "       [416.],\n",
       "       [420.],\n",
       "       [424.],\n",
       "       [428.],\n",
       "       [432.],\n",
       "       [436.],\n",
       "       [440.],\n",
       "       [444.],\n",
       "       [448.],\n",
       "       [452.],\n",
       "       [456.],\n",
       "       [460.],\n",
       "       [464.],\n",
       "       [468.],\n",
       "       [472.],\n",
       "       [476.],\n",
       "       [480.],\n",
       "       [484.],\n",
       "       [488.],\n",
       "       [492.],\n",
       "       [496.],\n",
       "       [500.],\n",
       "       [504.],\n",
       "       [508.],\n",
       "       [512.],\n",
       "       [516.],\n",
       "       [520.],\n",
       "       [524.],\n",
       "       [528.],\n",
       "       [532.],\n",
       "       [536.],\n",
       "       [540.],\n",
       "       [544.],\n",
       "       [548.],\n",
       "       [552.],\n",
       "       [556.],\n",
       "       [560.],\n",
       "       [564.],\n",
       "       [568.],\n",
       "       [572.],\n",
       "       [576.],\n",
       "       [580.],\n",
       "       [584.],\n",
       "       [588.],\n",
       "       [592.],\n",
       "       [596.],\n",
       "       [600.],\n",
       "       [604.],\n",
       "       [608.],\n",
       "       [612.],\n",
       "       [616.],\n",
       "       [620.],\n",
       "       [624.],\n",
       "       [628.],\n",
       "       [632.],\n",
       "       [636.],\n",
       "       [640.],\n",
       "       [644.],\n",
       "       [648.],\n",
       "       [652.],\n",
       "       [656.],\n",
       "       [660.],\n",
       "       [664.],\n",
       "       [668.],\n",
       "       [672.],\n",
       "       [676.],\n",
       "       [680.],\n",
       "       [684.],\n",
       "       [688.],\n",
       "       [692.],\n",
       "       [696.],\n",
       "       [700.],\n",
       "       [704.],\n",
       "       [708.],\n",
       "       [712.],\n",
       "       [716.],\n",
       "       [720.],\n",
       "       [724.],\n",
       "       [728.],\n",
       "       [732.],\n",
       "       [736.],\n",
       "       [740.],\n",
       "       [744.],\n",
       "       [748.],\n",
       "       [752.],\n",
       "       [756.],\n",
       "       [760.],\n",
       "       [764.],\n",
       "       [768.],\n",
       "       [772.],\n",
       "       [776.],\n",
       "       [780.],\n",
       "       [784.],\n",
       "       [788.],\n",
       "       [792.],\n",
       "       [796.],\n",
       "       [800.],\n",
       "       [804.],\n",
       "       [808.],\n",
       "       [812.],\n",
       "       [816.],\n",
       "       [820.],\n",
       "       [824.],\n",
       "       [828.],\n",
       "       [832.],\n",
       "       [836.],\n",
       "       [840.],\n",
       "       [844.],\n",
       "       [848.],\n",
       "       [852.],\n",
       "       [856.],\n",
       "       [860.],\n",
       "       [864.],\n",
       "       [868.],\n",
       "       [872.],\n",
       "       [876.],\n",
       "       [880.],\n",
       "       [884.],\n",
       "       [888.],\n",
       "       [892.],\n",
       "       [896.],\n",
       "       [900.],\n",
       "       [904.],\n",
       "       [908.],\n",
       "       [912.],\n",
       "       [916.],\n",
       "       [920.],\n",
       "       [924.],\n",
       "       [928.],\n",
       "       [932.],\n",
       "       [936.],\n",
       "       [940.],\n",
       "       [944.],\n",
       "       [948.],\n",
       "       [952.],\n",
       "       [956.],\n",
       "       [960.],\n",
       "       [964.],\n",
       "       [968.],\n",
       "       [972.],\n",
       "       [976.],\n",
       "       [980.],\n",
       "       [984.],\n",
       "       [988.],\n",
       "       [992.],\n",
       "       [996.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baz.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e123983-6dba-4982-80dd-18e6a5620e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fa1ce6c-cdeb-4038-8ed9-2342d271b3a4",
   "metadata": {},
   "source": [
    "### spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69d10c-2c7f-485b-9610-bdfa3bd22e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e972fc7-4704-4851-93f0-697cafb058ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658892b-d0ee-49fa-8d0d-06c1d96f70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8bf27-59b2-4828-a842-b03fbc7cd260",
   "metadata": {},
   "source": [
    "### spark partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada81fd-e88c-4f2f-807b-b827ae804b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id\n",
    "df.withColumn(\"partition_id\", spark_partition_id()).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad360fb-c816-4026-b906-3d0d95ef454d",
   "metadata": {},
   "source": [
    "## Test tensor columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b577952-9edc-4463-bc2c-71b29d125d4c",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8a15f-81ad-467f-906c-706b68e19837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175304f0-b76d-4301-b21c-2c4b4298c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_tensor2.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e4086-04c9-47a4-b470-2a1abfea15ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e30d7a-9143-46ca-bc0f-1f3c1a158da8",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=ArrayType(DoubleType()) | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa8b0f-b9c4-4565-9efa-e0b204b8827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c9d84-87d4-4efd-bfaf-3ec3ca6760ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=ArrayType(DoubleType()))\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9ac9e-3bc7-4668-befa-7f7507afe07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21161bb-277f-4cb8-86b4-da54d0adba09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pDF -> pS | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2bbf9-55e1-42eb-bcbd-cc5c4e3be058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd3d73-3e09-4803-b3cd-4c4bebf54f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_tensor2.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d4bfa-44ef-40bd-a2cb-c559e2123a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ef869-d875-4664-8d79-98200ffad5c0",
   "metadata": {},
   "source": [
    "### pDF -> pS | returnType=ArrayType(DoubleType()) | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b651bd-977c-47d9-ae24-5e50fd40aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a0187-e1bb-4eaa-adcd-2e38fe4d2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=ArrayType(DoubleType()))\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c65670-b50e-44db-8a05-4da71ced8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_tensor2.columns\n",
    "preds = df_tensor2.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754200f4-00c7-433e-91dc-fc78c012d513",
   "metadata": {},
   "source": [
    "### Union[pDF, pS] -> Union[pDF, pS] | returnType=StructType() | return pS => FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd79653-af9b-402c-8593-66fabf8a9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensor2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3089081-0ea4-4b18-8560-beb0d946e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_tensor2.schema)\n",
    "# def predict(inputs: Iterator[Union[pd.DataFrame, pd.Series]]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "# def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "# def predict(inputs: Iterator[pd.Series]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f0f1f-8f2f-45f5-9f1a-3275ccafb57e",
   "metadata": {},
   "source": [
    "## Test scalar columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0d3ca-69dc-4e2d-bbcc-ed1d37e831f2",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc79165-ce6b-489a-a56c-71169e2290be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1510180-016c-4a56-9427-25b437ad3a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_scalar.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722dee2-ecc9-4f5a-8e3c-7dba759a7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ad717-87a4-44a8-87c8-b01302143c29",
   "metadata": {},
   "source": [
    "### pDF -> pDF | returnType=DoubleType() | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f043b8-9755-4fe7-bb42-18eae5452d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916afdf-8f38-4fd0-8dfa-3f898174a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=DoubleType())\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d655206-ca3e-4a5c-a337-38f90213d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc1abd-933e-4571-a735-c26ccf6e8d19",
   "metadata": {},
   "source": [
    "### pDF -> pS | returnType=StructType | return pDF => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da96e84-94c8-4c99-8831-544e855c7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7a314-f511-42f0-aff5-cc5a894b6f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_scalar.schema)\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babeda32-112d-4d6d-89fb-8f7ad24bc4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e69ae2-0802-40d5-8d8c-918b8c1b6457",
   "metadata": {},
   "source": [
    "### pDF -> pS | returnType=DoubleType() | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead95954-f7a3-48e7-bd44-15d3b2a3d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7564de-9a76-474a-9666-6b7d875b17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=DoubleType())\n",
    "def predict(inputs: Iterator[pd.DataFrame]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d0f75-25d9-418e-9487-d7a8befc890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(struct(*columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa8769-8a26-4cdd-9728-c304874c1b2f",
   "metadata": {},
   "source": [
    "### Union[pDF, pS] -> Union[pDF, pS] | returnType=StructType) | return pS => FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dcc5c-b4c1-49e2-889f-87ab6037442d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=df_scalar.schema)\n",
    "def predict(inputs: Iterator[Union[pd.DataFrame, pd.Series]]) -> Iterator[Union[pd.DataFrame, pd.Series]]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717ffa6-110c-4881-8c23-e69b16974609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341934d-625f-4f71-85bf-350a290275f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "from pyspark.sql.pandas.typehints import infer_eval_type\n",
    "from typing import get_type_hints, Any, Callable, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b8f77-a22b-4377-bae0-79a99eb92386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_iterator_annotation(\n",
    "    annotation: Any, parameter_check_func: Optional[Callable[[Any], bool]] = None\n",
    ") -> bool:\n",
    "    name = getattr(annotation, \"_name\", getattr(annotation, \"__name__\", None))\n",
    "    return name == \"Iterator\" and (\n",
    "        parameter_check_func is None or all(map(parameter_check_func, annotation.__args__))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357203ee-f2ad-47c8-bed1-b0f0dc14caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_union_annotation(\n",
    "    annotation: Any, parameter_check_func: Optional[Callable[[Any], bool]] = None\n",
    ") -> bool:\n",
    "    import typing\n",
    "\n",
    "    # Note that we cannot rely on '__origin__' in other type hints as it has changed from version\n",
    "    # to version. For example, it's abc.Iterator in Python 3.7 but typing.Iterator in Python 3.6.\n",
    "    origin = getattr(annotation, \"__origin__\", None)\n",
    "    return origin == typing.Union and (\n",
    "        parameter_check_func is None or all(map(parameter_check_func, annotation.__args__))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33785c-39a2-4495-842b-08885d6b5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tuple_annotation(\n",
    "    annotation: Any, parameter_check_func: Optional[Callable[[Any], bool]] = None\n",
    ") -> bool:\n",
    "    # Tuple has _name but other types have __name__\n",
    "    # Check if the name is Tuple first. After that, check the generic types.\n",
    "    name = getattr(annotation, \"_name\", getattr(annotation, \"__name__\", None))\n",
    "    return name == \"Tuple\" and (\n",
    "        parameter_check_func is None or all(map(parameter_check_func, annotation.__args__))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab214bb-8e14-4b63-b3a7-294f86c75c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: Iterator[Union[pd.Series, pd.DataFrame]]) -> Iterator[pd.DataFrame]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd7ca3-afee-4546-a0b4-c05f786d4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = signature(predict)\n",
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f075a-38b0-4475-b0e9-5da48a337a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_hints = get_type_hints(predict)\n",
    "type_hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4066b-1ea0-49e6-9591-a29ef46febee",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {}\n",
    "for param in sig.parameters.values():\n",
    "    if param.annotation is not param.empty:\n",
    "        annotations[param.name] = type_hints.get(param.name, param.annotation)\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce3e70-3a83-418a-b062-19e683994850",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sig = [\n",
    "    annotations[parameter] for parameter in sig.parameters if parameter in annotations]\n",
    "parameters_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe5863-75a4-40ac-9ddd-fb84230cdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_annotation = type_hints.get(\"return\", sig.return_annotation)\n",
    "return_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857dda63-60ed-4bda-b852-9618e4a52826",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_series_or_frame = all(\n",
    "    a == pd.Series\n",
    "    or a == pd.DataFrame  # Series\n",
    "    or check_union_annotation(  # DataFrame  # Union[DataFrame, Series]\n",
    "        a, parameter_check_func=lambda na: na == pd.Series or na == pd.DataFrame\n",
    "    )\n",
    "    for a in parameters_sig\n",
    ") and (return_annotation == pd.Series or return_annotation == pd.DataFrame)\n",
    "is_series_or_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e74b04-8bcb-423b-82ec-6f50ed11321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_iterator_tuple_series_or_frame = (\n",
    "    len(parameters_sig) == 1\n",
    "    and check_iterator_annotation(  # Iterator\n",
    "        parameters_sig[0],\n",
    "        parameter_check_func=lambda a: check_tuple_annotation(  # Tuple\n",
    "            a,\n",
    "            parameter_check_func=lambda ta: (\n",
    "                ta == Ellipsis\n",
    "                or ta == pd.Series  # ...\n",
    "                or ta == pd.DataFrame  # Series\n",
    "                or check_union_annotation(  # DataFrame  # Union[DataFrame, Series]\n",
    "                    ta, parameter_check_func=lambda na: (na == pd.Series or na == pd.DataFrame)\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    and check_iterator_annotation(\n",
    "        return_annotation, parameter_check_func=lambda a: a == pd.DataFrame or a == pd.Series\n",
    "    )\n",
    ")\n",
    "is_iterator_tuple_series_or_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a17191-d9f6-4de9-b6dd-5ec13e2d8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_iterator_series_or_frame = (\n",
    "    len(parameters_sig) == 1\n",
    "    and check_iterator_annotation(\n",
    "        parameters_sig[0],\n",
    "        parameter_check_func=lambda a: (\n",
    "            a == pd.Series\n",
    "            or a == pd.DataFrame  # Series\n",
    "            or check_union_annotation(  # DataFrame  # Union[DataFrame, Series]\n",
    "                a, parameter_check_func=lambda ua: ua == pd.Series or ua == pd.DataFrame\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    and check_iterator_annotation(\n",
    "        return_annotation, parameter_check_func=lambda a: a == pd.DataFrame or a == pd.Series\n",
    "    )\n",
    ")\n",
    "is_iterator_series_or_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bac7e8-2c6d-4702-842d-b396f00f98d9",
   "metadata": {},
   "source": [
    "### pS -> pS | returnType=ArrayType(DoubleType()) | return pS => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a724d0-91d4-431c-b370-23306cfbce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029256e6-8320-4dad-91cf-01e6db08493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93759c1e-83f8-4d17-a4ac-90a5d58c3957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=ArrayType(DoubleType()))\n",
    "def predict(inputs: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    for batch in inputs:\n",
    "        print(\"===== batch: {}\".format(type(batch)))\n",
    "        print(\"===== len(batch: {}\".format(len(batch)))\n",
    "        # print(\"===== batch.columns: {}\".format(batch.columns))\n",
    "        # print(\"===== batch.dtypes:\\n{}\".format(batch.dtypes))\n",
    "        print(\"===== batch[0]:\\n{}\".format(batch[0]))\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f08667-baa0-48f3-b6a1-4006d4d8e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_scalar.columns\n",
    "preds = df_scalar.withColumn(\"preds\", predict(array(columns))).toPandas()\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c172c-6462-4226-843e-59905c5e3941",
   "metadata": {},
   "source": [
    "## Test caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae1db9-8ab6-4985-8d7c-4684da85f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from pyspark.ml.functions import batch_infer_udf\n",
    "from pyspark.sql.functions import struct, pandas_udf\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129f2b5-c3da-4cf4-8b22-fdf9d4a158e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "\n",
    "# 4 scalar columns\n",
    "pdf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7dc28-3246-4ead-b76b-442a792f9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    # emulate loading a model, this should only be invoked once (per worker process)\n",
    "    fake_output = np.random.random()\n",
    "\n",
    "    def predict(inputs):\n",
    "        return [fake_output for i in inputs]\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221a5af-5060-46ee-adc3-d25b457023bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = batch_infer_udf(predict_batch_fn, return_type=DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd887b1-bbca-4a7f-ad3e-fa1e458d41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# results should be the same\n",
    "df1 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952c941-125e-442b-8c22-d82f6e0957d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793aa60a-d1f7-4234-b21e-84c37e1155cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6e8f2-12fc-4069-bb1d-5fba62e4c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79589fbe-ac5a-40c5-bf07-c0341c1818dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = df.withColumn(\"preds\", identity(struct(\"a\"))).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc851cbd-bfe4-4d62-bb24-389610ebb7ff",
   "metadata": {},
   "source": [
    "## Test executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb93652-3adf-419e-bd05-a0695932afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from pyspark.ml.functions import batch_infer_udf\n",
    "from pyspark.sql.functions import struct, pandas_udf\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d3b4f-726c-4d82-855c-afaf5670a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "\n",
    "# 4 scalar columns\n",
    "pdf = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe89306-d7fa-4bb7-8657-3b34212b6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfn(it):\n",
    "    import tensorflow as tf\n",
    "    print(\">>>> {}\".format(tf.__version__))\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "    # Create some tensors\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52acb13-205b-478c-abb9-8283b99475c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.foreachPartition(myfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9112497-f078-4eeb-b220-a052a326b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(returnType=FloatType())\n",
    "def myudf(it: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for part in it:\n",
    "        import tensorflow as tf\n",
    "        print(tf.__version__)\n",
    "        yield part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d53a7b-02df-4820-b5b1-72258b2f429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = df.withColumn(\"preds\", struct(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f40c5b-36fe-472e-9ec6-9b49cc2785cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67dc70-b052-4b39-a3a3-3cdb49ce6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== df1:\\n{}\".format(df1))\n",
    "print(\"==== df2:\\n{}\".format(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0fe5b-4936-4dbe-911b-6b22838d0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id\n",
    "df.withColumn(\"partition_id\", spark_partition_id()).withColumn(\"preds\", identity(struct(\"a\"))).groupBy(\"partition_id\", \"preds\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c3115-3e7f-4ca3-b26a-7b053812c09e",
   "metadata": {},
   "source": [
    "## Test zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c7d410-8151-40eb-a82a-333f04204292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7a992a7-1771-41d3-8068-2cb86d03bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.Series([0,1,2,3,4,5,6,7,8])\n",
    "bar = pd.Series(['a','b','c','d','e','f','g','h','i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fe40800-65b0-4ff2-87ec-22d0ad3c9131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0\n",
       " 1    1\n",
       " 2    2\n",
       " 3    3\n",
       " 4    4\n",
       " 5    5\n",
       " 6    6\n",
       " 7    7\n",
       " 8    8\n",
       " dtype: int64,\n",
       " 0    a\n",
       " 1    b\n",
       " 2    c\n",
       " 3    d\n",
       " 4    e\n",
       " 5    f\n",
       " 6    g\n",
       " 7    h\n",
       " 8    i\n",
       " dtype: object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = (foo, bar)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "887736f7-9733-4a19-ae7a-71a93d33cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, batch_size):\n",
    "    acc = []\n",
    "    for i, x in enumerate(zip(*iterable)):\n",
    "        acc += x\n",
    "        if i % batch_size == 0:\n",
    "            yield acc\n",
    "            acc = []\n",
    "    yield acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "577f4821-2209-4dcd-9361-794aa7ec48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import more_itertools\n",
    "\n",
    "def batch(iterable, batch_size):\n",
    "    for x in more_itertools.chunked(zip(*iterable), batch_size):\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6f9ecfb-0859-4f4d-b618-33e694c8589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'a'), (1, 'b')]\n",
      "====\n",
      "[(2, 'c'), (3, 'd')]\n",
      "====\n",
      "[(4, 'e'), (5, 'f')]\n",
      "====\n",
      "[(6, 'g'), (7, 'h')]\n",
      "====\n",
      "[(8, 'i')]\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "for x in batch(test, 2):\n",
    "    print(x)\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39599309-4dfe-402f-8957-feceeb03422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.concat(test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4d00ab4-ed45-492c-9481-18c9526cac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  a\n",
       "1  1  b\n",
       "2  2  c\n",
       "3  3  d\n",
       "4  4  e\n",
       "5  5  f\n",
       "6  6  g\n",
       "7  7  h\n",
       "8  8  i"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "/home/leey/devpub/leewyang/spark/python/pyspark/context.py:642: RuntimeWarning: Unable to cleanly shutdown Spark JVM process. It is possible that the process has crashed, been killed or may also be in a zombie state.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c0ab7-e335-4179-ab73-057e376291c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
