{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792a56d6-0ea6-4e8f-bef9-b578c0abec41",
   "metadata": {},
   "source": [
    "# Pyspark TensorFlow Training\n",
    "\n",
    "Based on: https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8bb4d-48f3-4cb7-a111-7ba34489f2e0",
   "metadata": {},
   "source": [
    "## Single Node Training on Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b28f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 16:09:57.401409: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe275a3-9e5b-4e2d-bcaa-3829a441bf9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b007f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset as numpy arrays\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7cedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten and normalize\n",
    "train_images = train_images.reshape(-1, 784) / 255.0\n",
    "test_images = test_images.reshape(-1, 784) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77bfbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be729464-029e-4534-b8c3-e44e57ef9e0b",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746d94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 16:09:59.431796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1922] Ignoring visible gpu device (device: 1, name: Quadro P620, pci bus id: 0000:65:00.0, compute capability: 6.1) with core count: 4. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2023-01-05 16:09:59.432350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 16:09:59.794436: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-01-05 16:09:59.794476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22344 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ddd55-21bd-4ff9-94f9-3a5d70977c6a",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244746be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  44/1875 [..............................] - ETA: 6s - loss: 1.0386 - sparse_categorical_accuracy: 0.6918 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 16:10:01.020358: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2174 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9691\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.0867 - val_sparse_categorical_accuracy: 0.9725\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0712 - val_sparse_categorical_accuracy: 0.9782\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0635 - val_sparse_categorical_accuracy: 0.9801\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.0620 - val_sparse_categorical_accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe2c4c5760>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=5,\n",
    "          validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d3bba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -5.797349 ,  -7.324735 ,  -4.530537 ,  -1.59399  , -14.33293  ,\n",
       "         -8.626202 , -16.838335 ,  12.26039  ,  -6.1140094,  -1.9424609]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = test_images[:1]\n",
    "model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e700b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(test_img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6881a2-1cde-4be1-bfbe-437ec19faeb0",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f11a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"rm -rf mnist_model\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f9376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1d6fe-b9a4-4839-9795-54ec1cf5d32d",
   "metadata": {},
   "source": [
    "## Distributed Training on executors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee3efb7-c54c-4144-8d4d-fd2bfd25359d",
   "metadata": {},
   "source": [
    "### Save dataset as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0c48ba-054a-4078-a740-9c4765fe558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf_784 = pd.DataFrame(train_images)\n",
    "pdf_labels = pd.DataFrame(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd6d62c-36d2-4448-9a1e-d29b528bf808",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_train = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f091859-0279-47fe-a80f-e7b31052ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_train['image'] = pdf_784.values.tolist()\n",
    "pdf_train['label'] = pdf_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "233a3335-a9ad-4406-8d09-89daf3f6f200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  label\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      5\n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0\n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      4\n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1\n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      9\n",
       "...                                                  ...    ...\n",
       "59995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      8\n",
       "59996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      3\n",
       "59997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      5\n",
       "59998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      6\n",
       "59999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      8\n",
       "\n",
       "[60000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "869d07a2-83bb-453b-bc1a-1e6626ad23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.createDataFrame(pdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72391755-7f84-46b8-a4e9-d8678cfd1c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/05 16:12:04 WARN TaskSetManager: Stage 0 contains a task of very large size (21199 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train.write.mode(\"overwrite\").parquet(\"mnist_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3514c5b-836a-4f4e-92af-41f1db96f813",
   "metadata": {},
   "source": [
    "### mapInPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a78ef77-5d3b-4f1f-9fb3-33380ffb8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.parquet(\"mnist_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "106b2fad-2225-40b6-88d4-7f314e7b7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_iter):\n",
    "    import json\n",
    "    import os\n",
    "    import random\n",
    "    import socket\n",
    "    import tensorflow as tf\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from pyspark import BarrierTaskContext\n",
    "    from datetime import datetime\n",
    "    \n",
    "    print(\"{}: {}: GOT HERE 1\".format(datetime.now(), os.getpid()))\n",
    "    # get list of participating nodes and my local address\n",
    "    context = BarrierTaskContext.get()\n",
    "    task_infos = context.getTaskInfos()\n",
    "    workers = [t.address.split(':')[0] for t in task_infos]\n",
    "    rank = context.partitionId()\n",
    "    addr = workers[rank]\n",
    "\n",
    "    # find available port for TF server \n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "        sock.bind(('', 0))\n",
    "        _, port = sock.getsockname()\n",
    "        tf_addr = \"{}:{}\".format(addr, port)\n",
    "        tf_addresses = context.allGather(tf_addr)\n",
    "    \n",
    "    # configure TF_CONFIG\n",
    "    TF_CONFIG = {\n",
    "        \"cluster\": {\"worker\": tf_addresses}, \n",
    "        \"task\": {\"type\": \"worker\", \"index\": rank}\n",
    "    }\n",
    "    print(f\"TF_CONFIG = {TF_CONFIG}\")\n",
    "    os.environ['TF_CONFIG'] = json.dumps(TF_CONFIG)\n",
    "    \n",
    "    # run the training code\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "    with strategy.scope():\n",
    "\n",
    "        # Define a simple sequential model\n",
    "        def create_model():\n",
    "            model = tf.keras.models.Sequential([\n",
    "                keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "                keras.layers.Dropout(0.2),\n",
    "                keras.layers.Dense(10)\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer='adam',\n",
    "                            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                            metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "            return model\n",
    "\n",
    "        # Create a basic model instance\n",
    "        model = create_model()\n",
    "\n",
    "        # Display the model's architecture\n",
    "        model.summary()\n",
    "\n",
    "        # simulate random startup latency\n",
    "        time.sleep(random.randint(0,5))\n",
    "\n",
    "        print(\"{}: {}: waiting for barrier\".format(datetime.now(), os.getpid()))\n",
    "        context.barrier()\n",
    "        print(\"{}: {}: continuing\".format(datetime.now(), os.getpid()))\n",
    "\n",
    "        for pdf in df_iter:\n",
    "            print(type(pdf), len(pdf))\n",
    "            x = np.vstack(pdf['image'].to_numpy())\n",
    "            y = pdf['label'].to_numpy()\n",
    "            model.fit(x, y)\n",
    "            yield pdf\n",
    "            \n",
    "        # TODO: after last iter, checkpoint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b816ed00-6f09-42a8-a57e-24817b288474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd_out = df_train \\\n",
    "    .repartition(2) \\\n",
    "    .mapInPandas(train, schema=\"image array<float>, label float\") \\\n",
    "    .rdd \\\n",
    "    .barrier() \\\n",
    "    .mapPartitions(lambda x: x) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea22aed-87a1-49fc-924a-d9ad110fc5d0",
   "metadata": {},
   "source": [
    "## Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bdf2a64-67fe-476d-ae07-32e422be8c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train = spark.read.parquet(\"mnist_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b0ef352-dd56-4109-a0d8-ecef9273b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from pyspark import BarrierTaskContext\n",
    "\n",
    "class FrameworkPlugin(ABC):\n",
    "    @staticmethod    \n",
    "    def setup(context: BarrierTaskContext):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def teardown(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e5573a1-3240-4fd4-b52c-9c77c8172b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorFlowPlugin(FrameworkPlugin):\n",
    "    @staticmethod\n",
    "    def setup(context: BarrierTaskContext):\n",
    "        import json\n",
    "        import socket\n",
    "\n",
    "        task_infos = context.getTaskInfos()\n",
    "        workers = [t.address.split(':')[0] for t in task_infos]\n",
    "        rank = context.partitionId()\n",
    "        world_size = len(workers)\n",
    "        my_addr = workers[rank]\n",
    "\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            # find available port for TF server \n",
    "            sock.bind(('', 0))\n",
    "            _, port = sock.getsockname()\n",
    "            tf_addr = \"{}:{}\".format(my_addr, port)\n",
    "            tf_addresses = context.allGather(tf_addr)\n",
    "\n",
    "            # configure TF_CONFIG\n",
    "            TF_CONFIG = {\n",
    "                \"cluster\": {\"worker\": tf_addresses}, \n",
    "                \"task\": {\"type\": \"worker\", \"index\": rank}\n",
    "            }\n",
    "            print(f\"TF_CONFIG = {TF_CONFIG}\")\n",
    "            os.environ['TF_CONFIG'] = json.dumps(TF_CONFIG)\n",
    "\n",
    "            return rank, world_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def teardown():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "355274e0-95d9-42fe-bfd6-1c3248eaff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def distribute(framework_plugin):\n",
    "    def decorator_distribute(train_fn):\n",
    "        @functools.wraps(train_fn)\n",
    "        def _wrapper(df_iter):\n",
    "            from pyspark import BarrierTaskContext\n",
    "\n",
    "            # get list of participating nodes and my local address\n",
    "            context = BarrierTaskContext.get()         \n",
    "            rank, world_size = framework_plugin.setup(context)      \n",
    "            result = train_fn(df_iter)\n",
    "            framework_plugin.teardown()\n",
    "            return result\n",
    "        return _wrapper\n",
    "    return decorator_distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc94dc27-d686-4b16-8af2-850de91a3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "@distribute(TensorFlowPlugin)\n",
    "def train_fn(df_iter):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # run the training code\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "    with strategy.scope():\n",
    "\n",
    "        # Define a simple sequential model\n",
    "        def create_model():\n",
    "            model = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Dense(10)\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer='adam',\n",
    "                            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                            metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "            return model\n",
    "\n",
    "        # Create a basic model instance\n",
    "        model = create_model()\n",
    "\n",
    "        # Display the model's architecture\n",
    "        model.summary()\n",
    "\n",
    "        # Receive data from Spark\n",
    "        for pdf in df_iter:\n",
    "            print(type(pdf), len(pdf))\n",
    "            x = np.vstack(pdf['image'].to_numpy())\n",
    "            y = pdf['label'].to_numpy()\n",
    "            model.fit(x, y)\n",
    "            yield pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe0d8df3-bbd4-4c8c-af8d-92084aa338f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd_out = df_train \\\n",
    "    .repartition(2) \\\n",
    "    .mapInPandas(train_fn, schema=\"image array<float>, label float\") \\\n",
    "    .rdd \\\n",
    "    .barrier() \\\n",
    "    .mapPartitions(lambda x: x) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883e5e0-0619-420b-b381-2b401afb073c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
