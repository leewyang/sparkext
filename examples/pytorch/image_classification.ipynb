{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e87c927",
   "metadata": {},
   "source": [
    "# PySpark PyTorch Inference\n",
    "\n",
    "### Image Classification\n",
    "Based on: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d714f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c942a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a89aa8e-ef62-4aac-8260-4b004f2c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a97111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) torch.float32\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af350",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512d0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c1b7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c5650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854608e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305333  [    0/60000]\n",
      "loss: 2.293172  [ 6400/60000]\n",
      "loss: 2.271651  [12800/60000]\n",
      "loss: 2.265887  [19200/60000]\n",
      "loss: 2.253572  [25600/60000]\n",
      "loss: 2.213814  [32000/60000]\n",
      "loss: 2.226953  [38400/60000]\n",
      "loss: 2.188729  [44800/60000]\n",
      "loss: 2.190818  [51200/60000]\n",
      "loss: 2.163593  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 41.1%, Avg loss: 2.150287 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165365  [    0/60000]\n",
      "loss: 2.156008  [ 6400/60000]\n",
      "loss: 2.096980  [12800/60000]\n",
      "loss: 2.116343  [19200/60000]\n",
      "loss: 2.065670  [25600/60000]\n",
      "loss: 2.000599  [32000/60000]\n",
      "loss: 2.033970  [38400/60000]\n",
      "loss: 1.950576  [44800/60000]\n",
      "loss: 1.960650  [51200/60000]\n",
      "loss: 1.901740  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 1.886987 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.922720  [    0/60000]\n",
      "loss: 1.892854  [ 6400/60000]\n",
      "loss: 1.774740  [12800/60000]\n",
      "loss: 1.823813  [19200/60000]\n",
      "loss: 1.711796  [25600/60000]\n",
      "loss: 1.663581  [32000/60000]\n",
      "loss: 1.693363  [38400/60000]\n",
      "loss: 1.588073  [44800/60000]\n",
      "loss: 1.616052  [51200/60000]\n",
      "loss: 1.522444  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.527063 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.598055  [    0/60000]\n",
      "loss: 1.562350  [ 6400/60000]\n",
      "loss: 1.409907  [12800/60000]\n",
      "loss: 1.488700  [19200/60000]\n",
      "loss: 1.364019  [25600/60000]\n",
      "loss: 1.364482  [32000/60000]\n",
      "loss: 1.383599  [38400/60000]\n",
      "loss: 1.302355  [44800/60000]\n",
      "loss: 1.336261  [51200/60000]\n",
      "loss: 1.243444  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.262851 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.344074  [    0/60000]\n",
      "loss: 1.325001  [ 6400/60000]\n",
      "loss: 1.159524  [12800/60000]\n",
      "loss: 1.267725  [19200/60000]\n",
      "loss: 1.137144  [25600/60000]\n",
      "loss: 1.168785  [32000/60000]\n",
      "loss: 1.191693  [38400/60000]\n",
      "loss: 1.124576  [44800/60000]\n",
      "loss: 1.159910  [51200/60000]\n",
      "loss: 1.078604  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.098655 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97839",
   "metadata": {},
   "source": [
    "### Save Model State Dict\n",
    "This is the [currently recommended save format](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5d24de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_weights.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")\n",
    "print(\"Saved PyTorch Model State to model_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416bbef",
   "metadata": {},
   "source": [
    "### Save Entire Model\n",
    "This saves the entire model using python pickle, but has the [following disadvantage](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model):\n",
    "> The serialized data is bound to the specific classes and the exact directory structure used when the model is saved... Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87098c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac221ca7-e227-4c8c-8577-1eeda4a61fc7",
   "metadata": {},
   "source": [
    "### Save Model as TorchScript\n",
    "This saves an [intermediate representation of the compute graph](https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format), which does not require pickle (or even python).  However, this currently doesn't work with spark, which uses pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d9b3a45-7618-43e4-8bd3-8bb317a484d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd01550-c72e-47f2-abe6-e14f26b06fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted.save(\"model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8916-f437-4a2a-9bf4-14ff5376d305",
   "metadata": {},
   "source": [
    "### Load Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe3b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_state = NeuralNetwork()\n",
    "model_from_state.load_state_dict(torch.load(\"model_weights.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c405bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "model_from_state.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model_from_state(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708f5e0",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc5bce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc219a56-4abd-4b61-9f9a-686dae7c9614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = new_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c482a-1c5d-4bf2-bc3f-8a4e53d442b5",
   "metadata": {},
   "source": [
    "### Load Torchscript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef3c419e-d384-446c-b07b-1af93e07d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model = torch.jit.load(\"model.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "038af830-a360-45eb-ab4e-b1adab0af164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = ts_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a930b0-2f90-44d7-9d97-8020dd73e682",
   "metadata": {},
   "source": [
    "## MLFlow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffd5c07-dc7c-4162-8efa-9e709d4d2fd1",
   "metadata": {},
   "source": [
    "### Save MLFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbead8ff-277d-4018-a9d0-93dd02d24184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ce23f83-2b82-4b01-9bec-cb6b5123f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature, ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c7676cf-1c94-4965-93e2-2ab2ddbfa85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model = torch.jit.load(\"model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf2a89-f7ed-420b-a77c-880f0e026aee",
   "metadata": {},
   "source": [
    "#### Inferred signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d926fc8b-1d59-4578-bafa-c9dee5e8a546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([1, 784]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = test_data[0][0].reshape(1,784)\n",
    "type(sample), sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1ee2675-f620-447a-bad5-5196b8dad10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [Tensor('float32', (-1, 784))]\n",
       "outputs: \n",
       "  [Tensor('float32', (-1, 10))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature = infer_signature(sample.numpy(), ts_model(sample).detach().numpy())\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0a5cbb8-cead-411b-a88a-a75e0943cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/04/26 16:15:05 WARNING mlflow.utils.requirements_utils: Found torch version (1.11.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==1.11.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2022/04/26 16:15:07 WARNING mlflow.utils.requirements_utils: Found torch version (1.11.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==1.11.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "subprocess.call(\"rm -rf model_infer\".split())\n",
    "mlflow.pytorch.save_model(pytorch_model=ts_model,\n",
    "                         signature=signature,\n",
    "                         path=\"model_infer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ff4da-ccd3-4486-b14b-fcfc2d43089f",
   "metadata": {},
   "source": [
    "#### Manual signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3e4d33c-cbe3-4ac0-a5b5-adfbb377edd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['dense_input': Tensor('float32', (-1, 784))]\n",
       "outputs: \n",
       "  ['dense_1': Tensor('float32', (-1, 10))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch flavor doesn't like named inputs\n",
    "input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 784), \"dense_input\")])\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 10), \"dense_1\")])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18cc5fff-1da9-4b81-9fd7-1f538ad8d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/04/26 16:15:07 WARNING mlflow.utils.requirements_utils: Found torch version (1.11.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==1.11.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2022/04/26 16:15:08 WARNING mlflow.utils.requirements_utils: Found torch version (1.11.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==1.11.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "subprocess.call(\"rm -rf model_manual\".split())\n",
    "mlflow.pytorch.save_model(pytorch_model=ts_model,\n",
    "                         signature=signature,\n",
    "                         path=\"model_manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e419fef-e2a3-479b-916a-dd70b594dfbf",
   "metadata": {},
   "source": [
    "### Load data pandas.DataFrame as 784 floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6c3f994-f4b5-4623-bf52-26d4d4cbc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aac695f-1bc7-465a-b977-9ccfbc2ae824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bc923e7-2a7d-4027-868b-e9cb028ff50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), dtype('float32'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data = data.astype(np.float32)\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae9dc049-8be4-4abc-af1c-e638b5383f12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2         3    4         5         6    7         8    \\\n",
       "0     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.003922   \n",
       "3     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "4     0.0  0.0  0.0  0.007843  0.0  0.003922  0.003922  0.0  0.000000   \n",
       "...   ...  ...  ...       ...  ...       ...       ...  ...       ...   \n",
       "9995  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9996  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9997  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9998  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9999  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "           9    ...       774       775  776       777       778       779  \\\n",
       "0     0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "1     0.000000  ...  0.007843  0.011765  0.0  0.011765  0.682353  0.741176   \n",
       "2     0.000000  ...  0.643137  0.227451  0.0  0.000000  0.000000  0.000000   \n",
       "3     0.082353  ...  0.003922  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "4     0.000000  ...  0.278431  0.047059  0.0  0.000000  0.000000  0.000000   \n",
       "...        ...  ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9996  0.121569  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9997  0.000000  ...  0.105882  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9998  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9999  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "           780  781  782  783  \n",
       "0     0.000000  0.0  0.0  0.0  \n",
       "1     0.262745  0.0  0.0  0.0  \n",
       "2     0.000000  0.0  0.0  0.0  \n",
       "3     0.000000  0.0  0.0  0.0  \n",
       "4     0.000000  0.0  0.0  0.0  \n",
       "...        ...  ...  ...  ...  \n",
       "9995  0.000000  0.0  0.0  0.0  \n",
       "9996  0.000000  0.0  0.0  0.0  \n",
       "9997  0.000000  0.0  0.0  0.0  \n",
       "9998  0.000000  0.0  0.0  0.0  \n",
       "9999  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pdf = pd.DataFrame(data)\n",
    "test_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbe8be-69a4-4a14-beca-4de50e3837f0",
   "metadata": {},
   "source": [
    "### Load data as pandas.DataFrame of 1 array of 784 floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef33f1a9-dbd9-475a-9584-94ced3d95236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.007843137718737125, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dense_input\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...\n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4     [0.0, 0.0, 0.0, 0.007843137718737125, 0.0, 0.0...\n",
       "...                                                 ...\n",
       "9995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pdf1 = pd.DataFrame()\n",
    "test_pdf1['dense_input'] = test_pdf.values.tolist()\n",
    "test_pdf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a56a0f-dcb4-4ed8-8966-67d966d6a66f",
   "metadata": {},
   "source": [
    "### Infer using MLFlow PyFuncModel (inferred signature w/o input names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a88c07c-5486-42b7-abf9-41daaba90c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "290f8a90-7920-48c9-842a-7b17a2e58252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leey/.pyenv/versions/3.9.10/envs/sparkext_mlflow/lib/python3.9/site-packages/torch/serialization.py:707: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    }
   ],
   "source": [
    "# Note: PyTorch \"flavor\" is defined in the MLModel file.\n",
    "model_infer = mlflow.pyfunc.load_model(\"model_infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12f38a23-94d7-48b4-afc9-f3648bb634fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flavors:\n",
      "  python_function:\n",
      "    data: data\n",
      "    env: conda.yaml\n",
      "    loader_module: mlflow.pytorch\n",
      "    pickle_module_name: mlflow.pytorch.pickle_module\n",
      "    python_version: 3.9.10\n",
      "  pytorch:\n",
      "    code: null\n",
      "    model_data: data\n",
      "    pytorch_version: 1.11.0+cpu\n",
      "mlflow_version: 1.25.2.dev0\n",
      "model_uuid: eccae151243f4216a4640fb4e60d2d1c\n",
      "signature:\n",
      "  inputs: '[{\"type\": \"tensor\", \"tensor-spec\": {\"dtype\": \"float32\", \"shape\": [-1, 784]}}]'\n",
      "  outputs: '[{\"type\": \"tensor\", \"tensor-spec\": {\"dtype\": \"float32\", \"shape\": [-1,\n",
      "    10]}}]'\n",
      "utc_time_created: '2022-04-26 23:15:05.415817'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_infer.metadata)  # contents of MLModel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba95bb-ac68-425c-ae6a-5c0fb1a88867",
   "metadata": {},
   "source": [
    "#### Infer using pandas.DataFrame (784 floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c99424e-d3b9-4ade-9f5b-5d4f12fbfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_infer.predict(test_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd4bbfa5-6280-470a-9b69-575f9b42ca0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9588f936-5054-438d-b5c3-9d54c5b48a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.042467</td>\n",
       "      <td>-2.246295</td>\n",
       "      <td>-0.688900</td>\n",
       "      <td>-2.178937</td>\n",
       "      <td>-0.917537</td>\n",
       "      <td>2.271457</td>\n",
       "      <td>-0.909829</td>\n",
       "      <td>2.509097</td>\n",
       "      <td>1.686130</td>\n",
       "      <td>3.034637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.940828</td>\n",
       "      <td>-3.285853</td>\n",
       "      <td>3.581051</td>\n",
       "      <td>-1.234425</td>\n",
       "      <td>3.221895</td>\n",
       "      <td>-2.022241</td>\n",
       "      <td>2.715813</td>\n",
       "      <td>-3.501479</td>\n",
       "      <td>1.552690</td>\n",
       "      <td>-2.119475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.881065</td>\n",
       "      <td>4.977236</td>\n",
       "      <td>-0.511262</td>\n",
       "      <td>3.587086</td>\n",
       "      <td>0.533625</td>\n",
       "      <td>-2.545371</td>\n",
       "      <td>0.409574</td>\n",
       "      <td>-3.335326</td>\n",
       "      <td>-2.377713</td>\n",
       "      <td>-2.922745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.305144</td>\n",
       "      <td>3.794120</td>\n",
       "      <td>-0.423444</td>\n",
       "      <td>2.669347</td>\n",
       "      <td>0.324053</td>\n",
       "      <td>-1.769337</td>\n",
       "      <td>0.232410</td>\n",
       "      <td>-2.441168</td>\n",
       "      <td>-1.861111</td>\n",
       "      <td>-2.070968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.026658</td>\n",
       "      <td>-1.369347</td>\n",
       "      <td>1.488516</td>\n",
       "      <td>-0.220768</td>\n",
       "      <td>1.353701</td>\n",
       "      <td>-1.123980</td>\n",
       "      <td>1.471480</td>\n",
       "      <td>-2.058816</td>\n",
       "      <td>0.558626</td>\n",
       "      <td>-1.172350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-2.476522</td>\n",
       "      <td>-3.402988</td>\n",
       "      <td>-0.709699</td>\n",
       "      <td>-3.013192</td>\n",
       "      <td>-1.013795</td>\n",
       "      <td>2.752758</td>\n",
       "      <td>-1.020825</td>\n",
       "      <td>2.582841</td>\n",
       "      <td>2.396552</td>\n",
       "      <td>4.753345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.954735</td>\n",
       "      <td>2.415779</td>\n",
       "      <td>-0.235035</td>\n",
       "      <td>1.798817</td>\n",
       "      <td>0.224770</td>\n",
       "      <td>-1.150019</td>\n",
       "      <td>0.216863</td>\n",
       "      <td>-1.612515</td>\n",
       "      <td>-1.213792</td>\n",
       "      <td>-1.535196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.011031</td>\n",
       "      <td>-0.345896</td>\n",
       "      <td>-0.034898</td>\n",
       "      <td>0.637689</td>\n",
       "      <td>0.247803</td>\n",
       "      <td>-0.683495</td>\n",
       "      <td>0.544897</td>\n",
       "      <td>-1.331556</td>\n",
       "      <td>0.591085</td>\n",
       "      <td>-0.740176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.317076</td>\n",
       "      <td>3.869592</td>\n",
       "      <td>-0.527877</td>\n",
       "      <td>2.937577</td>\n",
       "      <td>0.342804</td>\n",
       "      <td>-1.840980</td>\n",
       "      <td>0.269499</td>\n",
       "      <td>-2.493871</td>\n",
       "      <td>-1.901167</td>\n",
       "      <td>-2.141911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-1.382957</td>\n",
       "      <td>-1.553206</td>\n",
       "      <td>-0.348626</td>\n",
       "      <td>-1.429813</td>\n",
       "      <td>-0.485871</td>\n",
       "      <td>1.491774</td>\n",
       "      <td>-0.500850</td>\n",
       "      <td>1.801841</td>\n",
       "      <td>1.170600</td>\n",
       "      <td>1.422206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -2.042467 -2.246295 -0.688900 -2.178937 -0.917537  2.271457 -0.909829   \n",
       "1     0.940828 -3.285853  3.581051 -1.234425  3.221895 -2.022241  2.715813   \n",
       "2     1.881065  4.977236 -0.511262  3.587086  0.533625 -2.545371  0.409574   \n",
       "3     1.305144  3.794120 -0.423444  2.669347  0.324053 -1.769337  0.232410   \n",
       "4     1.026658 -1.369347  1.488516 -0.220768  1.353701 -1.123980  1.471480   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -2.476522 -3.402988 -0.709699 -3.013192 -1.013795  2.752758 -1.020825   \n",
       "9996  0.954735  2.415779 -0.235035  1.798817  0.224770 -1.150019  0.216863   \n",
       "9997  1.011031 -0.345896 -0.034898  0.637689  0.247803 -0.683495  0.544897   \n",
       "9998  1.317076  3.869592 -0.527877  2.937577  0.342804 -1.840980  0.269499   \n",
       "9999 -1.382957 -1.553206 -0.348626 -1.429813 -0.485871  1.491774 -0.500850   \n",
       "\n",
       "             7         8         9  \n",
       "0     2.509097  1.686130  3.034637  \n",
       "1    -3.501479  1.552690 -2.119475  \n",
       "2    -3.335326 -2.377713 -2.922745  \n",
       "3    -2.441168 -1.861111 -2.070968  \n",
       "4    -2.058816  0.558626 -1.172350  \n",
       "...        ...       ...       ...  \n",
       "9995  2.582841  2.396552  4.753345  \n",
       "9996 -1.612515 -1.213792 -1.535196  \n",
       "9997 -1.331556  0.591085 -0.740176  \n",
       "9998 -2.493871 -1.901167 -2.141911  \n",
       "9999  1.801841  1.170600  1.422206  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a45bf-8bfc-4fe8-8bdd-7e3d7ebeaefe",
   "metadata": {},
   "source": [
    "#### Infer using pandas.DataFrame (array of 784 floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a59370a5-355b-45c3-b7ba-6afa84aa06e4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Shape of input (10000, 1) does not match expected shape (-1, 784).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_infer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pdf1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:630\u001b[0m, in \u001b[0;36mPyFuncModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    628\u001b[0m input_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget_input_schema()\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_enforce_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_impl\u001b[38;5;241m.\u001b[39mpredict(data)\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:585\u001b[0m, in \u001b[0;36m_enforce_schema\u001b[0;34m(pfInput, input_schema)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_actual_columns \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_schema\u001b[38;5;241m.\u001b[39minputs):\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel inference is missing inputs. The model signature declares \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m inputs  but the provided value only has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m inputs. Note: the inputs were not named in the signature so we can \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly verify their count.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(input_schema\u001b[38;5;241m.\u001b[39minputs), num_actual_columns)\n\u001b[1;32m    582\u001b[0m         )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 585\u001b[0m     \u001b[43m_enforce_tensor_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfInput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_schema\u001b[38;5;241m.\u001b[39mis_tensor_spec()\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _enforce_col_schema(pfInput, input_schema)\n\u001b[1;32m    588\u001b[0m )\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:509\u001b[0m, in \u001b[0;36m_enforce_tensor_schema\u001b[0;34m(pfInput, input_schema)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pfInput, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m--> 509\u001b[0m         new_pfInput \u001b[38;5;241m=\u001b[39m \u001b[43m_enforce_tensor_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfInput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pfInput, (np\u001b[38;5;241m.\u001b[39mndarray, csc_matrix, csr_matrix)):\n\u001b[1;32m    511\u001b[0m         new_pfInput \u001b[38;5;241m=\u001b[39m _enforce_tensor_spec(pfInput, input_schema\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:453\u001b[0m, in \u001b[0;36m_enforce_tensor_spec\u001b[0;34m(values, tensor_spec)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expected \u001b[38;5;241m!=\u001b[39m actual:\n\u001b[0;32m--> 453\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    454\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of input \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not match expected shape \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    455\u001b[0m                 actual_shape, expected_shape\n\u001b[1;32m    456\u001b[0m             )\n\u001b[1;32m    457\u001b[0m         )\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_tensor_type(actual_type) \u001b[38;5;241m!=\u001b[39m tensor_spec\u001b[38;5;241m.\u001b[39mtype:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype of input \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not match expected dtype \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    461\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, tensor_spec\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    462\u001b[0m         )\n\u001b[1;32m    463\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Shape of input (10000, 1) does not match expected shape (-1, 784)."
     ]
    }
   ],
   "source": [
    "preds = model_infer.predict(test_pdf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9783d2b6-1262-427b-9f6a-4d51dce3fdca",
   "metadata": {},
   "source": [
    "#### Infer using dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2e24974-7bd8-4b9e-a828-e41d776c1a34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "This model contains a tensor-based model signature with no input names, which suggests a numpy array input, but an input of type <class 'dict'> was found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_infer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdense_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:630\u001b[0m, in \u001b[0;36mPyFuncModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    628\u001b[0m input_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget_input_schema()\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_enforce_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_impl\u001b[38;5;241m.\u001b[39mpredict(data)\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:585\u001b[0m, in \u001b[0;36m_enforce_schema\u001b[0;34m(pfInput, input_schema)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_actual_columns \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_schema\u001b[38;5;241m.\u001b[39minputs):\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel inference is missing inputs. The model signature declares \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m inputs  but the provided value only has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m inputs. Note: the inputs were not named in the signature so we can \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly verify their count.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(input_schema\u001b[38;5;241m.\u001b[39minputs), num_actual_columns)\n\u001b[1;32m    582\u001b[0m         )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 585\u001b[0m     \u001b[43m_enforce_tensor_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfInput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_schema\u001b[38;5;241m.\u001b[39mis_tensor_spec()\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _enforce_col_schema(pfInput, input_schema)\n\u001b[1;32m    588\u001b[0m )\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:513\u001b[0m, in \u001b[0;36m_enforce_tensor_schema\u001b[0;34m(pfInput, input_schema)\u001b[0m\n\u001b[1;32m    511\u001b[0m         new_pfInput \u001b[38;5;241m=\u001b[39m _enforce_tensor_spec(pfInput, input_schema\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model contains a tensor-based model signature with no input names,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which suggests a numpy array input, but an input of type \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(pfInput))\n\u001b[1;32m    517\u001b[0m         )\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_pfInput\n",
      "\u001b[0;31mMlflowException\u001b[0m: This model contains a tensor-based model signature with no input names, which suggests a numpy array input, but an input of type <class 'dict'> was found."
     ]
    }
   ],
   "source": [
    "preds = model_infer.predict({\"dense_input\": data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe146fd-9f87-477d-b36a-c33f5860939e",
   "metadata": {},
   "source": [
    "### Infer using MLFlow PyFuncModel (manual signature w/ input names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c33f9506-8c8a-4c6e-b749-ea3da604adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leey/.pyenv/versions/3.9.10/envs/sparkext_mlflow/lib/python3.9/site-packages/torch/serialization.py:707: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    }
   ],
   "source": [
    "# Note: PyTorch \"flavor\" is defined in the MLModel file.\n",
    "model_manual = mlflow.pyfunc.load_model(\"model_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1f60b39-fadb-4485-9df5-81af7cbfd7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flavors:\n",
      "  python_function:\n",
      "    data: data\n",
      "    env: conda.yaml\n",
      "    loader_module: mlflow.pytorch\n",
      "    pickle_module_name: mlflow.pytorch.pickle_module\n",
      "    python_version: 3.9.10\n",
      "  pytorch:\n",
      "    code: null\n",
      "    model_data: data\n",
      "    pytorch_version: 1.11.0+cpu\n",
      "mlflow_version: 1.25.2.dev0\n",
      "model_uuid: b718a8c147044ad6a7d635dcf9185532\n",
      "signature:\n",
      "  inputs: '[{\"name\": \"dense_input\", \"type\": \"tensor\", \"tensor-spec\": {\"dtype\": \"float32\",\n",
      "    \"shape\": [-1, 784]}}]'\n",
      "  outputs: '[{\"name\": \"dense_1\", \"type\": \"tensor\", \"tensor-spec\": {\"dtype\": \"float32\",\n",
      "    \"shape\": [-1, 10]}}]'\n",
      "utc_time_created: '2022-04-26 23:15:07.156337'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_manual.metadata)  # contents of MLModel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73054a7-abbc-4000-aec7-41516e725abc",
   "metadata": {},
   "source": [
    "#### Infer using pandas.DataFrame (784 floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "013c94c7-d800-47a0-a49a-a3936c20c4ab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Model is missing inputs ['dense_input']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_manual\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:630\u001b[0m, in \u001b[0;36mPyFuncModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    628\u001b[0m input_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget_input_schema()\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_enforce_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_impl\u001b[38;5;241m.\u001b[39mpredict(data)\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:569\u001b[0m, in \u001b[0;36m_enforce_schema\u001b[0;34m(pfInput, input_schema)\u001b[0m\n\u001b[1;32m    567\u001b[0m     extra_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m actual_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m extra_cols]\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[0;32m--> 569\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is missing inputs \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Note that there were extra inputs: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(missing_cols, extra_cols)\n\u001b[1;32m    572\u001b[0m         )\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_schema\u001b[38;5;241m.\u001b[39mis_tensor_spec():\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# The model signature does not specify column names => we can only verify column count.\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     num_actual_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pfInput\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mMlflowException\u001b[0m: Model is missing inputs ['dense_input']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783]"
     ]
    }
   ],
   "source": [
    "preds = model_manual.predict(test_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d31af-6eee-4b6b-85b0-82d721b627dc",
   "metadata": {},
   "source": [
    "#### Infer using pandas.DataFrame (array of 784 floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fde90d9c-0c78-4890-be4b-6fd49178cc5e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_manual\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pdf1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:630\u001b[0m, in \u001b[0;36mPyFuncModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    628\u001b[0m input_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget_input_schema()\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_enforce_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_impl\u001b[38;5;241m.\u001b[39mpredict(data)\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:585\u001b[0m, in \u001b[0;36m_enforce_schema\u001b[0;34m(pfInput, input_schema)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_actual_columns \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_schema\u001b[38;5;241m.\u001b[39minputs):\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel inference is missing inputs. The model signature declares \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m inputs  but the provided value only has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m inputs. Note: the inputs were not named in the signature so we can \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly verify their count.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(input_schema\u001b[38;5;241m.\u001b[39minputs), num_actual_columns)\n\u001b[1;32m    582\u001b[0m         )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 585\u001b[0m     \u001b[43m_enforce_tensor_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfInput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_schema\u001b[38;5;241m.\u001b[39mis_tensor_spec()\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _enforce_col_schema(pfInput, input_schema)\n\u001b[1;32m    588\u001b[0m )\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:499\u001b[0m, in \u001b[0;36m_enforce_tensor_schema\u001b[0;34m(pfInput, input_schema)\u001b[0m\n\u001b[1;32m    496\u001b[0m     new_pfInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_name, tensor_spec \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_schema\u001b[38;5;241m.\u001b[39minput_names(), input_schema\u001b[38;5;241m.\u001b[39minputs):\n\u001b[1;32m    498\u001b[0m         new_pfInput[col_name] \u001b[38;5;241m=\u001b[39m _enforce_tensor_spec(\n\u001b[0;32m--> 499\u001b[0m             \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfInput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m)\u001b[49m, tensor_spec\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model contains a tensor-based model signature with input names, which\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m suggests a dictionary input mapping input name to tensor, but an input of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m type \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m was found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(pfInput))\n\u001b[1;32m    506\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/sparkext_mlflow/lib/python3.9/site-packages/pandas/core/series.py:872\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "preds = model_manual.predict(test_pdf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20622eb1-32cd-4781-9f9a-192dbe2ff80b",
   "metadata": {},
   "source": [
    "#### Infer using dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f90b8ab-9cca-46e6-9f5f-9e6661d9b86d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The PyTorch flavor does not support List or Dict input types. Please use a pandas.DataFrame or a numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_manual\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdense_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pyfunc/__init__.py:631\u001b[0m, in \u001b[0;36mPyFuncModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m     data \u001b[38;5;241m=\u001b[39m _enforce_schema(data, input_schema)\n\u001b[0;32m--> 631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devpub/mlflow/mlflow/pytorch/__init__.py:755\u001b[0m, in \u001b[0;36m_PyTorchWrapper.predict\u001b[0;34m(self, data, device)\u001b[0m\n\u001b[1;32m    753\u001b[0m     inp_data \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    756\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe PyTorch flavor does not support List or Dict input types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use a pandas.DataFrame or a numpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m     )\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data should be pandas.DataFrame or numpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: The PyTorch flavor does not support List or Dict input types. Please use a pandas.DataFrame or a numpy.ndarray"
     ]
    }
   ],
   "source": [
    "preds = model_manual.predict({\"dense_input\": data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918393",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1daec3",
   "metadata": {},
   "source": [
    "### Convert numpy dataset to Spark DataFrame (via Pandas DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42c5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f063cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c828393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), dtype('float32'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data = data.astype(np.float32)\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7760bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1033a60-7504-40f5-9dba-30f7c59cd10c",
   "metadata": {},
   "source": [
    "### Save as 784 columns of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eef80e7b-d5c3-4357-b7c4-89583ab7a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 16:17:29 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "22/04/26 16:17:29 WARN TaskSetManager: Stage 0 contains a task of very large size (4313 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 0:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 167 ms, total: 1min 15s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.createDataFrame(test_pdf)\n",
    "df.write.mode(\"overwrite\").parquet(\"fashion_mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "546977b6-d528-4179-a7c2-c78eeda74a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7448",
   "metadata": {},
   "source": [
    "### Save as 1 column of 784 floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7d2bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 51.8 ms, total: 276 ms\n",
      "Wall time: 274 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "test_pdf['data'] = test_pdf.values.tolist()\n",
    "pdf = test_pdf[['data']]\n",
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4863d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 44 ms, total: 3.3 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Pandas uses double\n",
    "schema = StructType([StructField(\"data\",ArrayType(FloatType()), True)])\n",
    "df1 = spark.createDataFrame(pdf, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d8cb2c1-495d-4dce-8422-0f14fc78917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "406edba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(data,ArrayType(FloatType,true),true)))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8ebae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 16:17:39 WARN TaskSetManager: Stage 1 contains a task of very large size (4315 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 1:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 3.86 ms, total: 17.9 ms\n",
      "Wall time: 1.36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df1.write.mode(\"overwrite\").parquet(\"fashion_mnist_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688429e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "088cb37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 16:17:40 WARN TaskSetManager: Stage 2 contains a task of very large size (4313 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e1112-d187-44f0-b9a9-601c26ea5932",
   "metadata": {},
   "source": [
    "## Inference using MLFlow pyfunc.spark_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eefeace4-f803-4d04-b600-123eb445dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.sql.functions import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f959168-c004-40cf-9f85-59ff86a6bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10df0b8f-4837-4ae2-aad6-bdd1277e8e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e8e41-b504-4d49-9675-36fcd18610ea",
   "metadata": {},
   "source": [
    "#### Inferred signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0773086a-ec80-45b3-8afe-1bdc13f8f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/04/26 16:18:03 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n"
     ]
    }
   ],
   "source": [
    "mnist_infer = mlflow.pyfunc.spark_udf(spark, model_uri=\"model_infer\", result_type=\"array<float>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b546b7e-7718-49fc-9379-4ff2bdf17fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [Tensor('float32', (-1, 784))]\n",
       "outputs: \n",
       "  [Tensor('float32', (-1, 10))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_infer.metadata.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23d61b90-ffbc-4d44-bfca-5d4dac411dec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 15.0 in stage 4.0 (TID 49) (192.168.86.223 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1273, in udf\n",
      "    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1115, in _predict_row_batch\n",
      "    result = predict_fn(pdf)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1255, in batch_predict_fn\n",
      "    return loaded_model.predict(pdf)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 630, in predict\n",
      "    data = _enforce_schema(data, input_schema)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 585, in _enforce_schema\n",
      "    _enforce_tensor_schema(pfInput, input_schema)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 509, in _enforce_tensor_schema\n",
      "    new_pfInput = _enforce_tensor_spec(pfInput.to_numpy(), input_schema.inputs[0])\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 453, in _enforce_tensor_spec\n",
      "    raise MlflowException(\n",
      "mlflow.exceptions.MlflowException: Shape of input (128, 1) does not match expected shape (-1, 784).\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/04/26 16:18:32 ERROR TaskSetManager: Task 15 in stage 4.0 failed 1 times; aborting job\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 2.0 in stage 4.0 (TID 36) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 14.0 in stage 4.0 (TID 48) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 13.0 in stage 4.0 (TID 47) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 6.0 in stage 4.0 (TID 40) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 8.0 in stage 4.0 (TID 42) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 1.0 in stage 4.0 (TID 35) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 10.0 in stage 4.0 (TID 44) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 12.0 in stage 4.0 (TID 46) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 34) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:32 WARN TaskSetManager: Lost task 4.0 in stage 4.0 (TID 38) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1273, in udf\n    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1115, in _predict_row_batch\n    result = predict_fn(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1255, in batch_predict_fn\n    return loaded_model.predict(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 630, in predict\n    data = _enforce_schema(data, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 585, in _enforce_schema\n    _enforce_tensor_schema(pfInput, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 509, in _enforce_tensor_schema\n    new_pfInput = _enforce_tensor_spec(pfInput.to_numpy(), input_schema.inputs[0])\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 453, in _enforce_tensor_spec\n    raise MlflowException(\nmlflow.exceptions.MlflowException: Shape of input (128, 1) does not match expected shape (-1, 784).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/devpub/spark/python/pyspark/sql/pandas/conversion.py:157\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    158\u001b[0m column_counter \u001b[38;5;241m=\u001b[39m Counter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    160\u001b[0m dtype \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/devpub/spark/python/pyspark/sql/dataframe.py:693\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc) \u001b[38;5;28;01mas\u001b[39;00m css:\n\u001b[0;32m--> 693\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(PickleSerializer())))\n",
      "File \u001b[0;32m~/devpub/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/devpub/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1273, in udf\n    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1115, in _predict_row_batch\n    result = predict_fn(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1255, in batch_predict_fn\n    return loaded_model.predict(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 630, in predict\n    data = _enforce_schema(data, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 585, in _enforce_schema\n    _enforce_tensor_schema(pfInput, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 509, in _enforce_tensor_schema\n    new_pfInput = _enforce_tensor_spec(pfInput.to_numpy(), input_schema.inputs[0])\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 453, in _enforce_tensor_spec\n    raise MlflowException(\nmlflow.exceptions.MlflowException: Shape of input (128, 1) does not match expected shape (-1, 784).\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist_infer(*columns)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e2093-197f-4f4a-9e1e-42a0afe9b203",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Manual schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0c6028c-b4b7-49c3-8e57-d753796808c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/04/26 16:18:41 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n"
     ]
    }
   ],
   "source": [
    "mnist_manual = mlflow.pyfunc.spark_udf(spark, model_uri=\"model_manual\", result_type=\"array<float>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60ba05e3-1b33-4051-82bc-716f36dcb685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['dense_input': Tensor('float32', (-1, 784))]\n",
       "outputs: \n",
       "  ['dense_1': Tensor('float32', (-1, 10))]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_manual.metadata.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46c52496-1787-4ba5-8ac4-3849d41dfda1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 2.0 in stage 5.0 (TID 52) (192.168.86.223 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1273, in udf\n",
      "    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1115, in _predict_row_batch\n",
      "    result = predict_fn(pdf)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1255, in batch_predict_fn\n",
      "    return loaded_model.predict(pdf)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 630, in predict\n",
      "    data = _enforce_schema(data, input_schema)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 585, in _enforce_schema\n",
      "    _enforce_tensor_schema(pfInput, input_schema)\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 498, in _enforce_tensor_schema\n",
      "    new_pfInput[col_name] = _enforce_tensor_spec(\n",
      "  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 444, in _enforce_tensor_spec\n",
      "    raise MlflowException(\n",
      "mlflow.exceptions.MlflowException: Shape of input (128,) does not match expected shape (-1, 784).\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/04/26 16:18:50 ERROR TaskSetManager: Task 2 in stage 5.0 failed 1 times; aborting job\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 8.0 in stage 5.0 (TID 58) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1273, in udf\n    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1115, in _predict_row_batch\n    result = predict_fn(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1255, in batch_predict_fn\n    return loaded_model.predict(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 630, in predict\n    data = _enforce_schema(data, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 585, in _enforce_schema\n    _enforce_tensor_schema(pfInput, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 498, in _enforce_tensor_schema\n    new_pfInput[col_name] = _enforce_tensor_spec(\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 444, in _enforce_tensor_spec\n    raise MlflowException(\nmlflow.exceptions.MlflowException: Shape of input (128,) does not match expected shape (-1, 784).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/devpub/spark/python/pyspark/sql/pandas/conversion.py:157\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    158\u001b[0m column_counter \u001b[38;5;241m=\u001b[39m Counter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    160\u001b[0m dtype \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/devpub/spark/python/pyspark/sql/dataframe.py:693\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc) \u001b[38;5;28;01mas\u001b[39;00m css:\n\u001b[0;32m--> 693\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(PickleSerializer())))\n",
      "File \u001b[0;32m~/devpub/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/devpub/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1273, in udf\n    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1115, in _predict_row_batch\n    result = predict_fn(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 1255, in batch_predict_fn\n    return loaded_model.predict(pdf)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 630, in predict\n    data = _enforce_schema(data, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 585, in _enforce_schema\n    _enforce_tensor_schema(pfInput, input_schema)\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 498, in _enforce_tensor_schema\n    new_pfInput[col_name] = _enforce_tensor_spec(\n  File \"/home/leey/devpub/mlflow/mlflow/pyfunc/__init__.py\", line 444, in _enforce_tensor_spec\n    raise MlflowException(\nmlflow.exceptions.MlflowException: Shape of input (128,) does not match expected shape (-1, 784).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 4.0 in stage 5.0 (TID 54) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 50) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 3.0 in stage 5.0 (TID 53) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 5.0 in stage 5.0 (TID 55) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 12.0 in stage 5.0 (TID 62) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 10.0 in stage 5.0 (TID 60) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 14.0 in stage 5.0 (TID 64) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 6.0 in stage 5.0 (TID 56) (192.168.86.223 executor 1): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 11.0 in stage 5.0 (TID 61) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 1.0 in stage 5.0 (TID 51) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 13.0 in stage 5.0 (TID 63) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 15.0 in stage 5.0 (TID 65) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 9.0 in stage 5.0 (TID 59) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/04/26 16:18:50 WARN TaskSetManager: Lost task 7.0 in stage 5.0 (TID 57) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist_manual(*columns)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e6443-c082-4c09-98ec-444f571a2394",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e49c1-0c8e-4627-873c-83bad133f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957a8d6-b4c3-47fb-b752-4b89a194f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preds.drop(columns=['preds']).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5ed06-9ff6-4dd1-9423-839edbd03de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17412cdd-f07a-4277-bfb4-5bd0af071803",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe93cfe-e71c-405f-bfb8-537b1905c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['preds'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00db116-078a-4227-a341-ea224841ce16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
