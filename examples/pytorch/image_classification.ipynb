{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e87c927",
   "metadata": {},
   "source": [
    "# PySpark PyTorch Inference\n",
    "\n",
    "### Image Classification\n",
    "Based on: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c942a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89aa8e-ef62-4aac-8260-4b004f2c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a97111",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af350",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c1b7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854608e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97839",
   "metadata": {},
   "source": [
    "### Save Model State Dict\n",
    "This is the [currently recommended save format](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")\n",
    "print(\"Saved PyTorch Model State to model_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416bbef",
   "metadata": {},
   "source": [
    "### Save Entire Model\n",
    "This saves the entire model using python pickle, but has the [following disadvantage](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model):\n",
    "> The serialized data is bound to the specific classes and the exact directory structure used when the model is saved... Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87098c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac221ca7-e227-4c8c-8577-1eeda4a61fc7",
   "metadata": {},
   "source": [
    "### Save Model as TorchScript\n",
    "This saves an [intermediate representation of the compute graph](https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format), which does not require pickle (or even python).  However, this currently doesn't work with spark, which uses pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b3a45-7618-43e4-8bd3-8bb317a484d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd01550-c72e-47f2-abe6-e14f26b06fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted.save(\"model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8916-f437-4a2a-9bf4-14ff5376d305",
   "metadata": {},
   "source": [
    "### Load Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_state = NeuralNetwork()\n",
    "model_from_state.load_state_dict(torch.load(\"model_weights.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c405bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_state.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model_from_state(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708f5e0",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc219a56-4abd-4b61-9f9a-686dae7c9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = new_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c482a-1c5d-4bf2-bc3f-8a4e53d442b5",
   "metadata": {},
   "source": [
    "### Load Torchscript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c419e-d384-446c-b07b-1af93e07d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model = torch.jit.load(\"model.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038af830-a360-45eb-ab4e-b1adab0af164",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = ts_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918393",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1daec3",
   "metadata": {},
   "source": [
    "### Convert numpy dataset to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c828393",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf784 = pd.DataFrame(data)\n",
    "pdf784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "pdf1 = pd.DataFrame()\n",
    "pdf1['data'] = pdf784.values.tolist()\n",
    "pdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3b86a-8b61-4128-ab61-0199fd3437cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Spark DataFrame from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(\"data\",ArrayType(FloatType()), True)])\n",
    "df = spark.createDataFrame(pdf1, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406edba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f4a01-3a49-4114-b9a0-2ae54526d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(str(x), FloatType(), True) for x in range(784)])\n",
    "df784 = spark.createDataFrame(pdf784, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7448",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.write.mode(\"overwrite\").parquet(\"fashion_mnist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922314ce-2996-4666-9fc9-bcd98d16bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df784.write.mode(\"overwrite\").parquet(\"fashion_mnist_784\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688429e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d272b64",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sparkext\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efade52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c5e0b-fb7a-4b4c-9391-fbae4ec2b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b810352-dae3-419f-a8f6-d31665deebb3",
   "metadata": {},
   "source": [
    "### Using TorchScript Model\n",
    "TorchScript models do not require the model definition prior to loading, but they don't serialize well from Spark driver to executors, so we must use a `model_loader` function that is invoked on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd88a5-d9ae-4eca-9fcd-582728e574cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    return torch.jit.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0ae89-36c7-4d20-9c7b-5550aa4432c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd() / \"model.ts\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00943715-6fef-4f0f-8927-1ae0e0617247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sparkext.torch.Model(str(model_path), model_loader) \\\n",
    "            .setInputCol(\"data\") \\\n",
    "            .setOutputCol(\"preds\") \\\n",
    "            .setInputShape((-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf05247",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write.mode(\"overwrite\").parquet(\"mnist_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c61229",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea498703-4829-46d6-a8c0-676afb3f876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf85ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(preds[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706f98f-797c-4666-bca1-b17d397a7165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db4f92-3c57-4d70-afaf-d2780d9f6683",
   "metadata": {},
   "source": [
    "### Using Saved Model\n",
    "\n",
    "Since the model is pickled, the model class must be defined before loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e47d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sparkext.torch.Model(\"model.pt\") \\\n",
    "            .setInputCol(\"data\") \\\n",
    "            .setOutputCol(\"preds\") \\\n",
    "            .setInputShape((-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c7924-cfe2-4031-a833-0e581a6ad8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a4b19-53ee-4b6a-ac0b-6712d5f43f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write.mode(\"overwrite\").parquet(\"mnist_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914ab60-437e-4265-ae77-21864a684b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0]['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba604c-1f2d-4515-955f-6a7cb5fbe8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62b2c7-5919-4df6-8612-c6d1b61986db",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(preds[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7194371-4488-4d89-89ca-aab94d6c6a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a7035-26ba-40bf-93f2-692bb209c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75f452-acef-4888-bbf4-7414babd22cc",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad74fe-63c9-459a-a065-df864e1d39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "from sparkext.torch import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41498941-5928-4dfa-9b1f-4320d54691b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e387bb-09bd-4f73-b3f0-24a22dbd41a2",
   "metadata": {},
   "source": [
    "### Using TorchScript Model\n",
    "TorchScript models do not require the model definition prior to loading, but they don't serialize well from Spark driver to executors, so we must use a `model_loader` function that is invoked on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827253b-978c-44e9-99cb-9c10985fbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    import torch\n",
    "    return torch.jit.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316689b-f0da-4ac5-934d-5e9343d35e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd() / \"model.ts\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6759c3-1f00-4b68-9800-11890cdbe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(str(model_path), model_loader=model_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb83fd-ee2b-49fa-b77d-369cd6beb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(col(\"data\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0e876-afc3-44f6-8b5f-c7ac8370a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e807a-a7ef-403f-a53b-a7f83cfb4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77897b3-4a3b-433b-8c33-2a888bd33992",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33edd34-d949-4a89-b11f-9fb02073d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(preds[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdbe9b-a834-41ac-919b-f6f44ffb4222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a46502-6d86-4548-8441-2151d206413d",
   "metadata": {},
   "source": [
    "### Using Saved Model\n",
    "\n",
    "Since the model is pickled, the model class must be defined before loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24308ad8-bad8-478b-aee6-a21b1c01ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf4542-da40-4c4d-9d3a-ba11044aa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d9207-2a13-4c6f-a91b-4003893694d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df.withColumn(\"preds\", classify(col(\"data\"))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31bd313-7ea7-46d0-b9ce-ee6c0583d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15ee7a-41fc-47fd-8e82-5dfa725e1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(preds[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5ed06-9ff6-4dd1-9423-839edbd03de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17412cdd-f07a-4277-bfb4-5bd0af071803",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe93cfe-e71c-405f-bfb8-537b1905c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d210ee9-aceb-4c9a-a5fe-08349b15c385",
   "metadata": {},
   "source": [
    "## Inference using Triton UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526675e9-2f2f-4e6e-aa0b-593d5f57d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ef9ec-4de9-409f-8318-b379ed8346a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818d287-7a38-4dfe-8556-d11405fb8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70fb55-8cb6-4380-a736-a77ddc018936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkext.triton.udf import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d642b7-9b3b-4ef1-83cb-ee7e58d63459",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = model_udf(\"localhost:8001\", \"fashion_mnist\", batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51fe8da-0422-47f8-9f77-ab65df97ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(col(\"data\"))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f57b6-425f-4740-85fb-0abf35db7971",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b9371-d078-45fd-b43b-5167bbc15a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae5d0f-ccaf-41e3-bed3-fa942f32f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "img = np.array(preds[index].data)\n",
    "predictions = preds[index].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bd858-06bd-429c-9bb3-3f52db187f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ac4b7-4414-4219-8bfd-3a3700d54a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec40fb2-cce2-4e3e-b956-9f8b2ae6b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c77eb4-7bd6-40c7-9a35-ee899a66ece3",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59395856-a588-43c6-93c8-c83100716ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1 columns of 784 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133cc9a5-64c6-4820-807e-b87cf7e0b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b151d9-d112-43b6-a479-887e2fd0e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cabcd546-2e8e-40d0-8b79-7598a7a83aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73dc73cb-25e3-4798-a019-e1abd684eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using {} device\".format(device))\n",
    "    model = torch.jit.load(\"/home/leey/devpub/leewyang/sparkext/examples/pytorch/model.ts\")\n",
    "    model.to(device)\n",
    "    \n",
    "    def predict(inputs: np.ndarray):\n",
    "        torch_inputs = torch.from_numpy(inputs).to(device)\n",
    "        outputs = model(torch_inputs)\n",
    "        return outputs.detach().numpy()\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df68cca1-2d47-4e88-8aad-9899402aee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(predict_batch_fn,\n",
    "                          input_tensor_shapes=[[-1, 784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63555b3b-3673-4712-97aa-fd728c6c4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 503 ms, sys: 142 ms, total: 645 ms\n",
      "Wall time: 7.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbf058a-70d6-4199-af9d-13843d078950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 472 ms, sys: 131 ms, total: 602 ms\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f5ed801-6ca5-43a0-bf9c-2535a0dfe2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 629 ms, sys: 105 ms, total: 734 ms\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbec03-9b64-46c4-a748-f889be571384",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f1e5fd-5866-4b78-b9d3-709e6b383a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds[0].preds\n",
    "img = preds[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b76502-adb7-45ec-a365-2e61cdd576fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c163953a-1504-444f-b39f-86b61d34e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0fad05-50ab-4ae5-b9fd-e50133c4c92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56f36efb-e3a2-49f9-b9fb-1657bc25e5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9588213562965393,\n",
       " -2.071481943130493,\n",
       " 2.1429624557495117,\n",
       " -0.4603125751018524,\n",
       " 2.076378107070923,\n",
       " -1.5263869762420654,\n",
       " 2.026245594024658,\n",
       " -2.510979175567627,\n",
       " 1.5055983066558838,\n",
       " -1.3217121362686157]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca1195-ea0f-405f-87fe-857e5c0c76a5",
   "metadata": {},
   "source": [
    "### 784 columns of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ab0af6-b5c9-4b74-9dd6-baa7737cc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_784\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ae45dc-85a0-4864-8a58-9dc29ae4efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/21 08:50:55 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 139 ms, total: 1.23 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3fb48b-f871-41f2-ac57-346899a6fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 983 ms, sys: 176 ms, total: 1.16 s\n",
      "Wall time: 5.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a43f3a7e-c6ef-4eaa-bfa8-8ca09cab7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/21 08:51:11 WARN TaskSetManager: Lost task 0.0 in stage 7.0 (TID 42) (192.168.86.223 executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 289, in predict\n",
      "    raise ValueError(\n",
      "ValueError: Multiple input columns found, but model expected a single input, use `struct` or `array` to combine columns into tensors.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:108)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:52)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:889)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:889)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1490)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "22/09/21 08:51:11 ERROR TaskSetManager: Task 0 in stage 7.0 failed 1 times; aborting job\n",
      "22/09/21 08:51:11 WARN TaskSetManager: Lost task 2.0 in stage 7.0 (TID 44) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/09/21 08:51:11 WARN TaskSetManager: Lost task 1.0 in stage 7.0 (TID 43) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 289, in predict\n    raise ValueError(\nValueError: Multiple input columns found, but model expected a single input, use `struct` or `array` to combine columns into tensors.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/pyspark/sql/dataframe.py:1137\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1137\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/pyspark/sql/utils.py:205\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    201\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 289, in predict\n    raise ValueError(\nValueError: Multiple input columns found, but model expected a single input, use `struct` or `array` to combine columns into tensors.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5def0eb-6a67-452b-a16b-3ce195427d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 1.0 in stage 8.0 (TID 51) (192.168.86.223 executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 289, in predict\n",
      "    raise ValueError(\n",
      "ValueError: Multiple input columns found, but model expected a single input, use `struct` or `array` to combine columns into tensors.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:108)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:52)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:889)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:889)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1490)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "22/09/21 08:51:18 ERROR TaskSetManager: Task 1 in stage 8.0 failed 1 times; aborting job\n",
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 50) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 3.0 in stage 8.0 (TID 53) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 4.0 in stage 8.0 (TID 54) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 6.0 in stage 8.0 (TID 56) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 5.0 in stage 8.0 (TID 55) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 7.0 in stage 8.0 (TID 57) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n",
      "22/09/21 08:51:18 WARN TaskSetManager: Lost task 2.0 in stage 8.0 (TID 52) (192.168.86.223 executor 0): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 289, in predict\n    raise ValueError(\nValueError: Multiple input columns found, but model expected a single input, use `struct` or `array` to combine columns into tensors.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/pyspark/sql/dataframe.py:1137\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1137\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/devpub/leewyang/spark/python/pyspark/sql/utils.py:205\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    201\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/home/leey/devpub/leewyang/spark/python/pyspark/ml/functions.py\", line 289, in predict\n    raise ValueError(\nValueError: Multiple input columns found, but model expected a single input, use `struct` or `array` to combine columns into tensors.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48ec42-0df6-4e6a-b019-1270ab71d2cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d815c701-9f5b-422c-b3f9-fbc30456953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b571b742-5079-42b2-8524-9181a0dec2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = preds.iloc[0]\n",
    "predictions = sample.preds\n",
    "img = sample.drop('preds').to_numpy(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33d6a4e-e6b9-489d-ac21-c4eddc801784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d10061e-aca6-4f81-bdfe-72e327ed7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f70e08-2c1d-419f-8676-3f6f4aba760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e1c07cc-b2bc-4902-a9a6-4ac7f02c5fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9588213562965393,\n",
       " -2.071481943130493,\n",
       " 2.1429624557495117,\n",
       " -0.4603125751018524,\n",
       " 2.076378107070923,\n",
       " -1.5263869762420654,\n",
       " 2.026245594024658,\n",
       " -2.510979175567627,\n",
       " 1.5055983066558838,\n",
       " -1.3217121362686157]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001469be-f3b6-4def-bf7d-67e10393335c",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53ca290a-ccc3-4923-a292-944921bab36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab94d4d1-dac6-4474-9eb0-59478aa98f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12b5f2fc-52e9-428a-b683-6ab1b639aa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b329c-5921-436f-bfca-a382a6762da4",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e869730-3597-4074-bab0-f87768f8996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"64M\",\n",
    "            volumes={\"/home/leey/devpub/leewyang/sparkext/examples/models\": {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "            \n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4362d-7514-4b84-b238-f704a97e1e72",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "960657d0-31c9-4df6-8eb8-ac3d23137f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0262fd4a-9845-44b9-8c75-1c105e7deeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"fashion_mnist\"),\n",
    "                          input_tensor_shapes=[[-1, 784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc5f6baa-052e-4b89-94b6-4821cf01952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 427 ms, sys: 106 ms, total: 533 ms\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a85dea35-e41d-482d-8a8f-52d3c108f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 530 ms, sys: 74.5 ms, total: 605 ms\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc3f0dbe-c52b-41d6-8097-8cebaa5ee5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 625 ms, sys: 87.9 ms, total: 713 ms\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26690a-9dc4-4c36-9904-568d73e2be3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab2fe42f-a072-4370-bac2-52fd95363530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0608fff-7cfb-489e-96c9-8e1d92e57562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/envs/spark_dev/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/envs/spark_dev/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/envs/spark_dev/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/envs/spark_dev/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/lib/python3.9/asyncio/base_events.py\", line 1854, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/home/leey/.pyenv/versions/3.9.10/lib/python3.9/selectors.py\", line 469, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/pyspark/context.py\", line 365, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/home/leey/devpub/leewyang/spark/python/pyspark/context.py\", line 2243, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "AttributeError: 'NoneType' object has no attribute 'sc'\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de2664-3d60-487b-90da-6d0f3b8b9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
