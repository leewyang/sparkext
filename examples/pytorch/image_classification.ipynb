{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e87c927",
   "metadata": {},
   "source": [
    "# PySpark PyTorch Inference\n",
    "\n",
    "### Image Classification\n",
    "Based on: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d714f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c942a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a89aa8e-ef62-4aac-8260-4b004f2c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a97111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) torch.float32\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af350",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512d0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c1b7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c5650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854608e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.292186  [    0/60000]\n",
      "loss: 2.289895  [ 6400/60000]\n",
      "loss: 2.270453  [12800/60000]\n",
      "loss: 2.269008  [19200/60000]\n",
      "loss: 2.242647  [25600/60000]\n",
      "loss: 2.217875  [32000/60000]\n",
      "loss: 2.219310  [38400/60000]\n",
      "loss: 2.180045  [44800/60000]\n",
      "loss: 2.177415  [51200/60000]\n",
      "loss: 2.160084  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 2.143999 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.146929  [    0/60000]\n",
      "loss: 2.144132  [ 6400/60000]\n",
      "loss: 2.080031  [12800/60000]\n",
      "loss: 2.101583  [19200/60000]\n",
      "loss: 2.035192  [25600/60000]\n",
      "loss: 1.982249  [32000/60000]\n",
      "loss: 2.003722  [38400/60000]\n",
      "loss: 1.914538  [44800/60000]\n",
      "loss: 1.922915  [51200/60000]\n",
      "loss: 1.857814  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.848279 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.877045  [    0/60000]\n",
      "loss: 1.852387  [ 6400/60000]\n",
      "loss: 1.725277  [12800/60000]\n",
      "loss: 1.772789  [19200/60000]\n",
      "loss: 1.651121  [25600/60000]\n",
      "loss: 1.617464  [32000/60000]\n",
      "loss: 1.632947  [38400/60000]\n",
      "loss: 1.532744  [44800/60000]\n",
      "loss: 1.562259  [51200/60000]\n",
      "loss: 1.466065  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.478508 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.541079  [    0/60000]\n",
      "loss: 1.518708  [ 6400/60000]\n",
      "loss: 1.361943  [12800/60000]\n",
      "loss: 1.436895  [19200/60000]\n",
      "loss: 1.315140  [25600/60000]\n",
      "loss: 1.326918  [32000/60000]\n",
      "loss: 1.337177  [38400/60000]\n",
      "loss: 1.259731  [44800/60000]\n",
      "loss: 1.299541  [51200/60000]\n",
      "loss: 1.214085  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.228425 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.298147  [    0/60000]\n",
      "loss: 1.294436  [ 6400/60000]\n",
      "loss: 1.120747  [12800/60000]\n",
      "loss: 1.227603  [19200/60000]\n",
      "loss: 1.100790  [25600/60000]\n",
      "loss: 1.139673  [32000/60000]\n",
      "loss: 1.158362  [38400/60000]\n",
      "loss: 1.090639  [44800/60000]\n",
      "loss: 1.135843  [51200/60000]\n",
      "loss: 1.065136  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.072474 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97839",
   "metadata": {},
   "source": [
    "### Save Model State Dict\n",
    "This is the [currently recommended save format](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5d24de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_weights.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")\n",
    "print(\"Saved PyTorch Model State to model_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416bbef",
   "metadata": {},
   "source": [
    "### Save Entire Model\n",
    "This saves the entire model using python pickle, but has the [following disadvantage](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model):\n",
    "> The serialized data is bound to the specific classes and the exact directory structure used when the model is saved... Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87098c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac221ca7-e227-4c8c-8577-1eeda4a61fc7",
   "metadata": {},
   "source": [
    "### Save Model as TorchScript\n",
    "This saves an [intermediate representation of the compute graph](https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format), which does not require pickle (or even python).  However, this currently doesn't work with spark, which uses pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d9b3a45-7618-43e4-8bd3-8bb317a484d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd01550-c72e-47f2-abe6-e14f26b06fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted.save(\"model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8916-f437-4a2a-9bf4-14ff5376d305",
   "metadata": {},
   "source": [
    "### Load Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe3b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_state = NeuralNetwork()\n",
    "model_from_state.load_state_dict(torch.load(\"model_weights.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c405bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "model_from_state.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model_from_state(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708f5e0",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc5bce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc219a56-4abd-4b61-9f9a-686dae7c9614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = new_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c482a-1c5d-4bf2-bc3f-8a4e53d442b5",
   "metadata": {},
   "source": [
    "### Load Torchscript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef3c419e-d384-446c-b07b-1af93e07d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model = torch.jit.load(\"model.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "038af830-a360-45eb-ab4e-b1adab0af164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = ts_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918393",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1daec3",
   "metadata": {},
   "source": [
    "### Convert numpy dataset to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f063cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c828393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), dtype('float64'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7760bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2         3    4         5         6    7         8     \n",
       "0     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000  \\\n",
       "1     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.003922   \n",
       "3     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "4     0.0  0.0  0.0  0.007843  0.0  0.003922  0.003922  0.0  0.000000   \n",
       "...   ...  ...  ...       ...  ...       ...       ...  ...       ...   \n",
       "9995  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9996  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9997  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9998  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9999  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "           9    ...       774       775  776       777       778       779   \n",
       "0     0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  \\\n",
       "1     0.000000  ...  0.007843  0.011765  0.0  0.011765  0.682353  0.741176   \n",
       "2     0.000000  ...  0.643137  0.227451  0.0  0.000000  0.000000  0.000000   \n",
       "3     0.082353  ...  0.003922  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "4     0.000000  ...  0.278431  0.047059  0.0  0.000000  0.000000  0.000000   \n",
       "...        ...  ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9996  0.121569  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9997  0.000000  ...  0.105882  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9998  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9999  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "           780  781  782  783  \n",
       "0     0.000000  0.0  0.0  0.0  \n",
       "1     0.262745  0.0  0.0  0.0  \n",
       "2     0.000000  0.0  0.0  0.0  \n",
       "3     0.000000  0.0  0.0  0.0  \n",
       "4     0.000000  0.0  0.0  0.0  \n",
       "...        ...  ...  ...  ...  \n",
       "9995  0.000000  0.0  0.0  0.0  \n",
       "9996  0.000000  0.0  0.0  0.0  \n",
       "9997  0.000000  0.0  0.0  0.0  \n",
       "9998  0.000000  0.0  0.0  0.0  \n",
       "9999  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf784 = pd.DataFrame(data)\n",
    "pdf784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7d2bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 187 ms, sys: 56.7 ms, total: 244 ms\n",
      "Wall time: 239 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   data\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...\n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4     [0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...\n",
       "...                                                 ...\n",
       "9995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "pdf1 = pd.DataFrame()\n",
    "pdf1['data'] = pdf784.values.tolist()\n",
    "pdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20c3b86a-8b61-4128-ab61-0199fd3437cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Spark DataFrame from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4863d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 40.7 ms, total: 236 ms\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(\"data\",ArrayType(FloatType()), True)])\n",
    "df = spark.createDataFrame(pdf1, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "406edba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "831f4a01-3a49-4114-b9a0-2ae54526d72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 40.6 ms, total: 285 ms\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(str(x), FloatType(), True) for x in range(784)])\n",
    "df784 = spark.createDataFrame(pdf784, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7448",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8ebae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/09 09:57:18 WARN TaskSetManager: Stage 0 contains a task of very large size (4030 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 ms, sys: 204 µs, total: 15.5 ms\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.write.mode(\"overwrite\").parquet(\"fashion_mnist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922314ce-2996-4666-9fc9-bcd98d16bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/09 09:57:21 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/05/09 09:57:22 WARN TaskSetManager: Stage 1 contains a task of very large size (7847 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 1:============================================>              (6 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 ms, sys: 0 ns, total: 19.5 ms\n",
      "Wall time: 3.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df784.write.mode(\"overwrite\").parquet(\"fashion_mnist_784\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688429e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "088cb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c77eb4-7bd6-40c7-9a35-ee899a66ece3",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59395856-a588-43c6-93c8-c83100716ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1 columns of 784 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "133cc9a5-64c6-4820-807e-b87cf7e0b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79b151d9-d112-43b6-a479-887e2fd0e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cabcd546-2e8e-40d0-8b79-7598a7a83aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73dc73cb-25e3-4798-a019-e1abd684eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using {} device\".format(device))\n",
    "    model = torch.jit.load(\"/home/leey/devpub/leewyang/sparkext/examples/pytorch/model.ts\")\n",
    "    model.to(device)\n",
    "    \n",
    "    def predict(inputs: np.ndarray):\n",
    "        torch_inputs = torch.from_numpy(inputs).to(device)\n",
    "        outputs = model(torch_inputs)\n",
    "        return outputs.detach().numpy()\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df68cca1-2d47-4e88-8aad-9899402aee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(predict_batch_fn,\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63555b3b-3673-4712-97aa-fd728c6c4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 651 ms, sys: 101 ms, total: 753 ms\n",
      "Wall time: 5.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dbf058a-70d6-4199-af9d-13843d078950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 486 ms, sys: 130 ms, total: 615 ms\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f5ed801-6ca5-43a0-bf9c-2535a0dfe2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 775 ms, sys: 77.2 ms, total: 852 ms\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbec03-9b64-46c4-a748-f889be571384",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1f1e5fd-5866-4b78-b9d3-709e6b383a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds[0].preds\n",
    "img = preds[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76b76502-adb7-45ec-a365-2e61cdd576fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c163953a-1504-444f-b39f-86b61d34e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc0fad05-50ab-4ae5-b9fd-e50133c4c92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56f36efb-e3a2-49f9-b9fb-1657bc25e5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0282938480377197,\n",
       " -2.5728402137756348,\n",
       " 2.186373233795166,\n",
       " -0.5846771001815796,\n",
       " 2.186190605163574,\n",
       " -1.420069932937622,\n",
       " 2.110525608062744,\n",
       " -3.175826072692871,\n",
       " 1.546919584274292,\n",
       " -1.4171236753463745]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca1195-ea0f-405f-87fe-857e5c0c76a5",
   "metadata": {},
   "source": [
    "### 784 columns of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0ab0af6-b5c9-4b74-9dd6-baa7737cc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_784\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13ae45dc-85a0-4864-8a58-9dc29ae4efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 159 ms, total: 1.24 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b3fb48b-f871-41f2-ac57-346899a6fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 825 ms, sys: 171 ms, total: 997 ms\n",
      "Wall time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a43f3a7e-c6ef-4eaa-bfa8-8ca09cab7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should raise ValueError\n",
    "# preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48ec42-0df6-4e6a-b019-1270ab71d2cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d815c701-9f5b-422c-b3f9-fbc30456953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b571b742-5079-42b2-8524-9181a0dec2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = preds.iloc[0]\n",
    "predictions = sample.preds\n",
    "img = sample.drop('preds').to_numpy(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d33d6a4e-e6b9-489d-ac21-c4eddc801784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d10061e-aca6-4f81-bdfe-72e327ed7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01f70e08-2c1d-419f-8676-3f6f4aba760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df3DU9b3v8ddmkywhLsEIySYScqMF6zUczlUsyFEJTs2Y3uFWsedivacDd6qjIzDDpI5TZHqb6R+kY0eGPzhS9cyhcAstZ3rV2oER04OEWkoPcuVIqUexxEuUpCkR8guyye5+7x8cMyeA4Pvj7n6S7PMxszNkd998P/nmm33lm919JRQEQSAAADzI870AAEDuIoQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeJPvewEXS6VSOnXqlKLRqEKhkO/lAACMgiBQX1+fKisrlZd35XOdMRdCp06dUlVVle9lAAC+oPb2ds2YMeOK9xlzIRSNRiVJd+pryleB59Ug7fLC9plU0r6Z4sn27Ug6899qzTPD958xz0R+MdU8Ex60N2xFf/sn84wkJT+xf05OXH7bkc2msbG+vjEqoWG9qd0jj+dXkrEQeu655/SjH/1IHR0duuWWW7Rx40bdddddV5379Fdw+SpQfogQmnBCDiEUsj91mRcqtG9HUrhwknkmNTli306BfTv5SfuDW36e234IZet7z+lX7mM8hLK5vrHq33fB53lKJSMvTNi5c6fWrFmjdevW6e2339Zdd92lhoYGnTx5MhObAwCMUxkJoQ0bNujb3/62HnnkEd18883auHGjqqqqtHnz5kxsDgAwTqU9hIaGhnT48GHV19ePur6+vl4HDhy45P7xeFy9vb2jLgCA3JD2EDp9+rSSyaTKy8tHXV9eXq7Ozs5L7t/c3KySkpKRC6+MA4DckbE3q178hFQQBJd9kmrt2rXq6ekZubS3t2dqSQCAMSbtr46bNm2awuHwJWc9XV1dl5wdSVIkElEkYn91EQBg/Ev7mVBhYaFuu+02tbS0jLq+paVFCxcuTPfmAADjWEbeJ9TY2Khvfetbmjdvnu644w698MILOnnypB5//PFMbA4AME5lJISWLVum7u5u/eAHP1BHR4dqa2u1e/duVVdXZ2JzAIBxKhQEY6tjore3VyUlJarT1ydWY0K2ylgd2gVcanGyKf61280ze158zmlb/+NEg3nm1hL7i2nOpexNBtMK+swz7YOl5hlJ+sM8h4eFbD2UOFQ/hcIOTR2SgsSwfcjlezBIOcyMqYfuURLBsPbpl+rp6dGUKVOueF/+lAMAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeJORFu0JL1tlpC6yWEYavuUm88zH915nnkktOmue+dsPlphnJOl8wl6au/vULeaZKZFB88y5YXvp6ZlzReYZSSr8lf04Su6yf23L/uGweSYYHrLPZLOkNxjbhcBjDWdCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8Ca3W7Rd27CDIL3rSKNP/ucd5pn+r/U7beu269vNM/nDPeaZE932duajf5phnpGkSdG4eSYcTplnTvcWm2eGztsbvhW4HeNFUXvL99y/+zfzzNn/Ps0886cD1eaZG/7J3sQuSal/fddpzszlsWgMPw5ZcCYEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN7kdoGpqyyVDbb9bK55pmr6x+aZwb5rzDOSdLCtxjwT2Ls+FXL4Ualg8pB9SNJQPDvfEqE8+/GQV+Cw8xzF4/ay1IPHbzDP5E8aNs9cM+cT88zpuW5ln+d+u9A8M6P5gNO2chVnQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgTU4XmIbCYae5IJEwz4Rn2csdK6/rMc/8uTdqnsnLcyvGnFw8aJ4ZGrIfcomEw9cpcCiZlRQOZ6ck1KXANJl0+JnRcT8oZF9fQZG9jNTFUMJ+DDkf439z2jyTXxEzzyQ6Os0zynN7/FIq6TaXIZwJAQC8IYQAAN6kPYSampoUCoVGXWIx++kpAGDiy8hzQrfccot+/etfj3wcdnzuBQAwsWUkhPLz8zn7AQBcVUaeEzp+/LgqKytVU1Ojhx56SCdOnPjM+8bjcfX29o66AAByQ9pDaP78+dq2bZv27NmjF198UZ2dnVq4cKG6u7sve//m5maVlJSMXKqqqtK9JADAGJX2EGpoaNCDDz6oOXPm6Ktf/ap27dolSdq6detl77927Vr19PSMXNrb29O9JADAGJXxN6sWFxdrzpw5On78+GVvj0QiikQimV4GAGAMyvj7hOLxuN59911VVFRkelMAgHEm7SH05JNPqrW1VW1tbfr973+vb3zjG+rt7dXy5cvTvSkAwDiX9l/HffTRR/rmN7+p06dPa/r06VqwYIEOHjyo6urqdG8KADDOpT2Efv7zn6f7v5wQzswrM89cE/7YPFOYby9XnTIpbp6RpL/0FZtnUinHQk24cSgileRUfJoYsr8pPZxvLxaNFNiLUgPHItcih231z5tpnpn0K3uBaV5hgXlGklKDFJgCACCJEAIAeEQIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN5k/I/ajWVByrHc0cHZWfa8n+xQuphM2bczNXLePCNJvYP2P0YYHyw0z+Tl2Usux7rAocg1z6GMNOVY3OlSfBrKs28r5XC8upaRunDZf5/MtT+sVv3KPKIgYS8rHos4EwIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3Od2irSB77cyDNXHzTDxh//IkkvafKyon95hnJOnP566xDzm0MycdPidXobwsNas7tDO7tIm7NG9L2dvnLvs7Pmz/vri22K0pPunwdTp/o/173QUt2gAAfEGEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8CbHC0yzVFYp6fqKM+YZl/LEVMr+c8XNkzvMM5L0h7wKpzmrkH03OHMpCXVZn8uhFw7bh5wPcZei2UTYPJMath+voUnmEcWKe+1Dkk6cuc48U1X5idO2chVnQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgTW4XmDrKm2RvUPzr6z42zxzo+E/mmfz8pHnm76a8a56RpNbJs8wznZ9MMc9EiobMM4FD+asrl9JTl/UVhO1f26RDoa0kpVzWNzlunjlzOmqeueG6bvPM5Hz7MSRJCZdC4Gs7zTPtU+zfF8let1LWrDXufk6cCQEAvCGEAADemENo//79WrJkiSorKxUKhfTKK6+Muj0IAjU1NamyslJFRUWqq6vTsWPH0rZgAMDEYQ6hgYEBzZ07V5s2bbrs7c8884w2bNigTZs26dChQ4rFYrr33nvV19f3hRcLAJhYzC9MaGhoUENDw2VvC4JAGzdu1Lp167R06VJJ0tatW1VeXq4dO3boscce+2KrBQBMKGl9TqitrU2dnZ2qr68fuS4SiWjRokU6cODAZWfi8bh6e3tHXQAAuSGtIdTZeeGlieXl5aOuLy8vH7ntYs3NzSopKRm5VFVVpXNJAIAxLCOvjgtd9Dr0IAguue5Ta9euVU9Pz8ilvb09E0sCAIxBaX2zaiwWk3ThjKiiomLk+q6urkvOjj4ViUQUiUTSuQwAwDiR1jOhmpoaxWIxtbS0jFw3NDSk1tZWLVy4MJ2bAgBMAOYzof7+fn3wwQcjH7e1tenIkSMqLS3VzJkztWbNGq1fv16zZs3SrFmztH79ek2ePFkPP/xwWhcOABj/zCH01ltvafHixSMfNzY2SpKWL1+un/zkJ3rqqad0/vx5PfHEEzpz5ozmz5+v119/XdGovSMKADCxmUOorq5OwRXK7EKhkJqamtTU1PRF1jWmhWZUXP1OF4lF7CWhw8mweaYwP2GeGQzsBZyStPDaE+aZ97unm2dcijsTDvtOcivudBEKZa4Q8j8KO5SrSlLgUNzpUvZZWGwvFv162RHzzP/pvNU84+qasL3IdfivbjLP5L1p3w+SMlpG6oLuOACAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHiT1r+smiuGqq7NynbicfuX5/qSHvNMn2NzdCRv2DxTHLG3Jg/EC80zKYdGZ8mt3Tpw2H95DttJOn5OLvId2reHEvbjtbjI3jh9XX6/ecaVy3fG4e6Z5pnzNxSZZ6a+aR65IOTwWWWweZszIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhgJTB/3X2ws1f/OXL9k35FCMWTG51zwzu6DYPCNJm87FzDNDibB5xq1edeLJXIXkpVzKUsMOpafxYftD0N6em80zVcVnzDOSdPqc/Xsj5fB9e3a2eURT7SMXZLCM1AVnQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDQWmDnputGd31KGGc1LRkHmmOGyf2d53nXlGkuIp++GTSNoLTPPDSfOMSwEnsi8/bC893fMne4Hp/bPfMc9I0qT8hHlm2OHYy7/ZXjw8UfCdCgDwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeUGDqIF5mL9QcdijujOTbt3Nz8SnzzP/a/bfmGUlaXf+aeeZQ3kzzTBDYy18nIpe9EDhuK5xnLxZNOBR3TiqwF4See3+qeSbxJbeft68pjJtneuKTzDNV1541z7h+bccazoQAAN4QQgAAb8whtH//fi1ZskSVlZUKhUJ65ZVXRt2+YsUKhUKhUZcFCxakbcEAgInDHEIDAwOaO3euNm3a9Jn3ue+++9TR0TFy2b179xdaJABgYjK/MKGhoUENDQ1XvE8kElEsFnNeFAAgN2TkOaF9+/aprKxMs2fP1qOPPqqurq7PvG88Hldvb++oCwAgN6Q9hBoaGrR9+3bt3btXzz77rA4dOqR77rlH8fjlX+rY3NyskpKSkUtVVVW6lwQAGKPS/j6hZcuWjfy7trZW8+bNU3V1tXbt2qWlS5decv+1a9eqsbFx5OPe3l6CCAByRMbfrFpRUaHq6modP378srdHIhFFIpFMLwMAMAZl/H1C3d3dam9vV0VFRaY3BQAYZ8xnQv39/frggw9GPm5ra9ORI0dUWlqq0tJSNTU16cEHH1RFRYU+/PBDPf3005o2bZoeeOCBtC4cADD+mUPorbfe0uLFi0c+/vT5nOXLl2vz5s06evSotm3bprNnz6qiokKLFy/Wzp07FY1G07dqAMCEYA6huro6BcFnV+ft2bPnCy1oPCiu7DPPuJQ7Ti06b5757ZkvmWe+1Ph784wknftX+3N5RYXD5pn+Qft2XAo4XbkUSbqsLxSyb8mlOFeSkg7Hq4tJ+fYC01ShfT8c63F7OuCGaLd55p14pXmmrMj+mPKXyZPNM5KUOnfOaS5T6I4DAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCANxn/y6oT0c3T/2yeaTt7nXnmvso/mmf+8f/+jXlmVnDYPCNJ51KF5pmwQxO0S0v1WOfSiO20naxsJbvbCsL2fdfRO8VpW4unv2+e+UPI3tg9JT9unum62d6YL0k6fMxtLkM4EwIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAb3K6wDS/aobT3Oxr/p955k9n7AWmMwo/Mc8Eg2HzjKsvTbIXub6e+HIGVpIb8hwaQsN5KadtDSXsDw2RgmHzzPnhAvNMUJw0zxTm22ck6aZJHeaZXwVzzDMn+u2PD2f+s1sp61S3vuKM4UwIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALzJ6QLT4Sp7aeAF9gLTcF5gnhlIRcwzBZ/YC0zD09z2w9TwB+aZ80P2wsqCsL18MpHK3s9XDr2iTsdDELhsyY1L8elw0n7sFUeGzDOhsH1t8YRbsW9puN88kxeyf20L8+zHeNc99n0nSVP/t9NYxnAmBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADe5HSB6cCMoqxtq9ChhPPdgUrzzLxF/2aeOXHsJvOMJJ2It5lnXMpIXco+E/aOS0luZaSF+fbPyWU/DCXs367JMV7kmnAoPS0sGjbP3HDtJ+YZSRpM2Qt3pxXZS0/7hieZZ6qv7zbPjEWcCQEAvCGEAADemEKoublZt99+u6LRqMrKynT//ffrvffeG3WfIAjU1NSkyspKFRUVqa6uTseOHUvrogEAE4MphFpbW7Vy5UodPHhQLS0tSiQSqq+v18DAwMh9nnnmGW3YsEGbNm3SoUOHFIvFdO+996qvry/tiwcAjG+mZzpfe+21UR9v2bJFZWVlOnz4sO6++24FQaCNGzdq3bp1Wrp0qSRp69atKi8v144dO/TYY4+lb+UAgHHvCz0n1NPTI0kqLS2VJLW1tamzs1P19fUj94lEIlq0aJEOHDhw2f8jHo+rt7d31AUAkBucQygIAjU2NurOO+9UbW2tJKmzs1OSVF5ePuq+5eXlI7ddrLm5WSUlJSOXqqoq1yUBAMYZ5xBatWqV3nnnHf3sZz+75LZQaPQ7BoIguOS6T61du1Y9PT0jl/b2dtclAQDGGac3q65evVqvvvqq9u/frxkzZoxcH4vFJF04I6qoqBi5vqur65Kzo09FIhFFIhGXZQAAxjnTmVAQBFq1apVeeukl7d27VzU1NaNur6mpUSwWU0tLy8h1Q0NDam1t1cKFC9OzYgDAhGE6E1q5cqV27NihX/7yl4pGoyPP85SUlKioqEihUEhr1qzR+vXrNWvWLM2aNUvr16/X5MmT9fDDD2fkEwAAjF+mENq8ebMkqa6ubtT1W7Zs0YoVKyRJTz31lM6fP68nnnhCZ86c0fz58/X6668rGo2mZcEAgInDFEJBcPUiyVAopKamJjU1NbmuKWsGr3WpXJR+d7rm6ne6yPlh+9Nvx3unm2cWTT9unvmX/+JYYHrevr78sGOzqJHbV1YK59nXl7L3qyoV2FcYCjlsyFG2tuSy7z7jNU5XdPp8sX1I0omhMvNMKrC/3mvYocj1zDm3AuYZFTHzTKLj8q9uTge64wAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOCN019WnSjO/JVbo3NVQdw8kx+yb6vYYTvVkdPmmfpFR8wzkvQvXTPNM9MmD5hnzgza24JdWqolKd+hqbowP2meCTtsJ1IwbJ4JHPdDPGFvdXbdVjb89XUfO83dXtRmnmmbYm+Xd3H0bKXT3MCtVeaZyC5atAEAExAhBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvMnpAtMg363A9JPByeaZU90l5pkgZS+E/K/Tj5pnSgvspaKSVBi2F3e6FotmS57D8vJcykjzE+YZlxLc4Xy3nzOTDsfecNJeeppwmCmN2o/X1z/4snlGkl7/51vNM0Ud9n2XKjCPKPqR2+PXtUdOmmfsR+vnx5kQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHiT0wWmsx87lLVt3Zil7fyTYuaZxK9nOm1rZvSMeaY/ETHPuBSEusxIUshhzqWStbhgyDyTSGXvZ8b8sL0cc+C8/WsbiQybZ2pLO8wzbxwpN89IUs13f+c0N5ZlsozUBWdCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOBNTheY4oKbS/7sNHfy3LXmmaFk2DyTCuwVoYmk689X2fmWGBguNM/kh+ylov2D9lJRSUo6lKUmhu1fW5cC02OfVJhnEjF7YWxW5dn3XShsn5GkIJm0D6UcZj4nzoQAAN4QQgAAb0wh1NzcrNtvv13RaFRlZWW6//779d577426z4oVKxQKhUZdFixYkNZFAwAmBlMItba2auXKlTp48KBaWlqUSCRUX1+vgYGBUfe777771NHRMXLZvXt3WhcNAJgYTM/Cvvbaa6M+3rJli8rKynT48GHdfffdI9dHIhHFYva/8AkAyC1f6Dmhnp4eSVJpaemo6/ft26eysjLNnj1bjz76qLq6uj7z/4jH4+rt7R11AQDkBucQCoJAjY2NuvPOO1VbWztyfUNDg7Zv3669e/fq2Wef1aFDh3TPPfcoHo9f9v9pbm5WSUnJyKWqqsp1SQCAccb5TRGrVq3SO++8ozfffHPU9cuWLRv5d21trebNm6fq6mrt2rVLS5cuveT/Wbt2rRobG0c+7u3tJYgAIEc4hdDq1av16quvav/+/ZoxY8YV71tRUaHq6modP378srdHIhFFIm5vqAMAjG+mEAqCQKtXr9bLL7+sffv2qaam5qoz3d3dam9vV0WF/V3OAICJzfSc0MqVK/XTn/5UO3bsUDQaVWdnpzo7O3X+/HlJUn9/v5588kn97ne/04cffqh9+/ZpyZIlmjZtmh544IGMfAIAgPHLdCa0efNmSVJdXd2o67ds2aIVK1YoHA7r6NGj2rZtm86ePauKigotXrxYO3fuVDQaTduiAQATg/nXcVdSVFSkPXv2fKEFAQByR263aIfs7czOm3JovA0SiQys5FLryv/Zaa6p817zTNWkM+aZnkSReaZt4DrzjCRdW3jePFNTdNo8E3ZoxJ6cZ2+C7plu33eS1BkvMc980DfNPJMM7O8SKcq3N29rrL933qGlOshgs3U2UWAKAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN7kdoHpVVrBP5ND8WmQHLtlg/f841NOc6mww/5z6Ix16PpU3rBbOW2qwP45vVFsn8kfsK/P5XMKOXbg5jkcril7R6/yHLpIB6fb93f0Q/t2JKlYJ9wGrVzKlF0fv8YYzoQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3Y647Lvj3PqSEhqUxW43k1ktmlqVuqOTgoNNckKXuODl0xwUJx+64pP1zcunQSw469A86fE6u3XFBlrrjAofuuNSgw/4esm9HkhIuC3QysbrjErqw34LPscZQ8HnulUUfffSRqqqqfC8DAPAFtbe3a8aMGVe8z5gLoVQqpVOnTikajSp0UbNsb2+vqqqq1N7erilTpnhaoX/shwvYDxewHy5gP1wwFvZDEATq6+tTZWWl8vKu/KzPmPt1XF5e3lWTc8qUKTl9kH2K/XAB++EC9sMF7IcLfO+HkpKSz3U/XpgAAPCGEAIAeBNuampq8r0Ii3A4rLq6OuXnj7nfJGYV++EC9sMF7IcL2A8XjKf9MOZemAAAyB38Og4A4A0hBADwhhACAHhDCAEAvBlXIfTcc8+ppqZGkyZN0m233abf/OY3vpeUVU1NTQqFQqMusVjM97Iybv/+/VqyZIkqKysVCoX0yiuvjLo9CAI1NTWpsrJSRUVFqqur07FjxzytNnOuth9WrFhxyfGxYMECT6vNjObmZt1+++2KRqMqKyvT/fffr/fee2/UfXLhePg8+2G8HA/jJoR27typNWvWaN26dXr77bd11113qaGhQSdPnvS9tKy65ZZb1NHRMXI5evSo7yVl3MDAgObOnatNmzZd9vZnnnlGGzZs0KZNm3To0CHFYjHde++96uvry/JKM+tq+0GS7rvvvlHHx+7du7O4wsxrbW3VypUrdfDgQbW0tCiRSKi+vl4DAwMj98mF4+Hz7AdpnBwPwTjxla98JXj88cdHXfflL385+O53v+tpRdn3/e9/P5g7d67vZXglKXj55ZdHPk6lUkEsFgt++MMfjlw3ODgYlJSUBD/+8Y99LDErLt4PQRAEy5cvD77+9a97WpEfXV1dgaSgtbU1CILcPR4u3g9BMH6Oh3FxJjQ0NKTDhw+rvr5+1PX19fU6cOCAp1X5cfz4cVVWVqqmpkYPPfSQTpw44XtJXrW1tamzs3PUsRGJRLRo0aKcOzYkad++fSorK9Ps2bP16KOPqqury/eSMqqnp0eSVFpaKil3j4eL98OnxsPxMC5C6PTp00omkyovLx91fXl5uTo7Oz2tKvvmz5+vbdu2ac+ePXrxxRfV2dmphQsXqru72/fSvPn065/rx4YkNTQ0aPv27dq7d6+effZZHTp0SPfcc4/i8bjvpWVEEARqbGzUnXfeqdraWkm5eTxcbj9I4+d4GPudDv/BxX/aIQiCS66byBoaGkb+PWfOHN1xxx268cYbtXXrVjU2NnpcmX+5fmxI0rJly0b+XVtbq3nz5qm6ulq7du3S0qVLPa4sM1atWqV33nlHb7755iW35dLx8Fn7YbwcD+PiTGjatGkKh8OX/CTT1dV1yU88uaS4uFhz5szR8ePHfS/Fm09fHcixcamKigpVV1dPyONj9erVevXVVy9ZeHIAAAIlSURBVPXGG2+M+tMvuXY8fNZ+uJyxejyMixAqLCzUbbfdppaWllHXt7S0aOHChZ5W5V88Hte7776riooK30vxpqamRrFYbNSxMTQ0pNbW1pw+NiSpu7tb7e3tE+r4CIJAq1at0ksvvaS9e/eqpqZm1O25cjxcbT9czlg9HsZNi/aUKVP0ve99T9dff70mTZqk9evX64033tCWLVs0depU38vLiieffFKRSERBEOj999/XqlWr9P777+v555+f0Pugv79ff/zjH9XZ2annn39e8+fPV1FRkYaGhjR16lQlk0k1NzfrpptuUjKZ1He+8x19/PHHeuGFFxSJRHwvP22utB/C4bCefvppRaNRJZNJHTlyRI888oiGh4e1adOmCbMfVq5cqe3bt+sXv/iFKisr1d/fr/7+foXDYRUUFCgUCuXE8XC1/dDf3z9+jgd/L8yz+/u///uguro6KCwsDG699dZRL0fMBcuWLQsqKiqCgoKCoLKyMli6dGlw7Ngx38vKuDfeeCOQdMll+fLlQRBceFnu97///SAWiwWRSCS4++67g6NHj/pddAZcaT+cO3cuqK+vD6ZPnx4UFBQEM2fODJYvXx6cPHnS97LT6nKfv6Rgy5YtI/fJhePhavthPB0P/CkHAIA34+I5IQDAxEQIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAb/4/sihjmi/e1CMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e1c07cc-b2bc-4902-a9a6-4ac7f02c5fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0282948 , -2.5728395 ,  2.186374  , -0.58467644,  2.1861913 ,\n",
       "       -1.4200702 ,  2.1105258 , -3.1758265 ,  1.5469192 , -1.417124  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001469be-f3b6-4def-bf7d-67e10393335c",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53ca290a-ccc3-4923-a292-944921bab36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab94d4d1-dac6-4474-9eb0-59478aa98f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12b5f2fc-52e9-428a-b683-6ab1b639aa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b329c-5921-436f-bfca-a382a6762da4",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e869730-3597-4074-bab0-f87768f8996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"64M\",\n",
    "            volumes={\"/home/leey/devpub/leewyang/sparkext/examples/models\": {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "            \n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4362d-7514-4b84-b238-f704a97e1e72",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "960657d0-31c9-4df6-8eb8-ac3d23137f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0262fd4a-9845-44b9-8c75-1c105e7deeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"fashion_mnist\"),\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc5f6baa-052e-4b89-94b6-4821cf01952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 673 ms, sys: 88.9 ms, total: 762 ms\n",
      "Wall time: 3.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a85dea35-e41d-482d-8a8f-52d3c108f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 520 ms, sys: 85.1 ms, total: 605 ms\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc3f0dbe-c52b-41d6-8097-8cebaa5ee5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 804 ms, sys: 85.3 ms, total: 889 ms\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26690a-9dc4-4c36-9904-568d73e2be3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab2fe42f-a072-4370-bac2-52fd95363530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0608fff-7cfb-489e-96c9-8e1d92e57562",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de2664-3d60-487b-90da-6d0f3b8b9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
