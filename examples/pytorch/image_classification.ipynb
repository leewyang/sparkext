{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e87c927",
   "metadata": {},
   "source": [
    "# PySpark PyTorch Inference\n",
    "\n",
    "### Image Classification\n",
    "Based on: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c942a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89aa8e-ef62-4aac-8260-4b004f2c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a97111",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af350",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c1b7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854608e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97839",
   "metadata": {},
   "source": [
    "### Save Model State Dict\n",
    "This is the [currently recommended save format](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")\n",
    "print(\"Saved PyTorch Model State to model_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416bbef",
   "metadata": {},
   "source": [
    "### Save Entire Model\n",
    "This saves the entire model using python pickle, but has the [following disadvantage](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model):\n",
    "> The serialized data is bound to the specific classes and the exact directory structure used when the model is saved... Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87098c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac221ca7-e227-4c8c-8577-1eeda4a61fc7",
   "metadata": {},
   "source": [
    "### Save Model as TorchScript\n",
    "This saves an [intermediate representation of the compute graph](https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format), which does not require pickle (or even python).  However, this currently doesn't work with spark, which uses pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b3a45-7618-43e4-8bd3-8bb317a484d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd01550-c72e-47f2-abe6-e14f26b06fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted.save(\"model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8916-f437-4a2a-9bf4-14ff5376d305",
   "metadata": {},
   "source": [
    "### Load Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_state = NeuralNetwork()\n",
    "model_from_state.load_state_dict(torch.load(\"model_weights.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c405bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_state.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model_from_state(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708f5e0",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc219a56-4abd-4b61-9f9a-686dae7c9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = new_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c482a-1c5d-4bf2-bc3f-8a4e53d442b5",
   "metadata": {},
   "source": [
    "### Load Torchscript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c419e-d384-446c-b07b-1af93e07d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model = torch.jit.load(\"model.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038af830-a360-45eb-ab4e-b1adab0af164",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = ts_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918393",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1daec3",
   "metadata": {},
   "source": [
    "### Convert numpy dataset to Spark DataFrame (via Pandas DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c828393",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "test_pdf['data'] = test_pdf.values.tolist()\n",
    "pdf = test_pdf[['data']]\n",
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# force FloatType since Pandas uses double\n",
    "schema = StructType([StructField(\"data\",ArrayType(FloatType()), True)])\n",
    "df = spark.createDataFrame(pdf, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406edba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7448",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.write.mode(\"overwrite\").parquet(\"fashion_mnist_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688429e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d272b64",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sparkext\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efade52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c5e0b-fb7a-4b4c-9391-fbae4ec2b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b810352-dae3-419f-a8f6-d31665deebb3",
   "metadata": {},
   "source": [
    "### Using TorchScript Model\n",
    "TorchScript models do not require the model definition prior to loading, but they don't serialize well from Spark driver to executors, so we must use a `model_loader` function that is invoked on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd88a5-d9ae-4eca-9fcd-582728e574cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    return torch.jit.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0ae89-36c7-4d20-9c7b-5550aa4432c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd() / \"model.ts\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00943715-6fef-4f0f-8927-1ae0e0617247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sparkext.torch.Model(str(model_path), model_loader) \\\n",
    "            .setInputCol(\"data\") \\\n",
    "            .setOutputCol(\"preds\") \\\n",
    "            .setInputShape((-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf05247",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write.mode(\"overwrite\").parquet(\"mnist_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c61229",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf85ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(df.take(1)[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706f98f-797c-4666-bca1-b17d397a7165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db4f92-3c57-4d70-afaf-d2780d9f6683",
   "metadata": {},
   "source": [
    "### Using Saved Model\n",
    "\n",
    "Since the model is pickled, the model class must be defined before loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e47d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sparkext.torch.Model(\"model.pt\") \\\n",
    "            .setInputCol(\"data\") \\\n",
    "            .setOutputCol(\"preds\") \\\n",
    "            .setInputShape((-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c7924-cfe2-4031-a833-0e581a6ad8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a4b19-53ee-4b6a-ac0b-6712d5f43f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write.mode(\"overwrite\").parquet(\"mnist_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914ab60-437e-4265-ae77-21864a684b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba604c-1f2d-4515-955f-6a7cb5fbe8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62b2c7-5919-4df6-8612-c6d1b61986db",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(df.take(1)[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7194371-4488-4d89-89ca-aab94d6c6a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75f452-acef-4888-bbf4-7414babd22cc",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad74fe-63c9-459a-a065-df864e1d39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "from sparkext.torch import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41498941-5928-4dfa-9b1f-4320d54691b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e387bb-09bd-4f73-b3f0-24a22dbd41a2",
   "metadata": {},
   "source": [
    "### Using TorchScript Model\n",
    "TorchScript models do not require the model definition prior to loading, but they don't serialize well from Spark driver to executors, so we must use a `model_loader` function that is invoked on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827253b-978c-44e9-99cb-9c10985fbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path: str):\n",
    "    import torch\n",
    "    return torch.jit.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316689b-f0da-4ac5-934d-5e9343d35e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd() / \"model.ts\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6759c3-1f00-4b68-9800-11890cdbe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(str(model_path), model_loader=model_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb83fd-ee2b-49fa-b77d-369cd6beb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(col(\"data\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0e876-afc3-44f6-8b5f-c7ac8370a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f98f4a-308f-454d-b451-960b301f47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33edd34-d949-4a89-b11f-9fb02073d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(pred[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdbe9b-a834-41ac-919b-f6f44ffb4222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77897b3-4a3b-433b-8c33-2a888bd33992",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e807a-a7ef-403f-a53b-a7f83cfb4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a46502-6d86-4548-8441-2151d206413d",
   "metadata": {},
   "source": [
    "### Using Saved Model\n",
    "\n",
    "Since the model is pickled, the model class must be defined before loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24308ad8-bad8-478b-aee6-a21b1c01ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf4542-da40-4c4d-9d3a-ba11044aa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d9207-2a13-4c6f-a91b-4003893694d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(col(\"data\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3472355-cc23-4016-998a-acf70b195710",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15ee7a-41fc-47fd-8e82-5dfa725e1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(df.take(1)[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5ed06-9ff6-4dd1-9423-839edbd03de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17412cdd-f07a-4277-bfb4-5bd0af071803",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe93cfe-e71c-405f-bfb8-537b1905c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41aa58b-79e7-41e3-bf9d-176052df5469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
