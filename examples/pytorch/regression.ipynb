{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04d288a-f4bf-4256-8ef8-fbc3ab92f24e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Based on: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-create-a-neural-network-for-regression-with-pytorch.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75930360-c5ce-49ef-a69a-da88fa69a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02ba0a-8384-42b5-917c-53889b4a6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee64cf-a44a-4aff-82db-c64ee3a8b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644e508-5e4c-4cdd-9ed1-9235887d9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, scale_data=True):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            # Apply scaling if necessary\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X.astype(np.float32))\n",
    "            self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b55c3-dc7b-4831-9943-83efd48091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HousingDataset(X, y)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=10, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868f39d-4695-4110-91d2-6f7a09d73b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a441b60-dca4-44d2-bc1c-aa7336d704bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cff2b4-9d23-4d2b-808a-a5edb8eda135",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the MLP\n",
    "mlp = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2db3f9-5db8-4b42-89ad-e77f23c4c1fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(0, 5):  # 5 epochs at maximum\n",
    "\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 200 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace480ba-9316-49a4-9763-dc0f61f66989",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950a3ed-ffe1-477f-a84f-f71c85dbf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp, \"housing_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101c0fe-65f1-411e-9192-e8a6b585ba0d",
   "metadata": {},
   "source": [
    "### Load and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411b00f-88d2-40f5-b716-a26733c968ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mlp = torch.load(\"housing_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e226f449-2931-4492-9003-503cdc61f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46af47e-db7e-42ee-9bd3-6e7d93850be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mlp(testX).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae2c0f-1da5-45a4-bf32-ed8b562d7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae694c-0127-4a61-8630-06004866cd14",
   "metadata": {},
   "source": [
    "### Columns as separate input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e11813-cf75-448e-a46e-f210cc7f52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from inspect import signature\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7da567-65df-4895-a867-0be05de27ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3340e01-b3bc-4cce-bb21-890517e1bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2ecd8-34e2-4ed5-8bd6-c9d56c951eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, scale_data=True):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            # Apply scaling if necessary\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X.astype(np.float32))\n",
    "            self.y = torch.from_numpy(y.astype(np.float32))\n",
    "            \n",
    "            # Split dataset into separate variables\n",
    "            self.MedInc = self.X[:,0]\n",
    "            self.HouseAge = self.X[:,1]\n",
    "            self.AveRooms = self.X[:,2]\n",
    "            self.AveBedrms = self.X[:,3]\n",
    "            self.Population = self.X[:,4]\n",
    "            self.AveOccup = self.X[:,5]\n",
    "            self.Latitude = self.X[:,6]\n",
    "            self.Longitude = self.X[:,7]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.MedInc)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Note: also returning combined X for ease of use later\n",
    "        return self.MedInc[i], self.HouseAge[i], self.AveRooms[i], self.AveBedrms[i], self.Population[i], self.AveOccup[i], self.Latitude[i], self.Longitude[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f4640-e190-413e-8e01-d67492408f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = HousingDataset2(housing.data, housing.target)\n",
    "trainloader2 = torch.utils.data.DataLoader(dataset2, batch_size=10, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2179934-6ae0-4d58-ae2c-d82f90d48074",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(trainloader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3383b-fb1c-4daf-9844-88df7abf799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inc, age, rms, bdrms, pop, occup, lat, lon):       \n",
    "        combined = torch.column_stack((inc, age, rms, bdrms, pop, occup, lat, lon))\n",
    "        return self.layers(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9de54-a8da-46da-ba89-177a75227420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MLP\n",
    "mlp2 = MLP2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631116aa-e496-4125-9970-14aeb816c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(mlp2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d0581-5911-4f21-b0c8-b94523f66dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(0, 5):  # 5 epochs at maximum\n",
    "\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader2, 0):\n",
    "\n",
    "        # Get and prepare inputs\n",
    "        a,b,c,d,e,f,g,h,targets = data\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp2(a,b,c,d,e,f,g,h)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 200 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca720ac4-8b4e-489b-844f-d54dd0659755",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp2, \"housing_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b12f2-9981-477b-8c21-a652a1736fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e,f,g,h,targets = next(iter(trainloader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392da40b-4a33-4001-afdc-6a4b72631396",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2(a,b,c,d,e,f,g,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d29fb0-5923-4684-8aa6-62618e8f1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signature(mlp2.forward))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13631d1f-2c71-4bee-afcb-bd3b55ec87c5",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9937e-2c70-4d67-b95f-4d9d5ab17c12",
   "metadata": {},
   "source": [
    "### Convert dataset to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35da14-61a3-4e7b-9d4f-086bf5e931b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95148019-ea95-40e5-a529-fcdb9a06f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(housing.data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d957c-6747-4408-aac8-45305afbfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(X, columns=housing.feature_names)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32ea98-a7f1-4011-a067-700377f1717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388cce9-6469-4f5a-898a-1a0b74eec438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Spark is somehow auto-converting Pandas float32 to DoubleType(), so forcing FloatType()\n",
    "schema = StructType([\n",
    "StructField(\"MedInc\",FloatType(),True),\n",
    "StructField(\"HouseAge\",FloatType(),True),\n",
    "StructField(\"AveRooms\",FloatType(),True),\n",
    "StructField(\"AveBedrms\",FloatType(),True),\n",
    "StructField(\"Population\",FloatType(),True),\n",
    "StructField(\"AveOccup\",FloatType(),True),\n",
    "StructField(\"Latitude\",FloatType(),True),\n",
    "StructField(\"Longitude\",FloatType(),True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(pdf, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33d367-fbf9-4918-b755-5447125547c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b144f-07ce-45b3-ab4f-dc26f205e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9932f-c21f-4eda-954e-26c38925ff84",
   "metadata": {},
   "source": [
    "### Save DataFrame as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bff7a-b687-4184-b3fa-b5f5b46ef5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"california_housing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261029ac-aa19-47cc-a423-ada08364f6a2",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb1ffe-43c5-4aad-b468-ef515567f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparkext\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebd1a8-bd63-454c-a3b7-32e88cbe76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"california_housing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73263f7-0529-4ca2-93f5-10a69747459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e63288-8c4e-45ea-b269-56cfae5b1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bea6ad-419c-4a66-9054-b5c45e4d114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inc, age, rms, bdrms, pop, occup, lat, lon):       \n",
    "        combined = torch.column_stack((inc, age, rms, bdrms, pop, occup, lat, lon))\n",
    "        return self.layers(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7ca36-172d-4748-a1d8-2b8e1f87d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sparkext.torch.Model(\"housing_model2.pt\") \\\n",
    "                .setInputCols(columns) \\\n",
    "                .setOutputCol(\"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f12e7d-9d24-4873-b4f5-e1258d51197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ba1f0-4e6f-43ec-9b5f-6364a91a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b07653-243b-48c3-a20b-e230002e132c",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5562968-a00c-43c6-b94f-87035dce0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from sparkext.torch import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27177f2-ed95-439c-85af-c58ed1e29aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"california_housing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f3814-5f3f-4cf5-9617-fb7c183ca1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375a6b2-8380-4de7-abc9-dc54dba40801",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a4f0d-0aa5-4f6d-b818-96b9bd5b20cf",
   "metadata": {},
   "source": [
    "### Using Saved Model\n",
    "\n",
    "Since the model is pickled, the model class must be defined before loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24308ad8-bad8-478b-aee6-a21b1c01ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inc, age, rms, bdrms, pop, occup, lat, lon):       \n",
    "        combined = torch.column_stack((inc, age, rms, bdrms, pop, occup, lat, lon))\n",
    "        return self.layers(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf4542-da40-4c4d-9d3a-ba11044aa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model_udf(\"housing_model2.pt\", input_columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d9207-2a13-4c6f-a91b-4003893694d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(*columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0e808-6bb2-4a0c-ac52-02e2d0d464da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3472355-cc23-4016-998a-acf70b195710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.show(truncate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba5bf2-854d-457d-8ea2-adbed539ff21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
