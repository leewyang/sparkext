{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96e58e7-51d0-486f-85ad-51dc18735e15",
   "metadata": {},
   "source": [
    "# DL API Pydoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf63025-da3e-4d22-b55c-9c1f9cefc2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://leey-dt.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0-SNAPSHOT</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://leey-dt:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f26cdec5220>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29b85c-8a0f-41af-ad72-e571926bd876",
   "metadata": {},
   "source": [
    "### Example (tensor column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9232e9-7930-4514-b702-ccde884341e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac22524-d92d-48bd-951c-d0c8142c9803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                data|\n",
      "+--------------------+\n",
      "|[0.0, 0.0, 0.0, 0...|\n",
      "|[0.0, 0.0, 0.0, 0...|\n",
      "|[0.0, 0.0, 0.0, 0...|\n",
      "|[0.0, 0.0, 0.0, 0...|\n",
      "|[0.0, 0.0, 0.0, 0...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_mnist_fn():\n",
    "    # load/init happens once per python worker\n",
    "    import tensorflow as tf\n",
    "    model = tf.keras.models.load_model('/home/leey/devpub/leewyang/sparkext/examples/tensorflow/mnist_model')\n",
    "\n",
    "    # predict on batches of tasks/partitions, using cached model\n",
    "    def predict(inputs: np.ndarray) -> np.ndarray:\n",
    "        # inputs.shape = [batch_size, 784]\n",
    "        # outputs.shape = [batch_size, 10], return_type = ArrayType(FloatType())\n",
    "        return model.predict(inputs)\n",
    "\n",
    "    return predict\n",
    "\n",
    "mnist_udf = predict_batch_udf(make_mnist_fn,\n",
    "                              return_type=ArrayType(FloatType()),\n",
    "                              batch_size=100,\n",
    "                              input_tensor_shapes=[[784]])\n",
    "\n",
    "df = spark.read.parquet(\"/home/leey/devpub/leewyang/sparkext/examples/tensorflow/mnist_test\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a332f260-2d07-41f4-beb6-681535ec0531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                data|               preds|\n",
      "+--------------------+--------------------+\n",
      "|[0.0, 0.0, 0.0, 0...|[1.4888417, -9.10...|\n",
      "|[0.0, 0.0, 0.0, 0...|[-7.9047585, -3.5...|\n",
      "|[0.0, 0.0, 0.0, 0...|[13.611437, -14.1...|\n",
      "|[0.0, 0.0, 0.0, 0...|[17.657278, -18.9...|\n",
      "|[0.0, 0.0, 0.0, 0...|[-9.834987, -10.8...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"preds\", mnist_udf(\"data\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2ed60-6eac-4aeb-967a-2182dfd135e8",
   "metadata": {},
   "source": [
    "### Example (scalar column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f42cdd-bdb3-4b39-bee9-7f2a64eef246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  0|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "df = spark.createDataFrame(pd.DataFrame(np.arange(100)))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d5ce0c-1b4c-4ee3-88aa-d267cdc94a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  0| x2|\n",
      "+---+---+\n",
      "|  0|0.0|\n",
      "|  1|2.0|\n",
      "|  2|4.0|\n",
      "|  3|6.0|\n",
      "|  4|8.0|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def make_times_two_fn():\n",
    "    def predict(inputs: np.ndarray) -> np.ndarray:\n",
    "        # inputs.shape = [batch_size]\n",
    "        # outputs.shape = [batch_size], return_type = FloatType()\n",
    "        return inputs * 2\n",
    "\n",
    "    return predict\n",
    "\n",
    "times_two_udf = predict_batch_udf(make_times_two_fn,\n",
    "                                  return_type=FloatType(),\n",
    "                                  batch_size=10)\n",
    "\n",
    "df = spark.createDataFrame(pd.DataFrame(np.arange(100)))\n",
    "df.withColumn(\"x2\", times_two_udf(\"0\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3522af-550e-4424-b501-556e2e5a7190",
   "metadata": {},
   "source": [
    "### Example (multiple scalar columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "708a83ee-ed91-437d-b2f8-d58e9cf04c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+\n",
      "|   a|   b|   c|   d|\n",
      "+----+----+----+----+\n",
      "| 0.0| 1.0| 2.0| 3.0|\n",
      "| 4.0| 5.0| 6.0| 7.0|\n",
      "| 8.0| 9.0|10.0|11.0|\n",
      "|12.0|13.0|14.0|15.0|\n",
      "|16.0|17.0|18.0|19.0|\n",
      "+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import array\n",
    "\n",
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "pdf = pd.DataFrame(data, columns=['a','b','c','d'])\n",
    "df = spark.createDataFrame(pdf)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d38ae2b-00d0-4885-808a-c826b0d991d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|   a|   b|   c|   d| sum|\n",
      "+----+----+----+----+----+\n",
      "| 0.0| 1.0| 2.0| 3.0| 6.0|\n",
      "| 4.0| 5.0| 6.0| 7.0|22.0|\n",
      "| 8.0| 9.0|10.0|11.0|38.0|\n",
      "|12.0|13.0|14.0|15.0|54.0|\n",
      "|16.0|17.0|18.0|19.0|70.0|\n",
      "+----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def make_sum_fn():\n",
    "    def predict(inputs: np.ndarray) -> np.ndarray:\n",
    "        # inputs.shape = [batch_size, 4]\n",
    "        # outputs.shape = [batch_size], return_type = FloatType()\n",
    "        return np.sum(inputs, axis=1)\n",
    "\n",
    "    return predict\n",
    "\n",
    "sum_udf = predict_batch_udf(make_sum_fn,\n",
    "                            return_type=FloatType(),\n",
    "                            batch_size=10,\n",
    "                            input_tensor_shapes=[[4]])\n",
    "\n",
    "df.withColumn(\"sum\", sum_udf(array(\"a\", \"b\", \"c\", \"d\"))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289b9ad3-0ec2-427a-8d88-ddee30636851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|   a|   b|   c|   d| sum|\n",
      "+----+----+----+----+----+\n",
      "| 0.0| 1.0| 2.0| 3.0| 6.0|\n",
      "| 4.0| 5.0| 6.0| 7.0|22.0|\n",
      "| 8.0| 9.0|10.0|11.0|38.0|\n",
      "|12.0|13.0|14.0|15.0|54.0|\n",
      "|16.0|17.0|18.0|19.0|70.0|\n",
      "+----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def make_sum_fn():\n",
    "    def predict(x1: np.ndarray, x2: np.ndarray, x3: np.ndarray, x4: np.ndarray) -> np.ndarray:\n",
    "        # xN.shape = [batch_size]\n",
    "        # outputs.shape = [batch_size], return_type = FloatType()\n",
    "        return x1 + x2 + x3 + x4\n",
    "\n",
    "    return predict\n",
    "\n",
    "sum_udf = predict_batch_udf(make_sum_fn,\n",
    "                            return_type=FloatType(),\n",
    "                            batch_size=10)\n",
    "\n",
    "df.withColumn(\"sum\", sum_udf(\"a\", \"b\", \"c\", \"d\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d486bb-a367-4c29-9fa6-8e9dfe32e2cc",
   "metadata": {},
   "source": [
    "### Example (multiple tensor columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21538c08-803b-43cb-98c2-dd53063dfb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                  t1|                t2|\n",
      "+--------------------+------------------+\n",
      "|[0.0, 1.0, 2.0, 3.0]|   [0.0, 1.0, 2.0]|\n",
      "|[4.0, 5.0, 6.0, 7.0]|   [4.0, 5.0, 6.0]|\n",
      "|[8.0, 9.0, 10.0, ...|  [8.0, 9.0, 10.0]|\n",
      "|[12.0, 13.0, 14.0...|[12.0, 13.0, 14.0]|\n",
      "|[16.0, 17.0, 18.0...|[16.0, 17.0, 18.0]|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StructType, StructField\n",
    "from typing import Mapping\n",
    "\n",
    "data = np.arange(0, 1000, dtype=np.float64).reshape(-1, 4)\n",
    "pdf = pd.DataFrame(data, columns=['a','b','c','d'])\n",
    "pdf_tensor = pd.DataFrame()\n",
    "pdf_tensor['t1'] = pdf.values.tolist()\n",
    "pdf_tensor['t2'] = pdf.drop(columns='d').values.tolist()\n",
    "df = spark.createDataFrame(pdf_tensor)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900311b8-043c-40e4-a8ce-9d8bfc4dae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+\n",
      "|                  t1|                t2|  sum|\n",
      "+--------------------+------------------+-----+\n",
      "|[0.0, 1.0, 2.0, 3.0]|   [0.0, 1.0, 2.0]|  9.0|\n",
      "|[4.0, 5.0, 6.0, 7.0]|   [4.0, 5.0, 6.0]| 37.0|\n",
      "|[8.0, 9.0, 10.0, ...|  [8.0, 9.0, 10.0]| 65.0|\n",
      "|[12.0, 13.0, 14.0...|[12.0, 13.0, 14.0]| 93.0|\n",
      "|[16.0, 17.0, 18.0...|[16.0, 17.0, 18.0]|121.0|\n",
      "+--------------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def make_multi_sum_fn():\n",
    "    def predict(x1: np.ndarray, x2: np.ndarray) -> Mapping[str, np.dtype]:\n",
    "        # x1.shape = [batch_size, 4]\n",
    "        # x2.shape = [batch_size, 3]\n",
    "        # outputs.shape = [batch_size], result_type = FloatType()\n",
    "        return np.sum(x1, axis=1) + np.sum(x2, axis=1)\n",
    "\n",
    "    return predict\n",
    "\n",
    "# multiple tensor columns with tensor_input_shapes => list of numpy arrays\n",
    "multi_sum_udf = predict_batch_udf(\n",
    "    make_multi_sum_fn,\n",
    "    return_type=FloatType(),\n",
    "    batch_size=5,\n",
    "    input_tensor_shapes=[[4], [3]],\n",
    ")\n",
    "\n",
    "df.withColumn(\"sum\", multi_sum_udf(\"t1\", \"t2\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db18eb8-22b8-4d7f-8186-1ff401c85c40",
   "metadata": {},
   "source": [
    "### Example (multiple outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fe83e79-1002-4572-baa8-a56b7066fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----+----+\n",
      "|                  t1|                t2|sum1|sum2|\n",
      "+--------------------+------------------+----+----+\n",
      "|[0.0, 1.0, 2.0, 3.0]|   [0.0, 1.0, 2.0]| 6.0| 3.0|\n",
      "|[4.0, 5.0, 6.0, 7.0]|   [4.0, 5.0, 6.0]|22.0|15.0|\n",
      "|[8.0, 9.0, 10.0, ...|  [8.0, 9.0, 10.0]|38.0|27.0|\n",
      "|[12.0, 13.0, 14.0...|[12.0, 13.0, 14.0]|54.0|39.0|\n",
      "|[16.0, 17.0, 18.0...|[16.0, 17.0, 18.0]|70.0|51.0|\n",
      "+--------------------+------------------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def make_multi_sum_fn():\n",
    "    def predict_columnar(x1, x2):\n",
    "        # x1.shape = [batch_size, 4]\n",
    "        # x2.shape = [batch_size, 3]\n",
    "        return {\n",
    "            \"sum1\": np.sum(x1, axis=1),\n",
    "            \"sum2\": np.sum(x2, axis=1)\n",
    "        }  # return_type = StructType()\n",
    "\n",
    "    return predict_columnar\n",
    "\n",
    "sum_cols = predict_batch_udf(\n",
    "    make_multi_sum_fn,\n",
    "    return_type=StructType([\n",
    "        StructField(\"sum1\", FloatType(), True),\n",
    "        StructField(\"sum2\", FloatType(), True)\n",
    "    ]),\n",
    "    batch_size=5,\n",
    "    input_tensor_shapes=[[4], [3]],\n",
    ")\n",
    "\n",
    "df.withColumn(\"sum\", sum_cols(\"t1\", \"t2\")).select(\"t1\", \"t2\", \"sum.*\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acc45ca-9381-4736-8b3b-1cb4ea95d755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----+----+\n",
      "|                  t1|                t2|sum1|sum2|\n",
      "+--------------------+------------------+----+----+\n",
      "|[0.0, 1.0, 2.0, 3.0]|   [0.0, 1.0, 2.0]| 6.0| 3.0|\n",
      "|[4.0, 5.0, 6.0, 7.0]|   [4.0, 5.0, 6.0]|22.0|15.0|\n",
      "|[8.0, 9.0, 10.0, ...|  [8.0, 9.0, 10.0]|38.0|27.0|\n",
      "|[12.0, 13.0, 14.0...|[12.0, 13.0, 14.0]|54.0|39.0|\n",
      "|[16.0, 17.0, 18.0...|[16.0, 17.0, 18.0]|70.0|51.0|\n",
      "+--------------------+------------------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def make_multi_sum_fn():\n",
    "    def predict_row(x1: np.ndarray, x2: np.ndarray) -> list[Mapping[str, float]]:\n",
    "        # x1.shape = [batch_size, 4]\n",
    "        # x2.shape = [batch_size, 3]\n",
    "        return [{'sum1': np.sum(x1[i]), 'sum2': np.sum(x2[i])} for i in range(len(x1))]\n",
    "    return predict_row\n",
    "\n",
    "multi_sum_udf = predict_batch_udf(\n",
    "    make_multi_sum_fn,\n",
    "    return_type=StructType([\n",
    "        StructField(\"sum1\", FloatType(), True),\n",
    "        StructField(\"sum2\", FloatType(), True)\n",
    "    ]),\n",
    "    batch_size=5,\n",
    "    input_tensor_shapes=[[4], [3]],\n",
    ")\n",
    "\n",
    "df.withColumn(\"sum\", multi_sum_udf(\"t1\", \"t2\")).select(\"t1\", \"t2\", \"sum.*\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e053185-7f6e-44cd-9a25-4be1a160c338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+------------------+\n",
      "|                  t1|                t2|                t1x2|              t2x2|\n",
      "+--------------------+------------------+--------------------+------------------+\n",
      "|[0.0, 1.0, 2.0, 3.0]|   [0.0, 1.0, 2.0]|[0.0, 2.0, 4.0, 6.0]|   [0.0, 2.0, 4.0]|\n",
      "|[4.0, 5.0, 6.0, 7.0]|   [4.0, 5.0, 6.0]|[8.0, 10.0, 12.0,...| [8.0, 10.0, 12.0]|\n",
      "|[8.0, 9.0, 10.0, ...|  [8.0, 9.0, 10.0]|[16.0, 18.0, 20.0...|[16.0, 18.0, 20.0]|\n",
      "|[12.0, 13.0, 14.0...|[12.0, 13.0, 14.0]|[24.0, 26.0, 28.0...|[24.0, 26.0, 28.0]|\n",
      "|[16.0, 17.0, 18.0...|[16.0, 17.0, 18.0]|[32.0, 34.0, 36.0...|[32.0, 34.0, 36.0]|\n",
      "+--------------------+------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_multi_times_two_fn():\n",
    "    def predict(x1: np.ndarray, x2: np.ndarray) -> Mapping[str, np.ndarray]:\n",
    "        # x1.shape = [batch_size, 4]\n",
    "        # x2.shape = [batch_size, 3]\n",
    "        return {\"t1x2\": x1 * 2, \"t2x2\": x2 * 2}\n",
    "    return predict\n",
    "\n",
    "multi_times_two_udf = predict_batch_udf(\n",
    "    make_multi_times_two_fn,\n",
    "    return_type=StructType([\n",
    "        StructField(\"t1x2\", ArrayType(FloatType()), True),\n",
    "        StructField(\"t2x2\", ArrayType(FloatType()), True)\n",
    "    ]),\n",
    "    batch_size=5,\n",
    "    input_tensor_shapes=[[4], [3]],\n",
    ")\n",
    "\n",
    "df.withColumn(\"x2\", multi_times_two_udf(\"t1\", \"t2\")).select(\"t1\", \"t2\", \"x2.*\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "777749fe-cf96-4d66-b2c6-bdb9d302b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(predict(t1, t2)=9.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StructType, StructField\n",
    "from typing import Mapping\n",
    "\n",
    "df = spark.createDataFrame([[[0.0, 1.0, 2.0, 3.0], [0.0, 1.0, 2.0]]], schema=[\"t1\", \"t2\"])\n",
    "\n",
    "def make_multi_sum_fn():\n",
    "    def predict(x1: np.ndarray, x2: np.ndarray) -> np.ndarray:\n",
    "        return np.sum(x1, axis=1) + np.sum(x2, axis=1)\n",
    "    return predict\n",
    "\n",
    "multi_sum_udf = predict_batch_udf(\n",
    "    make_multi_sum_fn,\n",
    "    return_type=FloatType(),\n",
    "    batch_size=1,\n",
    "    input_tensor_shapes=[[4], [3]],\n",
    ")\n",
    "\n",
    "df.select(multi_sum_udf(\"t1\", \"t2\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e2441-f030-492e-9e47-e9ebf574eece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
