{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f7ac5d-4a95-4170-a0ac-a7faac9d9ef4",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "### Text Classification using Pipelines\n",
    "\n",
    "Based on: https://huggingface.co/docs/transformers/quicktour#pipeline-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0f77b-ee1b-4477-a038-d25a4f1da0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sparkext\n",
    "\n",
    "from inspect import signature\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from sparkext.huggingface import pipeline_udf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b28d2-a5d1-4d07-8a49-8f82b808e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91fe91-b725-4564-ae93-56e3fb51e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"What can I say that hasn't been said already. I think this place is totally worth the hype.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be39eb3-462c-42ff-b8f4-09f4e4fe3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"I will not say much about this film, because there is not much to say, because there is not much there to talk about.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b2259-8a0e-4809-a8af-8b0b1d534cae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference using Spark ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b746e-d3fe-43b7-9c1a-73811e55a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence of IMDB reviews\n",
    "@pandas_udf(\"string\")\n",
    "def first_sentence(text: pd.Series) -> pd.Series:\n",
    "    return pd.Series([s.split(\".\")[0] for s in text])\n",
    "\n",
    "df = spark.read.parquet(\"imdb_test\").withColumn(\"sentence\", first_sentence(col(\"lines\"))).select(\"sentence\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436dbbec-5614-4f61-ae15-99f2071dea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sparkext.huggingface.PipelineModel(pipe, return_type=\"label string, score float\") \\\n",
    "                    .setInputCol(\"sentence\") \\\n",
    "                    .setOutputCol(\"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f1498-97fa-4ef9-8017-dc509b1049e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_model.transform(df).select(\"sentence\", \"preds.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec754596-4b40-4ef7-9771-31685be37324",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e80ad2-57a3-4c58-984d-f9cc4388f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9517f-23f3-4754-8ea2-f6f1b024a75e",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a80499-9b98-47d5-8ff5-b4af3369a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence of IMDB reviews\n",
    "@pandas_udf(\"string\")\n",
    "def first_sentence(text: pd.Series) -> pd.Series:\n",
    "    return pd.Series([s.split(\".\")[0] for s in text])\n",
    "\n",
    "df = spark.read.parquet(\"imdb_test\").withColumn(\"sentence\", first_sentence(col(\"lines\"))).select(\"sentence\").limit(100)\n",
    "df.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c2433-82d4-4526-ae50-cdd74faf29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: need to manually specify return_type per pipe output above\n",
    "classify = pipeline_udf(pipe, return_type=\"label string, score float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52de60c-a9b9-4791-a8eb-0c0134388da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "predictions = df.withColumn(\"preds\", classify(col(\"sentence\"))).select(\"sentence\", \"preds.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5510f-0f78-4aee-80de-046501cae14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d863084-101b-44ae-ac4c-c0874660e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0bd89b-ebf9-45ff-877e-0af7e4decdd8",
   "metadata": {},
   "source": [
    "### Using model loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e217b4-678a-4ee4-bfb1-eeaebd3a8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from sparkext.huggingface import pipeline_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb315c0c-e2af-4901-a963-46fa0c3f52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence of IMDB reviews\n",
    "@pandas_udf(\"string\")\n",
    "def first_sentence(text: pd.Series) -> pd.Series:\n",
    "    return pd.Series([s.split(\".\")[0] for s in text])\n",
    "\n",
    "df = spark.read.parquet(\"imdb_test\").withColumn(\"sentence\", first_sentence(col(\"lines\"))).select(\"sentence\").limit(100)\n",
    "df.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93917c10-d6db-4a86-a5c3-7ac9dd61dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(task: str):\n",
    "    import torch\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    device_id = torch.cuda.current_device() if torch.cuda.is_available() else -1\n",
    "    return pipeline(task, device=device_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435ac00-1b5e-49d1-9620-5e02b5d439bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: need to manually specify return_type per pipe output above\n",
    "classify = pipeline_udf(\"text-classification\", model_loader=model_loader, return_type=\"label string, score float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd4536-3237-4cd3-9e4e-e56a9a937b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.withColumn(\"preds\", classify(col(\"sentence\"))).select(\"sentence\", \"preds.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a7c0c-9a9e-47aa-aea1-9a75a538e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212c1b7-90d1-4b61-a7ef-5a90bb787194",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92b15e-0da0-46c3-81a3-fabaedbfc42c",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69dd6a1a-f450-47f0-9dbf-ad250585a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, struct, pandas_udf\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import FloatType, StringType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9665b7b6-d7e9-4bd4-b29d-7a449ac5b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+\n",
      "|                                                                        sentence|\n",
      "+--------------------------------------------------------------------------------+\n",
      "|                                                                                |\n",
      "|              I found myself getting increasingly angry as this movie progressed|\n",
      "|                The comparisons between the 1995 version and this are inevitable|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before bl...|\n",
      "|                 Don't get me wrong, I love the TV series of League Of Gentlemen|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zani...|\n",
      "|                                                           Oh but this is woeful|\n",
      "|                           Terry Cunningham directs this Sci-Fi Network original|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me ...|\n",
      "|           Tycus is one of the worst films direct to video films that I see ever|\n",
      "|                                                                         Edge Vs|\n",
      "|       If you like bad movies (and you must to watch this one) here's a good one|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspir...|\n",
      "|                                      I was Stan in the movie \"Dreams Come True\"|\n",
      "|                                                                          this 2|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these bi...|\n",
      "|                     This is just about one of the dumbest things I've ever seen|\n",
      "|And you know why? Because they thought (or at least made horror fans think) t...|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently ...|\n",
      "+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# only use first sentence of IMDB reviews\n",
    "@pandas_udf(\"string\")\n",
    "def first_sentence(text: pd.Series) -> pd.Series:\n",
    "    return pd.Series([s.split(\".\")[0] for s in text])\n",
    "\n",
    "df = spark.read.parquet(\"imdb_test\").withColumn(\"sentence\", first_sentence(col(\"lines\"))).select(\"sentence\").limit(100)\n",
    "df.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da9d25c-5ebe-4503-bb19-154fcc047cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from transformers import pipeline\n",
    "    pipe = pipeline(\"text-classification\")\n",
    "    def predict(inputs):\n",
    "        flattened = np.squeeze(inputs).tolist()\n",
    "        return pipe(flattened)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78afef29-ee30-4267-9fb6-be2dcb86cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=StructType([\n",
    "                                 StructField(\"label\", StringType(), True),\n",
    "                                 StructField(\"score\", FloatType(), True)\n",
    "                             ]),\n",
    "                             batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bc327e-89cf-4731-82e6-e66cb93deef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "predictions = df.withColumn(\"preds\", classify(struct(\"sentence\"))).select(\"sentence\", \"preds.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a7adf1-5284-4144-a6b5-4ebf3675b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 5.15 ms, total: 20.8 ms\n",
      "Wall time: 13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf00fe1-25bf-4a82-bae5-cf4b4fd4845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+--------+----------+\n",
      "|                                                                        sentence|   label|     score|\n",
      "+--------------------------------------------------------------------------------+--------+----------+\n",
      "|                                                                                |POSITIVE|  0.748121|\n",
      "|              I found myself getting increasingly angry as this movie progressed|NEGATIVE|0.99845886|\n",
      "|                The comparisons between the 1995 version and this are inevitable|NEGATIVE| 0.9997198|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before bl...|NEGATIVE| 0.9984042|\n",
      "|                 Don't get me wrong, I love the TV series of League Of Gentlemen|POSITIVE| 0.9998311|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far|POSITIVE|0.99915516|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zani...|NEGATIVE|0.99965274|\n",
      "|                                                           Oh but this is woeful|NEGATIVE| 0.9993011|\n",
      "|                           Terry Cunningham directs this Sci-Fi Network original|POSITIVE| 0.9987205|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me ...|NEGATIVE| 0.9994948|\n",
      "|           Tycus is one of the worst films direct to video films that I see ever|NEGATIVE| 0.9997583|\n",
      "|                                                                         Edge Vs|POSITIVE|0.68308145|\n",
      "|       If you like bad movies (and you must to watch this one) here's a good one|POSITIVE|0.99366415|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspir...|POSITIVE| 0.9988261|\n",
      "|                                      I was Stan in the movie \"Dreams Come True\"|POSITIVE|  0.993824|\n",
      "|                                                                          this 2|POSITIVE|0.99790776|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these bi...|NEGATIVE|0.99970883|\n",
      "|                     This is just about one of the dumbest things I've ever seen|NEGATIVE| 0.9994136|\n",
      "|And you know why? Because they thought (or at least made horror fans think) t...|NEGATIVE| 0.9994579|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently ...|NEGATIVE| 0.5800528|\n",
      "+--------------------------------------------------------------------------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25d441-21a1-4c8b-8799-d56d98c3edc1",
   "metadata": {},
   "source": [
    "### Using Triton server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a5b06-126a-4bc4-baae-a45ea30832a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144acb8e-4c08-40fc-a9ed-f721c409ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"256M\",\n",
    "            volumes={\n",
    "                \"/home/leey/devpub/leewyang/sparkext/examples/models_hf\": {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                \"/home/leey/huggingface/cache\": {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        \n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        \n",
    "        elapsed = 0\n",
    "        timeout = 120\n",
    "        ready = False\n",
    "        while not ready and elapsed < timeout:\n",
    "            try:\n",
    "                time.sleep(5)\n",
    "                elapsed += 5\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d77ab-60d3-45eb-a9c2-dc811eca0af4",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e659ae-6a19-414a-bbbe-0a5b74b720de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, struct, pandas_udf\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import FloatType, StringType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d53fb283-bf9e-4571-8c68-b75a41f1f067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+\n",
      "|                                                                        sentence|\n",
      "+--------------------------------------------------------------------------------+\n",
      "|                                                                                |\n",
      "|              I found myself getting increasingly angry as this movie progressed|\n",
      "|                The comparisons between the 1995 version and this are inevitable|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before bl...|\n",
      "|                 Don't get me wrong, I love the TV series of League Of Gentlemen|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zani...|\n",
      "|                                                           Oh but this is woeful|\n",
      "|                           Terry Cunningham directs this Sci-Fi Network original|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me ...|\n",
      "|           Tycus is one of the worst films direct to video films that I see ever|\n",
      "|                                                                         Edge Vs|\n",
      "|       If you like bad movies (and you must to watch this one) here's a good one|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspir...|\n",
      "|                                      I was Stan in the movie \"Dreams Come True\"|\n",
      "|                                                                          this 2|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these bi...|\n",
      "|                     This is just about one of the dumbest things I've ever seen|\n",
      "|And you know why? Because they thought (or at least made horror fans think) t...|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently ...|\n",
      "+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only use first sentence of IMDB reviews\n",
    "@pandas_udf(\"string\")\n",
    "def first_sentence(text: pd.Series) -> pd.Series:\n",
    "    return pd.Series([s.split(\".\")[0] for s in text])\n",
    "\n",
    "df = spark.read.parquet(\"imdb_test\").withColumn(\"sentence\", first_sentence(col(\"lines\"))).select(\"sentence\").limit(1000)\n",
    "df.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b0cc0d-c480-4e4a-bd41-207dc314cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name].astype(np_types[i.datatype]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # convert to rows of dictionaries form\n",
    "            output_names = [o.name for o in model_meta.outputs]\n",
    "            result = []\n",
    "            for name in output_names:\n",
    "                column = [{name: v} for v in response.as_numpy(name)]\n",
    "                if result:\n",
    "                    result = [{**old, **new} for old, new in zip(result, column)]\n",
    "                else:\n",
    "                    result = column\n",
    "            return result\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3930cfcd-3284-4c6a-a9b5-36b8053fe899",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(triton_fn,\n",
    "                             triton_uri=\"localhost:8001\",\n",
    "                             model_name=\"hf_pipeline\",\n",
    "                             return_type=StructType([\n",
    "                                 StructField(\"label\", StringType(), True),\n",
    "                                 StructField(\"score\", FloatType(), True)\n",
    "                             ]),\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eecbf23-4e9e-4d4c-8645-98209b25db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 ms, sys: 4.09 ms, total: 39.2 ms\n",
      "Wall time: 5.86 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "predictions = df.withColumn(\"preds\", classify(struct(\"sentence\"))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61d79f8-661e-4d9e-a3aa-c0754b854603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|                                                                                                                sentence|   label|     score|\n",
      "+------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|                                                                                                                        |POSITIVE| 0.7481212|\n",
      "|                                                      I found myself getting increasingly angry as this movie progressed|NEGATIVE|0.99845886|\n",
      "|                                                        The comparisons between the 1995 version and this are inevitable|NEGATIVE| 0.9997198|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before blathering on about its supposed revelatio...|NEGATIVE| 0.9984042|\n",
      "|                                                         Don't get me wrong, I love the TV series of League Of Gentlemen|POSITIVE| 0.9998311|\n",
      "|                                        Made it through the first half an hour and deserved a medal for getting that far|POSITIVE|0.99915516|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zaniness was thrown it when it should have been|NEGATIVE|0.99965274|\n",
      "|                                                                                                   Oh but this is woeful|NEGATIVE| 0.9993011|\n",
      "|                                                                   Terry Cunningham directs this Sci-Fi Network original|POSITIVE| 0.9987205|\n",
      "|                      First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of \"Magnolia\"|NEGATIVE| 0.9994948|\n",
      "|                                                   Tycus is one of the worst films direct to video films that I see ever|NEGATIVE| 0.9997583|\n",
      "|                                                                                                                 Edge Vs|POSITIVE|0.68308276|\n",
      "|                                               If you like bad movies (and you must to watch this one) here's a good one|POSITIVE|0.99366415|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspiration for famous movie killers like Norm...|POSITIVE| 0.9988261|\n",
      "|                                                                              I was Stan in the movie \"Dreams Come True\"|POSITIVE|  0.993824|\n",
      "|                                                                                                                  this 2|POSITIVE|0.99790776|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated super-productions that take ov...|NEGATIVE|0.99970883|\n",
      "|                                                             This is just about one of the dumbest things I've ever seen|NEGATIVE| 0.9994136|\n",
      "|And you know why? Because they thought (or at least made horror fans think) that a bunch of obnoxious, foul-mouthed, ...|NEGATIVE| 0.9994579|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently widowed Karen Tunny (Lori Heuring) moves...|NEGATIVE| 0.5800518|\n",
      "|Greetings;<br /><br />I never thought I would see the day when I would be so disgusted by A movie that it would be a ...|NEGATIVE| 0.9981445|\n",
      "|                                                                           I saw it tonight and fell asleep in the movie|NEGATIVE| 0.9987237|\n",
      "|                  This movie was one of the most boring horror movies I have seen in a long time (and I have seen a lot)|NEGATIVE| 0.9981223|\n",
      "|This is the dreary tale of the self absorbed affair between two unlikable people, one of whom is married to someone else|NEGATIVE|0.99969375|\n",
      "|                        Okay, so I forgot to watch and only caught the last episode, thinking it was the first or second|NEGATIVE| 0.9976852|\n",
      "|                            Words cannot describe how asinine, juvenile,and repetitive this steaming pile of a series is|NEGATIVE|0.99976665|\n",
      "|Somewhere in USA, the young Clair manipulates her friends Mic, Billy and John, showing a letter that would be sent by...|NEGATIVE|0.99521154|\n",
      "|George & Mildred - The Movie lacks the talents of its TV writer John Mortimer who brings the close quarter cut and th...|NEGATIVE| 0.9996866|\n",
      "|                             This is an irredeemably stupid, boring, unimaginative, lazily put together piece of garbage|NEGATIVE|0.99981016|\n",
      "|                                             Justine cannot find the perfect mate to make her first time the perfect one|NEGATIVE|0.99786204|\n",
      "|It is fascinating how this title manages to slip by the average viewer as something new and groundbreaking (quoting s...|POSITIVE|0.92442197|\n",
      "|I haven't watched this show in months, but for a while I was forced to watch it every day because I had a roommate th...|NEGATIVE|0.99288976|\n",
      "|All ambiguity about Michael Myers has withered away thanks to this series' chronic habit of arseholing about with its...|NEGATIVE|0.99911875|\n",
      "|                                                                                                             My goodness|POSITIVE|0.99984705|\n",
      "|                               This movie was playing on Lifetime Movie Network last month and I decided to check it out|POSITIVE| 0.9986909|\n",
      "|                                              After reading the book, Heart of Darkness, the movie did not do it justice|NEGATIVE|  0.999744|\n",
      "|I was aware of Man of the Year's critical pans and unremarkable gross, but was prepared to give the film the benefit ...|NEGATIVE|0.70504147|\n",
      "|I am a usually a very generous voter on IMDb and don't bother commenting on movies I did not like, but this was just ...|NEGATIVE|0.99719006|\n",
      "|                                                    This is one of the most ridiculous westerns that Hollywood ever made|NEGATIVE| 0.9992816|\n",
      "|At first I thought that this one was supposed to be somewhat of a comedy/horror when I had seen the body in the batht...|NEGATIVE|0.99978954|\n",
      "|After huge budget disaster films set in America like The Day After Tomorrow and Deep Impact, it was refreshing to see...|POSITIVE|0.99945635|\n",
      "|                     Even though I tried to avoid German films recently, positive reviews lured me into renting this one|NEGATIVE|0.91780525|\n",
      "|The Jaws rip off is the trashiest of the all the Italian 'genres', and director Joe D'Amato is second only to the gre...|NEGATIVE| 0.9952494|\n",
      "|                                   If I wouldn't have had any expectations of this film, it might have received a 5 or 6|NEGATIVE|0.99143183|\n",
      "|This was more of a love story than one about an angel who comes down here to earth, although both angles of that stor...|POSITIVE| 0.9951733|\n",
      "|               Silly Disney film about a college student who accidentally discovers a potion that makes things invisible|NEGATIVE| 0.9697155|\n",
      "|                                           Who gave these people money to make a movie? There was nothing funny about it|NEGATIVE| 0.9997385|\n",
      "|                                                                                                                   worst|NEGATIVE| 0.9998017|\n",
      "|This Swedish splatter movie tries to parody/imitate American horror films such as \"The Evil Dead\", \"Gremlins\" and others|NEGATIVE| 0.9994104|\n",
      "|                                                            Someone told me that Pink Flamingos was, in a word, \"insane\"|NEGATIVE| 0.9949151|\n",
      "+------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"preds\", classify(struct(\"sentence\"))).select(\"sentence\", \"preds.*\").show(n=50, truncate=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197c146-1794-47f0-bcd9-7e8d8ab8625f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "425d3b28-7705-45ba-8a18-ad34fc895219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f19643c-4ee4-44f2-b762-2078c0c8eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8beca-5682-45fd-be52-2bff679eae2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
