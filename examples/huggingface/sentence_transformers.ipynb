{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "### Sentence Transformers\n",
    "\n",
    "From: https://huggingface.co/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "#Sentences we want to encode. Example:\n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    "\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embedding = model.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eea5ca-3cf7-46e3-b40c-598538112d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a1dac-83e4-4c01-9a57-63ca8f5b0a41",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb461ee-b4ea-43cb-b8c1-67aa6c0c6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparkext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee94d9-4021-40b2-b8f7-297b041b1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7da12-544a-46ad-906e-69d180200a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64477925-b381-4c8f-801d-e22a78c08eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed06084-cc50-4c74-a556-ac0c2fdd0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sparkext.huggingface.SentenceTransformerModel(model) \\\n",
    "                .setInputCol(\"lines\") \\\n",
    "                .setOutputCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d060f-fd31-4286-8a17-5f3dc38bd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = my_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda76ad-18df-4d95-9c3c-ead09f3e86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750828cb-cd24-4ef0-9a66-04bf1948c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a136a1-3a22-456c-b9b1-176726aae552",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684117e-b912-4e0e-a2f9-bdf99bd3047d",
   "metadata": {},
   "source": [
    "### Using model instance on driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57079c-45e1-40a7-acfe-65d31d537f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from sparkext.huggingface import sentence_transformer_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30374c-2d98-4fa3-b7b5-f639036f677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb5938e-d8dd-462e-a00d-eb75d09ca6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b0916-6568-498f-a989-ea143bf104a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce43b02-75f4-4cf6-a2bf-4d3c72035cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = sentence_transformer_udf(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c291fb-32a4-48ef-a200-ac663f20bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d850b-7253-4959-8543-74f01af5d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12480bfe-8374-4349-9bea-3ff2cf9ce8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464c686-2e45-4e60-b3ec-28b82b5636e3",
   "metadata": {},
   "source": [
    "### Using model_id string on driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cde267-45a2-4d4e-a7b6-50d9e4b696a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from sparkext.huggingface import sentence_transformer_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8741df-0325-4f15-9ddb-ae79f40d3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed1ab8-7d11-404e-a365-61d2d53b53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = sentence_transformer_udf(\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95b0e9-9ad9-423a-8bb9-8a3c6ab2fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e485325-ed4a-4005-b0b2-12f5b3e8cb1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d154f63-6c8e-4566-8864-f36c997598e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc6f3d-50d6-4fa5-9a18-2fc6fe4b3898",
   "metadata": {},
   "source": [
    "### Using model loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03de6b-9dc9-4aef-b1c1-e8e87f823a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from sparkext.huggingface import sentence_transformer_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab46571-c637-44aa-8c50-2f9a3d7a4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0cca5-944c-4410-9162-7b7a0d645dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(model_name):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    return SentenceTransformer(model_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac08597-6599-438d-9e60-c0d15fdcba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = sentence_transformer_udf(\"paraphrase-MiniLM-L6-v2\", model_loader=model_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37539f13-b280-4352-82c9-e843709751e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6511eb-5c08-4307-9452-5baa869bb70a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1633d7-ae6e-4bfc-a0d2-ee9ab8ce9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8938317-e31e-4e8d-b2d8-f92c1b5a300c",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbda3e66-005a-4ad0-8017-c1cc7cbf0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836e5f84-12c6-4c95-838e-53de7e46a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36703d23-37a3-40df-b09a-c68206d285b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happened\" next. We will never know for sure what happened because ...|\n",
      "|I found myself getting increasingly angry as this movie progressed.<br /><br />Basically, Dr. Crawford (Dennis Hopper...|\n",
      "|The comparisons between the 1995 version and this are inevitable. Sadly, this version falls far short.<br /><br />The...|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before blathering on about its supposed revelatio...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gentlemen. It was funny, twisted and completely inspired. I was...|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far. Lots of excuses for scantily clad w...|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zaniness was thrown it when it should have b...|\n",
      "|Oh but this is woeful. One good actor after another turns in lamentable dialogue in half hearted fashion under what m...|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. All is not well in Washington state and Oregon; volcanic erupt...|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of \"Magnolia\". And then I though...|\n",
      "|Tycus is one of the worst films direct to video films that I see ever.<br /><br />I am not amazing that this product ...|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin music into the chair) 4/10 Taker Vs. Heidenreich-One of the...|\n",
      "|If you like bad movies (and you must to watch this one) here's a good one. Not quite as funny as the first, but much ...|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspiration for famous movie killers like Norm...|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the friend that worked at the factory with the main character an...|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the poorest excuses for an adaptation, ever. clearly possessing...|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated super-productions that take ov...|\n",
      "|This is just about one of the dumbest things I've ever seen. Maybe not a worst movie ever contender, but if you haven...|\n",
      "|And you know why? Because they thought (or at least made horror fans think) that a bunch of obnoxious, foul-mouthed, ...|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently widowed Karen Tunny (Lori Heuring) moves...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f780c026-0f3f-4aea-8b61-5b3dbae83fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import numpy as np\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "    def predict(inputs):\n",
    "        flattened = np.squeeze(inputs).tolist()\n",
    "        return model.encode(flattened)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c88ddc-ca19-4430-8b0e-b9fae143b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(predict_batch_fn,\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85344c22-4a4d-4cb0-8771-5836ae2794db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 ms, sys: 0 ns, total: 33.8 ms\n",
      "Wall time: 5.89 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d011c32d-ea79-4d13-9b63-9e96716dbcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.51 ms, sys: 6.32 ms, total: 13.8 ms\n",
      "Wall time: 1.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23bb885-6ab0-4471-943d-4c10414100fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.51 ms, sys: 750 Âµs, total: 9.26 ms\n",
      "Wall time: 1.14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93bc6da3-d853-4233-b805-cb4a46f4f9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 ms, sys: 2.41 ms, total: 13.3 ms\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2073616f-7151-4760-92f2-441dd0bfe9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happen...|[0.050629996, -0.19899222, 2.6855804E-4, 0.13270335, -0.1...|\n",
      "|I found myself getting increasingly angry as this movie p...|[-0.11778694, 0.08591189, -0.036073662, 0.055232063, 0.14...|\n",
      "|The comparisons between the 1995 version and this are ine...|[-0.03128382, -0.18052554, 0.024394799, -0.033730447, -0....|\n",
      "|Doesn't anyone bother to check where this kind of sludge ...|[0.1475993, -0.1878961, -0.21340893, 0.06103613, 0.140383...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gen...|[-0.19420478, 0.11641938, 0.0198595, -0.37481567, 0.05207...|\n",
      "|Made it through the first half an hour and deserved a med...|[0.105904594, 0.24451882, -0.02308792, 0.11886095, 0.0518...|\n",
      "|This movie seems a little clunky around the edges, like n...|[-0.12948102, -0.16344215, -0.2876198, -0.106285945, -0.0...|\n",
      "|Oh but this is woeful. One good actor after another turns...|[0.17870405, -0.3942062, 0.0040211934, -0.25492582, -0.26...|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. Al...|[0.0056077354, -0.21645337, 0.3479478, -0.15633495, 0.045...|\n",
      "|First the easy part: this movie is pretentious crapola!<b...|[-0.3021248, -0.06008274, -0.0011113342, 0.10290447, -0.1...|\n",
      "|Tycus is one of the worst films direct to video films tha...|[0.08535699, -0.38430452, 0.023358552, -0.25609735, 0.181...|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin...|[0.014433969, 0.090860635, -0.24186282, -0.29073125, -0.0...|\n",
      "|If you like bad movies (and you must to watch this one) h...|[-0.3808803, -0.19164646, 0.1651054, -0.1101302, -0.23371...|\n",
      "|Ed Gein, one of the most famous serial killers of all tim...|[-0.092979744, -0.06958655, -0.38250145, -0.10328238, 0.3...|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the ...|[0.1834897, -0.13936679, 0.10901367, 0.07426367, 0.122948...|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the...|[0.019682733, 0.04323908, -0.10767044, -0.34699067, 0.270...|\n",
      "|Another tiresome bore from Anthony Minghella, who seems t...|[0.15511079, -8.508954E-4, -0.106644526, -0.022700768, -0...|\n",
      "|This is just about one of the dumbest things I've ever se...|[0.116595924, -0.03326735, 0.18700723, -0.20488223, 2.068...|\n",
      "|And you know why? Because they thought (or at least made ...|[0.07326417, -0.15599199, -0.15853578, -7.800739E-4, -0.1...|\n",
      "|Having spent all of her money caring for her terminally i...|[-0.02512816, -0.29343498, -0.07579395, 0.1237835, -0.084...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d79840-e589-4310-8723-cd59ff01fa5d",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d7d4b-1a0b-4c5f-bc93-be2a039b6ea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1654cdc1-4f9a-4fd5-b7ac-6ca4215bde5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={\n",
    "                \"/home/leey/devpub/leewyang/sparkext/examples/models_hf\": {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                \"/home/leey/huggingface/cache\": {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34de5f-89f8-455e-b45e-a557a4ab0f05",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2969d502-e97b-49d6-bf80-7d177ae867cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f1e6d6-6519-49e7-8465-4419547633b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1603c004-deca-4096-9180-542d0b570dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happened\" next. We will never know for sure what happened because ...|\n",
      "|I found myself getting increasingly angry as this movie progressed.<br /><br />Basically, Dr. Crawford (Dennis Hopper...|\n",
      "|The comparisons between the 1995 version and this are inevitable. Sadly, this version falls far short.<br /><br />The...|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before blathering on about its supposed revelatio...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gentlemen. It was funny, twisted and completely inspired. I was...|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far. Lots of excuses for scantily clad w...|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zaniness was thrown it when it should have b...|\n",
      "|Oh but this is woeful. One good actor after another turns in lamentable dialogue in half hearted fashion under what m...|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. All is not well in Washington state and Oregon; volcanic erupt...|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of \"Magnolia\". And then I though...|\n",
      "|Tycus is one of the worst films direct to video films that I see ever.<br /><br />I am not amazing that this product ...|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin music into the chair) 4/10 Taker Vs. Heidenreich-One of the...|\n",
      "|If you like bad movies (and you must to watch this one) here's a good one. Not quite as funny as the first, but much ...|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspiration for famous movie killers like Norm...|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the friend that worked at the factory with the main character an...|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the poorest excuses for an adaptation, ever. clearly possessing...|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated super-productions that take ov...|\n",
      "|This is just about one of the dumbest things I've ever seen. Maybe not a worst movie ever contender, but if you haven...|\n",
      "|And you know why? Because they thought (or at least made horror fans think) that a bunch of obnoxious, foul-mouthed, ...|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently widowed Karen Tunny (Lori Heuring) moves...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29b0cc0d-c480-4e4a-bd41-207dc314cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c712b8f-6eb4-4fb8-9f0a-04feef847fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(triton_fn,\n",
    "                           triton_uri=\"localhost:8001\",\n",
    "                           model_name=\"hf_transformer\",\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           input_tensor_shapes=[[-1,1]],\n",
    "                           batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "934c1a1f-b126-45b0-9c15-265236820ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 ms, sys: 0 ns, total: 24.6 ms\n",
      "Wall time: 2.94 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "537c3371-3d79-4c9f-8179-4418e95433ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 ms, sys: 0 ns, total: 15.3 ms\n",
      "Wall time: 592 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f84cd3f6-b6a8-4142-859a-91f3c183457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 ms, sys: 0 ns, total: 10.4 ms\n",
      "Wall time: 615 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "921a4c01-e296-4406-be90-86f20c8c582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 ms, sys: 0 ns, total: 13.3 ms\n",
      "Wall time: 555 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f67584e-9c4e-474f-b6ea-7811b14d116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happen...|[0.05062989, -0.19899228, 2.6863161E-4, 0.1327033, -0.160...|\n",
      "|I found myself getting increasingly angry as this movie p...|[-0.11778692, 0.085911795, -0.036073525, 0.055232257, 0.1...|\n",
      "|The comparisons between the 1995 version and this are ine...|[-0.03128365, -0.18052553, 0.024394818, -0.033730507, -0....|\n",
      "|Doesn't anyone bother to check where this kind of sludge ...|[0.14759916, -0.18789622, -0.2134091, 0.061035916, 0.1403...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gen...|[-0.19420485, 0.116419286, 0.019859504, -0.37481552, 0.05...|\n",
      "|Made it through the first half an hour and deserved a med...|[0.105904594, 0.24451868, -0.023087794, 0.118861, 0.05184...|\n",
      "|This movie seems a little clunky around the edges, like n...|[-0.12948087, -0.1634422, -0.2876199, -0.10628595, -0.056...|\n",
      "|Oh but this is woeful. One good actor after another turns...|[0.178704, -0.39420658, 0.004021057, -0.25492573, -0.2631...|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. Al...|[0.00560789, -0.21645352, 0.34794772, -0.15633506, 0.0456...|\n",
      "|First the easy part: this movie is pretentious crapola!<b...|[-0.30212492, -0.060082667, -0.0011113272, 0.10290472, -0...|\n",
      "|Tycus is one of the worst films direct to video films tha...|[0.08535707, -0.38430452, 0.023358481, -0.25609732, 0.181...|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin...|[0.01443414, 0.09086039, -0.24186268, -0.2907313, -0.0735...|\n",
      "|If you like bad movies (and you must to watch this one) h...|[-0.38088015, -0.1916462, 0.16510548, -0.11012994, -0.233...|\n",
      "|Ed Gein, one of the most famous serial killers of all tim...|[-0.09297967, -0.069586396, -0.38250136, -0.103282444, 0....|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the ...|[0.18348958, -0.13936687, 0.109013535, 0.07426357, 0.1229...|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the...|[0.019682715, 0.043239, -0.10767033, -0.34699064, 0.27088...|\n",
      "|Another tiresome bore from Anthony Minghella, who seems t...|[0.15511078, -8.5098855E-4, -0.106644414, -0.022700703, -...|\n",
      "|This is just about one of the dumbest things I've ever se...|[0.116595626, -0.03326716, 0.18700743, -0.20488214, 2.069...|\n",
      "|And you know why? Because they thought (or at least made ...|[0.07326411, -0.155992, -0.15853566, -7.798262E-4, -0.158...|\n",
      "|Having spent all of her money caring for her terminally i...|[-0.025127873, -0.29343513, -0.07579355, 0.123783484, -0....|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0077c-785f-41af-9fa9-812e7fb63810",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8e5466b-b5dc-4fe1-9012-0c87cdd72962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82b9518-da7b-4ebc-8990-c8ab909bec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd8fed-709f-4d0e-9e73-fff284143852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
