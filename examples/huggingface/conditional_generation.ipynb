{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "## Conditional generation\n",
    "\n",
    "From: https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbccb1-3f82-425b-a82d-12d4f2f91d6e",
   "metadata": {},
   "source": [
    "### Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abfa26-02da-4d4a-a925-85b387de0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72972ade-3a97-4bb3-9efa-31039a1a9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d060a1-19ef-4101-a9a6-2fdc184e07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c79ac4-bf25-421e-b55e-020d6d9e15d5",
   "metadata": {},
   "source": [
    "### Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0dbf3-712b-4c58-85eb-261ce15bb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684fb41-9467-40c0-9d7e-a1cc867c5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2dfdb-0ad3-4d0f-81a4-268d92c53759",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      return_tensors=\"tf\").input_ids\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720158d4-e0e0-4904-b096-e5aede756afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b364b-13cb-48ea-a97a-ccfc9e408075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6db1f0-7d68-4af7-8bd6-c9fa45906c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8453111-d068-49bb-ab91-8ae3d8bcdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IMDB reviews (test) dataset\n",
    "data = IMDB(split='test')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bb49d-9a5b-4d1c-949e-24d01a7cd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nested array of string for pyspark\n",
    "lines = []\n",
    "for label, text in data:\n",
    "    # only take first sentence of IMDB review\n",
    "    lines.append([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5b472-47e8-4804-9907-772793fedb2b",
   "metadata": {},
   "source": [
    "### Create PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68121304-f1df-466e-9347-c9d2b36a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d9404-0269-476e-a9dd-1842667c915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384c762-1f79-4f60-876c-94b1f552e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba3513-82dd-47e7-8193-eb4389458757",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eec8ec-4126-4890-b957-025809fad67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e1fc8-42a3-47dd-b3c0-47efd5be1040",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20554ea5-01be-4a30-8607-db5d87786fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"512\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a1dac-83e4-4c01-9a57-63ca8f5b0a41",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb461ee-b4ea-43cb-b8c1-67aa6c0c6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sparkext\n",
    "from pyspark.sql.functions import col, pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee94d9-4021-40b2-b8f7-297b041b1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612f8a6-0f3e-4534-a280-50c4db1ec7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7da12-544a-46ad-906e-69d180200a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08396a-a30d-4baf-a3d3-727c8df91048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662e1cf-060f-4a4d-9fcb-47af89b5aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prefix, only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\")\n",
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed06084-cc50-4c74-a556-ac0c2fdd0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sparkext.huggingface.Model(model, tokenizer, \n",
    "                    max_length=128, padding=\"longest\", return_tensors=\"pt\", truncation=True, skip_special_tokens=True) \\\n",
    "                    .setInputCol(\"input\") \\\n",
    "                    .setOutputCol(\"translation\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99646d4c-9872-4831-aeb6-d09d0f03b2ba",
   "metadata": {},
   "source": [
    "# Note: the following AutoModel/string attempt doesn't work because the T5ForConditionalGeneration model actually adds a \n",
    "# language modeling head on top of the standard T5 model, where the AutoModel only loads the standard T5 model.\n",
    "# See: https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5ForConditionalGeneration\n",
    "\n",
    "my_model = sparkext.huggingface.Model(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d060f-fd31-4286-8a17-5f3dc38bd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_model.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750828cb-cd24-4ef0-9a66-04bf1948c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions.write.mode(\"overwrite\").parquet(\"imdb_translations\")\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fbd60-2bc0-4e8f-8b92-af3326cded3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eac91c-1b64-49ca-a1c3-c27dd4790a48",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF (PyTorch)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd52be5-d222-4a49-b50d-beb4f464379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from sparkext.huggingface import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1744be-443e-47b3-9959-021db568f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80796a24-ba03-4b10-86c5-8f97ae55118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a09f14-15be-46c7-88b3-7140d0473073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bc467-f8ef-4980-bb67-8e94d6f1f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32064637-092c-4e9d-a0c2-5c88a72afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8fa3f-0827-4a84-b189-3a240a10867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaf77c-a430-4aa2-b462-760b12e6a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also create a model loader function w/ model + tokenizer + kwargs\n",
    "# generate = model_udf(model_loader)\n",
    "\n",
    "# note: default return_type is 'string'\n",
    "generate = model_udf(model, tokenizer=tokenizer,\n",
    "                     max_length=128, padding=\"longest\", return_tensors=\"pt\", truncation=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1edc8-8505-4f27-949f-4271eede8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df1.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45b86d-97b9-4ae1-93d6-b11243c9a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b133e0-b4ce-4c58-a87d-ae246849407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bb3e5-a8ea-433f-89c2-e30ea0979280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d473acb-7dee-45e7-b341-18d12054a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afa21e-6bbe-4e50-b29f-433afaf79df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df2.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e786628-3b53-4efe-9a61-adabd973ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9ba57-8180-4487-a478-312faaa95c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a050bf2-8808-4b9e-b122-7ddaa6ace3f2",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF (TensorFlow)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68033d8-f949-4348-9c01-2b7ee9c525f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from sparkext.huggingface import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d1352-5648-4e0e-8084-85328ac15056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1a4ef-f592-45f7-b844-16cfd2717f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "# model = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d7fc1-00fb-4b8b-ad55-6f82c032ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5cbf0-ccbf-4400-99b1-da3bda9872be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad1ce9-e47b-4f43-9bf9-c1740a21299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ada7d-c086-44bf-b143-dd8e53d968fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335859b5-70ad-49ec-b640-ea0f1f39c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use a model_loader since spark doesn't serialize this model correctly\n",
    "def model_loader(model_id):\n",
    "    from transformers import TFT5ForConditionalGeneration\n",
    "    model = TFT5ForConditionalGeneration.from_pretrained(model_id)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_id)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ae13d-4648-43df-9484-467df763497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also create a model loader function w/ model + tokenizer + kwargs\n",
    "# generate = model_udf(model_loader)\n",
    "\n",
    "# note: default return_type for model_udf is 'string'\n",
    "generate = model_udf(\"t5-small\", tokenizer=tokenizer, model_loader=model_loader,\n",
    "                     max_length=128, padding=\"longest\", return_tensors=\"tf\", truncation=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3e433-021e-4ed0-a5e5-e654897a6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df1.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6915deb-11c8-4ac4-9bb6-4212b77bd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e36340-0208-4c38-a598-546bf4e0ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e94ac3-db63-4574-a6fc-40af81ac8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2bcdbc-ab77-40df-8216-c011128a189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8a10e-9a76-4414-a26c-f4abc9325f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df2.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67538959-9c89-4984-b469-4735955e4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d1f1d1-b7d8-4521-91b0-143464933a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a35761-f08a-4b10-8de7-7b73b4699829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
