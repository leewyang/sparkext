{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "### Conditional generation\n",
    "\n",
    "From: https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abfa26-02da-4d4a-a925-85b387de0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72972ade-3a97-4bb3-9efa-31039a1a9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6db1f0-7d68-4af7-8bd6-c9fa45906c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8453111-d068-49bb-ab91-8ae3d8bcdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IMDB reviews (test) dataset\n",
    "data = IMDB(split='test')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bb49d-9a5b-4d1c-949e-24d01a7cd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nested array of string for pyspark\n",
    "lines = []\n",
    "for label, text in data:\n",
    "    # only take first sentence of IMDB review\n",
    "    lines.append([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5b472-47e8-4804-9907-772793fedb2b",
   "metadata": {},
   "source": [
    "### Create PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68121304-f1df-466e-9347-c9d2b36a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d9404-0269-476e-a9dd-1842667c915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384c762-1f79-4f60-876c-94b1f552e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba3513-82dd-47e7-8193-eb4389458757",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eec8ec-4126-4890-b957-025809fad67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e1fc8-42a3-47dd-b3c0-47efd5be1040",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20554ea5-01be-4a30-8607-db5d87786fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"512\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a1dac-83e4-4c01-9a57-63ca8f5b0a41",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb461ee-b4ea-43cb-b8c1-67aa6c0c6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparkext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee94d9-4021-40b2-b8f7-297b041b1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612f8a6-0f3e-4534-a280-50c4db1ec7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7da12-544a-46ad-906e-69d180200a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed06084-cc50-4c74-a556-ac0c2fdd0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sparkext.huggingface.Model(model, tokenizer, prefix=\"Translate English to German: \")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99646d4c-9872-4831-aeb6-d09d0f03b2ba",
   "metadata": {},
   "source": [
    "# Note: the following AutoModel/string attempt doesn't work because the T5ForConditionalGeneration model actually adds a \n",
    "# language modeling head on top of the standard T5 model, where the AutoModel only loads the standard T5 model.\n",
    "# See: https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5ForConditionalGeneration\n",
    "\n",
    "my_model = sparkext.huggingface.Model(\"t5-small\", prefix=\"Translate English to German: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d060f-fd31-4286-8a17-5f3dc38bd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750828cb-cd24-4ef0-9a66-04bf1948c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write.mode(\"overwrite\").text(\"imdb_translations\")\n",
    "predictions.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eac91c-1b64-49ca-a1c3-c27dd4790a48",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd52be5-d222-4a49-b50d-beb4f464379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from sparkext.huggingface import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1744be-443e-47b3-9959-021db568f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80796a24-ba03-4b10-86c5-8f97ae55118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08396a-a30d-4baf-a3d3-727c8df91048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96940559-4160-4ee9-a085-8b4dc8e456ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"imdb_test\")\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662e1cf-060f-4a4d-9fcb-47af89b5aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)\n",
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaf77c-a430-4aa2-b462-760b12e6a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also create a model loader function w/ model + tokenizer + kwargs\n",
    "# generate = model_udf(model_loader)\n",
    "\n",
    "# note: default return_type is 'string'\n",
    "generate = model_udf(model, tokenizer=tokenizer,\n",
    "                     max_length=128, padding=\"longest\", return_tensors=\"pt\", truncation=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93501094-7131-43c8-b53d-7500d2892ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bb3e5-a8ea-433f-89c2-e30ea0979280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15435f0-44c0-4e8b-83bc-c7e721ac1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9ba57-8180-4487-a478-312faaa95c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
