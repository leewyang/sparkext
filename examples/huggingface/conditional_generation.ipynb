{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "## Conditional generation\n",
    "\n",
    "From: https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbccb1-3f82-425b-a82d-12d4f2f91d6e",
   "metadata": {},
   "source": [
    "### Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abfa26-02da-4d4a-a925-85b387de0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72972ade-3a97-4bb3-9efa-31039a1a9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d060a1-19ef-4101-a9a6-2fdc184e07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c79ac4-bf25-421e-b55e-020d6d9e15d5",
   "metadata": {},
   "source": [
    "### Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0dbf3-712b-4c58-85eb-261ce15bb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684fb41-9467-40c0-9d7e-a1cc867c5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2dfdb-0ad3-4d0f-81a4-268d92c53759",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      return_tensors=\"tf\").input_ids\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720158d4-e0e0-4904-b096-e5aede756afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b364b-13cb-48ea-a97a-ccfc9e408075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6db1f0-7d68-4af7-8bd6-c9fa45906c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8453111-d068-49bb-ab91-8ae3d8bcdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IMDB reviews (test) dataset\n",
    "data = IMDB(split='test')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bb49d-9a5b-4d1c-949e-24d01a7cd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nested array of string for pyspark\n",
    "lines = []\n",
    "for label, text in data:\n",
    "    # only take first sentence of IMDB review\n",
    "    lines.append([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5b472-47e8-4804-9907-772793fedb2b",
   "metadata": {},
   "source": [
    "### Create PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68121304-f1df-466e-9347-c9d2b36a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d9404-0269-476e-a9dd-1842667c915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384c762-1f79-4f60-876c-94b1f552e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba3513-82dd-47e7-8193-eb4389458757",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eec8ec-4126-4890-b957-025809fad67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e1fc8-42a3-47dd-b3c0-47efd5be1040",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20554ea5-01be-4a30-8607-db5d87786fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"512\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a1dac-83e4-4c01-9a57-63ca8f5b0a41",
   "metadata": {},
   "source": [
    "## Inference using Spark ML Model\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb461ee-b4ea-43cb-b8c1-67aa6c0c6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sparkext\n",
    "from pyspark.sql.functions import col, pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee94d9-4021-40b2-b8f7-297b041b1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612f8a6-0f3e-4534-a280-50c4db1ec7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7da12-544a-46ad-906e-69d180200a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08396a-a30d-4baf-a3d3-727c8df91048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662e1cf-060f-4a4d-9fcb-47af89b5aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prefix, only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\")\n",
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed06084-cc50-4c74-a556-ac0c2fdd0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sparkext.huggingface.Model(model, tokenizer, \n",
    "                    max_length=128, padding=\"longest\", return_tensors=\"pt\", truncation=True, skip_special_tokens=True) \\\n",
    "                    .setInputCol(\"input\") \\\n",
    "                    .setOutputCol(\"translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a931b-5bd1-4f9c-9574-1c7048d80be6",
   "metadata": {},
   "source": [
    "**Note**: \"AutoModel from string\" doesn't work here, because the T5ForConditionalGeneration model actually adds a \n",
    "language modeling head on top of the standard T5 model, where the AutoModel only loads the standard T5 model.\n",
    "See: https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5ForConditionalGeneration\n",
    "```\n",
    "my_model = sparkext.huggingface.Model(\"t5-small\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d060f-fd31-4286-8a17-5f3dc38bd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_model.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750828cb-cd24-4ef0-9a66-04bf1948c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions.write.mode(\"overwrite\").parquet(\"imdb_translations\")\n",
    "results = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fbd60-2bc0-4e8f-8b92-af3326cded3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eac91c-1b64-49ca-a1c3-c27dd4790a48",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF (PyTorch)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd52be5-d222-4a49-b50d-beb4f464379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from sparkext.huggingface import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1744be-443e-47b3-9959-021db568f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80796a24-ba03-4b10-86c5-8f97ae55118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a09f14-15be-46c7-88b3-7140d0473073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bc467-f8ef-4980-bb67-8e94d6f1f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32064637-092c-4e9d-a0c2-5c88a72afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8fa3f-0827-4a84-b189-3a240a10867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaf77c-a430-4aa2-b462-760b12e6a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: default return_type is 'string'\n",
    "generate = model_udf(model, tokenizer=tokenizer,\n",
    "                     max_length=128, padding=\"longest\", return_tensors=\"pt\", truncation=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1edc8-8505-4f27-949f-4271eede8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df1.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45b86d-97b9-4ae1-93d6-b11243c9a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b133e0-b4ce-4c58-a87d-ae246849407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bb3e5-a8ea-433f-89c2-e30ea0979280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d473acb-7dee-45e7-b341-18d12054a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afa21e-6bbe-4e50-b29f-433afaf79df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df2.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e786628-3b53-4efe-9a61-adabd973ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9ba57-8180-4487-a478-312faaa95c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a050bf2-8808-4b9e-b122-7ddaa6ace3f2",
   "metadata": {},
   "source": [
    "## Inference using Spark DL UDF (TensorFlow)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68033d8-f949-4348-9c01-2b7ee9c525f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from sparkext.huggingface import model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d1352-5648-4e0e-8084-85328ac15056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d7fc1-00fb-4b8b-ad55-6f82c032ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5cbf0-ccbf-4400-99b1-da3bda9872be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad1ce9-e47b-4f43-9bf9-c1740a21299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ada7d-c086-44bf-b143-dd8e53d968fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335859b5-70ad-49ec-b640-ea0f1f39c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use a model_loader since spark doesn't serialize this model correctly\n",
    "def model_loader(model_id):\n",
    "    from transformers import TFT5ForConditionalGeneration, T5Tokenizer\n",
    "    model = TFT5ForConditionalGeneration.from_pretrained(model_id)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_id)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ae13d-4648-43df-9484-467df763497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: default return_type for model_udf is 'string'\n",
    "generate = model_udf(\"t5-small\", tokenizer=tokenizer, model_loader=model_loader,\n",
    "                     max_length=128, padding=\"longest\", return_tensors=\"tf\", truncation=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3e433-021e-4ed0-a5e5-e654897a6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df1.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6915deb-11c8-4ac4-9bb6-4212b77bd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e36340-0208-4c38-a598-546bf4e0ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e94ac3-db63-4574-a6fc-40af81ac8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2bcdbc-ab77-40df-8216-c011128a189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8a10e-9a76-4414-a26c-f4abc9325f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df2.withColumn(\"preds\", generate(col(\"input\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67538959-9c89-4984-b469-4735955e4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d1f1d1-b7d8-4521-91b0-143464933a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4ecab-c9d9-466f-ba49-902ad1fd5488",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API (PyTorch)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a00479-1347-4de8-8431-faa77f8cdf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c483e4d4-9ab1-416f-a766-694e17490fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happened\" next. We will never know for sure what happened because ...|\n",
      "|I found myself getting increasingly angry as this movie progressed.<br /><br />Basically, Dr. Crawford (Dennis Hopper...|\n",
      "|The comparisons between the 1995 version and this are inevitable. Sadly, this version falls far short.<br /><br />The...|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before blathering on about its supposed revelatio...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gentlemen. It was funny, twisted and completely inspired. I was...|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far. Lots of excuses for scantily clad w...|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zaniness was thrown it when it should have b...|\n",
      "|Oh but this is woeful. One good actor after another turns in lamentable dialogue in half hearted fashion under what m...|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. All is not well in Washington state and Oregon; volcanic erupt...|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of \"Magnolia\". And then I though...|\n",
      "|Tycus is one of the worst films direct to video films that I see ever.<br /><br />I am not amazing that this product ...|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin music into the chair) 4/10 Taker Vs. Heidenreich-One of the...|\n",
      "|If you like bad movies (and you must to watch this one) here's a good one. Not quite as funny as the first, but much ...|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspiration for famous movie killers like Norm...|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the friend that worked at the factory with the main character an...|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the poorest excuses for an adaptation, ever. clearly possessing...|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated super-productions that take ov...|\n",
      "|This is just about one of the dumbest things I've ever seen. Maybe not a worst movie ever contender, but if you haven...|\n",
      "|And you know why? Because they thought (or at least made horror fans think) that a bunch of obnoxious, foul-mouthed, ...|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently widowed Karen Tunny (Lori Heuring) moves...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a0889a-35b4-493a-8197-1146fc7efd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831bc52c-a5c6-4c29-a6da-0566b5167773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef1d846-5852-4762-8527-602f32c0d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                           Translate English to German: |\n",
      "|                         Translate English to German: I found myself getting increasingly angry as this movie progressed|\n",
      "|                           Translate English to German: The comparisons between the 1995 version and this are inevitable|\n",
      "|Translate English to German: Doesn't anyone bother to check where this kind of sludge comes from before blathering on...|\n",
      "|                            Translate English to German: Don't get me wrong, I love the TV series of League Of Gentlemen|\n",
      "|           Translate English to German: Made it through the first half an hour and deserved a medal for getting that far|\n",
      "|Translate English to German: This movie seems a little clunky around the edges, like not quite enough zaniness was th...|\n",
      "|                                                                      Translate English to German: Oh but this is woeful|\n",
      "|                                      Translate English to German: Terry Cunningham directs this Sci-Fi Network original|\n",
      "|Translate English to German: First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of ...|\n",
      "|                      Translate English to German: Tycus is one of the worst films direct to video films that I see ever|\n",
      "|                                                                                    Translate English to German: Edge Vs|\n",
      "|                  Translate English to German: If you like bad movies (and you must to watch this one) here's a good one|\n",
      "|Translate English to German: Ed Gein, one of the most famous serial killers of all time, he was the inspiration for f...|\n",
      "|                                                 Translate English to German: I was Stan in the movie \"Dreams Come True\"|\n",
      "|                                                                                     Translate English to German: this 2|\n",
      "|Translate English to German: Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated s...|\n",
      "|                                Translate English to German: This is just about one of the dumbest things I've ever seen|\n",
      "|Translate English to German: And you know why? Because they thought (or at least made horror fans think) that a bunch...|\n",
      "|Translate English to German: Having spent all of her money caring for her terminally ill spouse, recently widowed Kar...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ae69d3-70c2-4765-928f-c96a7ba59829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import numpy as np\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    \n",
    "    def predict(inputs):\n",
    "        flattened = np.squeeze(inputs).tolist()   # convert 2d numpy array of string into flattened python list\n",
    "        input_ids = tokenizer(flattened, \n",
    "                              padding=\"longest\", \n",
    "                              max_length=128,\n",
    "                              return_tensors=\"pt\").input_ids\n",
    "        output_ids = model.generate(input_ids)\n",
    "        string_outputs = [tokenizer.decode(o, skip_special_tokens=True) for o in output_ids]\n",
    "        return string_outputs\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36684f59-d947-43f8-a2e8-c7a423764e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=StringType(),\n",
    "                             batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a01c855-8fa1-4765-a3a5-2c9dd872df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.3 ms, sys: 0 ns, total: 32.3 ms\n",
      "Wall time: 13.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08470540-fa6b-4be8-89a1-79011ad19238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 ms, sys: 0 ns, total: 18.7 ms\n",
      "Wall time: 5.77 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d912d4b0-cd0b-44ea-859a-b23455cc2700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.1 ms, sys: 0 ns, total: 40.1 ms\n",
      "Wall time: 5.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe3d88b-30f7-468f-8db8-1f4118d0f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.55 ms, sys: 4.95 ms, total: 13.5 ms\n",
      "Wall time: 5.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ad9b365-4b9a-438e-8fdf-47da55cb1cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                               Translate English to German: |                                    Übersetzen Sie Englisch.|\n",
      "|Translate English to German: I found myself getting incre...| Ich sah mich immer ärgerlicher, als dieser Film weiterging.|\n",
      "|Translate English to German: The comparisons between the ...|Die Vergleiche zwischen der Version 1995 und diese sind u...|\n",
      "|Translate English to German: Doesn't anyone bother to che...|    Warum hat man sich nicht angefreut, zu überprüfen, woher|\n",
      "|Translate English to German: Don't get me wrong, I love t...|Verstehen Sie mich nicht falsch, ich liebe die TV-Serie L...|\n",
      "|Translate English to German: Made it through the first ha...|Er hat die erste halbe Stunde durchgemacht und verdiente ...|\n",
      "|Translate English to German: This movie seems a little cl...|Dieser Film scheint etwas schlank um die Ecken zu sein, w...|\n",
      "|          Translate English to German: Oh but this is woeful|                               Oh, aber das ist beunruhigend|\n",
      "|Translate English to German: Terry Cunningham directs thi...|      Terry Cunningham leitet dieses Sci-Fi Network Original|\n",
      "|Translate English to German: First the easy part: this mo...| Zunächst der einfache Teil: dieser Film ist präzise crapola|\n",
      "|Translate English to German: Tycus is one of the worst fi...|Tycus ist einer der schlimmsten Filme direkt zu Videofilm...|\n",
      "|                        Translate English to German: Edge Vs|                                                     Edge Vs|\n",
      "|Translate English to German: If you like bad movies (and ...|Wenn Sie schlechte Filme (und Sie müssen diesen schauen) ...|\n",
      "|Translate English to German: Ed Gein, one of the most fam...|Ed Gein, einer der berühmtesten Serienmörder aller Zeiten...|\n",
      "|Translate English to German: I was Stan in the movie \"Dre...|                     Ich war Stan im Film \"Dreams Come True\"|\n",
      "|                         Translate English to German: this 2|                                                      this 2|\n",
      "|Translate English to German: Another tiresome bore from A...|Eine weitere lästige Bohrung von Anthony Minghella, der o...|\n",
      "|Translate English to German: This is just about one of th...| Das ist eines der düstersten Dinge, die ich je gesehen habe|\n",
      "|Translate English to German: And you know why? Because th...|Und Sie wissen, warum? Denn sie dachten (oder zumindest m...|\n",
      "|Translate English to German: Having spent all of her mone...|Nachdem sie ihr Geld für ihren stärksten Ehepartner ausge...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eb0c83b-d91b-4f8c-a5e7-c35f55c88108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "054f94fd-fe79-41e7-b1c7-6124083acc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                           Translate English to French: |\n",
      "|                         Translate English to French: I found myself getting increasingly angry as this movie progressed|\n",
      "|                           Translate English to French: The comparisons between the 1995 version and this are inevitable|\n",
      "|Translate English to French: Doesn't anyone bother to check where this kind of sludge comes from before blathering on...|\n",
      "|                            Translate English to French: Don't get me wrong, I love the TV series of League Of Gentlemen|\n",
      "|           Translate English to French: Made it through the first half an hour and deserved a medal for getting that far|\n",
      "|Translate English to French: This movie seems a little clunky around the edges, like not quite enough zaniness was th...|\n",
      "|                                                                      Translate English to French: Oh but this is woeful|\n",
      "|                                      Translate English to French: Terry Cunningham directs this Sci-Fi Network original|\n",
      "|Translate English to French: First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of ...|\n",
      "|                      Translate English to French: Tycus is one of the worst films direct to video films that I see ever|\n",
      "|                                                                                    Translate English to French: Edge Vs|\n",
      "|                  Translate English to French: If you like bad movies (and you must to watch this one) here's a good one|\n",
      "|Translate English to French: Ed Gein, one of the most famous serial killers of all time, he was the inspiration for f...|\n",
      "|                                                 Translate English to French: I was Stan in the movie \"Dreams Come True\"|\n",
      "|                                                                                     Translate English to French: this 2|\n",
      "|Translate English to French: Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated s...|\n",
      "|                                Translate English to French: This is just about one of the dumbest things I've ever seen|\n",
      "|Translate English to French: And you know why? Because they thought (or at least made horror fans think) that a bunch...|\n",
      "|Translate English to French: Having spent all of her money caring for her terminally ill spouse, recently widowed Kar...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f6b70f9-188a-402b-9143-78a5788140e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 ms, sys: 4.58 ms, total: 16.9 ms\n",
      "Wall time: 13.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e4afb6d-af31-4acb-b55b-d90fe5f63df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 3.72 ms, total: 19.7 ms\n",
      "Wall time: 5.83 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "031a6a5e-7999-4653-b394-19ed478d8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 ms, sys: 0 ns, total: 19 ms\n",
      "Wall time: 5.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229b6515-82f6-4e9c-90f0-a9c3cfb26301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 0 ns, total: 12.7 ms\n",
      "Wall time: 5.84 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be750ac-fa39-452e-bb4c-c2270bc2f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                               Translate English to French: |                                                           :|\n",
      "|Translate English to French: I found myself getting incre...|  Je me suis rendu de plus en plus en colère à mesure que ce|\n",
      "|Translate English to French: The comparisons between the ...|Les comparaisons entre la version de 1995 et cette versio...|\n",
      "|Translate English to French: Doesn't anyone bother to che...|          Ne s'agit-il pas de vérifier où viennent ces boues|\n",
      "|Translate English to French: Don't get me wrong, I love t...|Ne m'oubliez pas, je m'aime la série de télévision de League|\n",
      "|Translate English to French: Made it through the first ha...|                     l’issue de la première demi-heure, il a|\n",
      "|Translate English to French: This movie seems a little cl...|      Ce film semble un peu cloné autour des bords, comme il|\n",
      "|          Translate English to French: Oh but this is woeful|                           l'heure actuelle, il n'y a pas de|\n",
      "|Translate English to French: Terry Cunningham directs thi...|    Terry Cunningham dirige cette originale du réseau Sci-Fi|\n",
      "|Translate English to French: First the easy part: this mo...|Premièrement, la partie facile : ce film est pretentious ...|\n",
      "|Translate English to French: Tycus is one of the worst fi...|                Tycus est l'un des pires films directs à des|\n",
      "|                        Translate English to French: Edge Vs|                                                     Edge Vs|\n",
      "|Translate English to French: If you like bad movies (and ...|Si vous aimez des films mauvais (et vous devez regarder c...|\n",
      "|Translate English to French: Ed Gein, one of the most fam...|                  Ed Gein, l'un des assassinats en série les|\n",
      "|Translate English to French: I was Stan in the movie \"Dre...|                  Je l'étais dans le film \"Dreams Come True\"|\n",
      "|                         Translate English to French: this 2|                                                     Cette 2|\n",
      "|Translate English to French: Another tiresome bore from A...|                       Un autre ennui abusif d'Antonio Mingh|\n",
      "|Translate English to French: This is just about one of th...|                 Voilà l'un des plus dommageables que je n'a|\n",
      "|Translate English to French: And you know why? Because th...| Et vous savez pourquoi? Parce qu'ils pensaient (ou du moins|\n",
      "|Translate English to French: Having spent all of her mone...|Après avoir dépensé toute son argent pour s'occuper de so...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87ae53-b521-46c9-94b4-f757cf84dfd0",
   "metadata": {},
   "source": [
    "### Using Triton Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552865c-5dad-4f25-8834-f41e253ac2f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd00b7e-8150-4c95-a2e4-037e9c90f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"256M\",\n",
    "            volumes={\n",
    "                \"/home/leey/devpub/leewyang/sparkext/examples/models_hf\": {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                \"/home/leey/huggingface/cache\": {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d2df6-49fc-4be7-a534-a087dfe31c84",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a997c33-5202-466d-8304-b8c30f32978f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dea1875-6b95-4fc0-926d-a625a441b33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happened\" next. We will never know for sure what happened because ...|\n",
      "|I found myself getting increasingly angry as this movie progressed.<br /><br />Basically, Dr. Crawford (Dennis Hopper...|\n",
      "|The comparisons between the 1995 version and this are inevitable. Sadly, this version falls far short.<br /><br />The...|\n",
      "|Doesn't anyone bother to check where this kind of sludge comes from before blathering on about its supposed revelatio...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gentlemen. It was funny, twisted and completely inspired. I was...|\n",
      "|Made it through the first half an hour and deserved a medal for getting that far. Lots of excuses for scantily clad w...|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zaniness was thrown it when it should have b...|\n",
      "|Oh but this is woeful. One good actor after another turns in lamentable dialogue in half hearted fashion under what m...|\n",
      "|Terry Cunningham directs this Sci-Fi Network original. All is not well in Washington state and Oregon; volcanic erupt...|\n",
      "|First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of \"Magnolia\". And then I though...|\n",
      "|Tycus is one of the worst films direct to video films that I see ever.<br /><br />I am not amazing that this product ...|\n",
      "|Edge Vs. Michaels-Boring in general (loved the sweet chin music into the chair) 4/10 Taker Vs. Heidenreich-One of the...|\n",
      "|If you like bad movies (and you must to watch this one) here's a good one. Not quite as funny as the first, but much ...|\n",
      "|Ed Gein, one of the most famous serial killers of all time, he was the inspiration for famous movie killers like Norm...|\n",
      "|I was Stan in the movie \"Dreams Come True\". Stan was the friend that worked at the factory with the main character an...|\n",
      "|this 2.5 hour diluted snore-fest appears to be one of the poorest excuses for an adaptation, ever. clearly possessing...|\n",
      "|Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated super-productions that take ov...|\n",
      "|This is just about one of the dumbest things I've ever seen. Maybe not a worst movie ever contender, but if you haven...|\n",
      "|And you know why? Because they thought (or at least made horror fans think) that a bunch of obnoxious, foul-mouthed, ...|\n",
      "|Having spent all of her money caring for her terminally ill spouse, recently widowed Karen Tunny (Lori Heuring) moves...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d6c54e7-534d-406f-b8e6-fd592efd0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc1bbbe3-4232-49e5-80f6-99976524b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d10c61c-6102-4d19-8dd6-0c7b5b65343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                           Translate English to German: |\n",
      "|                         Translate English to German: I found myself getting increasingly angry as this movie progressed|\n",
      "|                           Translate English to German: The comparisons between the 1995 version and this are inevitable|\n",
      "|Translate English to German: Doesn't anyone bother to check where this kind of sludge comes from before blathering on...|\n",
      "|                            Translate English to German: Don't get me wrong, I love the TV series of League Of Gentlemen|\n",
      "|           Translate English to German: Made it through the first half an hour and deserved a medal for getting that far|\n",
      "|Translate English to German: This movie seems a little clunky around the edges, like not quite enough zaniness was th...|\n",
      "|                                                                      Translate English to German: Oh but this is woeful|\n",
      "|                                      Translate English to German: Terry Cunningham directs this Sci-Fi Network original|\n",
      "|Translate English to German: First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of ...|\n",
      "|                      Translate English to German: Tycus is one of the worst films direct to video films that I see ever|\n",
      "|                                                                                    Translate English to German: Edge Vs|\n",
      "|                  Translate English to German: If you like bad movies (and you must to watch this one) here's a good one|\n",
      "|Translate English to German: Ed Gein, one of the most famous serial killers of all time, he was the inspiration for f...|\n",
      "|                                                 Translate English to German: I was Stan in the movie \"Dreams Come True\"|\n",
      "|                                                                                     Translate English to German: this 2|\n",
      "|Translate English to German: Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated s...|\n",
      "|                                Translate English to German: This is just about one of the dumbest things I've ever seen|\n",
      "|Translate English to German: And you know why? Because they thought (or at least made horror fans think) that a bunch...|\n",
      "|Translate English to German: Having spent all of her money caring for her terminally ill spouse, recently widowed Kar...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e0907da-a5d9-4c3b-9db4-ce5e70ca9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9308bdd7-6f67-484d-8b51-dd1e1b2960ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(triton_fn,\n",
    "                             triton_uri=\"localhost:8001\",\n",
    "                             model_name=\"hf_generation\",\n",
    "                             return_type=StringType(),\n",
    "                             input_tensor_shapes=[[-1,1]],\n",
    "                             batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38484ffd-370d-492b-8ca4-9eff9f242a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 ms, sys: 20 ms, total: 33.2 ms\n",
      "Wall time: 6.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5db421ad-9bc2-4176-8936-bfd72f9ac6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 1.12 ms, total: 15 ms\n",
      "Wall time: 5.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebcb6699-3ac2-4529-ab0f-fab0a5e792da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 ms, sys: 3.72 ms, total: 14.4 ms\n",
      "Wall time: 5.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2ed18ad-d00b-472c-b2c3-047932f2105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 ms, sys: 1.5 ms, total: 14.5 ms\n",
      "Wall time: 6.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cd64a1c-beb8-47d5-ac6f-e8525bb61176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                               Translate English to German: |                                    Übersetzen Sie Englisch.|\n",
      "|Translate English to German: I found myself getting incre...| Ich sah mich immer ärgerlicher, als dieser Film weiterging.|\n",
      "|Translate English to German: The comparisons between the ...|Die Vergleiche zwischen der Version 1995 und diese sind u...|\n",
      "|Translate English to German: Doesn't anyone bother to che...|    Warum hat man sich nicht angefreut, zu überprüfen, woher|\n",
      "|Translate English to German: Don't get me wrong, I love t...|Verstehen Sie mich nicht falsch, ich liebe die TV-Serie L...|\n",
      "|Translate English to German: Made it through the first ha...|Er hat die erste halbe Stunde durchgemacht und verdiente ...|\n",
      "|Translate English to German: This movie seems a little cl...|Dieser Film scheint etwas schlank um die Ecken zu sein, w...|\n",
      "|          Translate English to German: Oh but this is woeful|                               Oh, aber das ist beunruhigend|\n",
      "|Translate English to German: Terry Cunningham directs thi...|      Terry Cunningham leitet dieses Sci-Fi Network Original|\n",
      "|Translate English to German: First the easy part: this mo...| Zunächst der einfache Teil: dieser Film ist präzise crapola|\n",
      "|Translate English to German: Tycus is one of the worst fi...|Tycus ist einer der schlimmsten Filme direkt zu Videofilm...|\n",
      "|                        Translate English to German: Edge Vs|                                                     Edge Vs|\n",
      "|Translate English to German: If you like bad movies (and ...|Wenn Sie schlechte Filme (und Sie müssen diesen schauen) ...|\n",
      "|Translate English to German: Ed Gein, one of the most fam...|Ed Gein, einer der berühmtesten Serienmörder aller Zeiten...|\n",
      "|Translate English to German: I was Stan in the movie \"Dre...|                     Ich war Stan im Film \"Dreams Come True\"|\n",
      "|                         Translate English to German: this 2|                                                      this 2|\n",
      "|Translate English to German: Another tiresome bore from A...|Eine weitere lästige Bohrung von Anthony Minghella, der o...|\n",
      "|Translate English to German: This is just about one of th...| Das ist eines der düstersten Dinge, die ich je gesehen habe|\n",
      "|Translate English to German: And you know why? Because th...|Und Sie wissen, warum? Denn sie dachten (oder zumindest m...|\n",
      "|Translate English to German: Having spent all of her mone...|Nachdem sie ihr Geld für ihren stärksten Ehepartner ausge...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af70fed8-0f2b-4ea7-841c-476afdf9b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef075e10-e22c-4236-9e0b-cb47cf2d3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                           Translate English to French: |\n",
      "|                         Translate English to French: I found myself getting increasingly angry as this movie progressed|\n",
      "|                           Translate English to French: The comparisons between the 1995 version and this are inevitable|\n",
      "|Translate English to French: Doesn't anyone bother to check where this kind of sludge comes from before blathering on...|\n",
      "|                            Translate English to French: Don't get me wrong, I love the TV series of League Of Gentlemen|\n",
      "|           Translate English to French: Made it through the first half an hour and deserved a medal for getting that far|\n",
      "|Translate English to French: This movie seems a little clunky around the edges, like not quite enough zaniness was th...|\n",
      "|                                                                      Translate English to French: Oh but this is woeful|\n",
      "|                                      Translate English to French: Terry Cunningham directs this Sci-Fi Network original|\n",
      "|Translate English to French: First the easy part: this movie is pretentious crapola!<br /><br />It put me in mind of ...|\n",
      "|                      Translate English to French: Tycus is one of the worst films direct to video films that I see ever|\n",
      "|                                                                                    Translate English to French: Edge Vs|\n",
      "|                  Translate English to French: If you like bad movies (and you must to watch this one) here's a good one|\n",
      "|Translate English to French: Ed Gein, one of the most famous serial killers of all time, he was the inspiration for f...|\n",
      "|                                                 Translate English to French: I was Stan in the movie \"Dreams Come True\"|\n",
      "|                                                                                     Translate English to French: this 2|\n",
      "|Translate English to French: Another tiresome bore from Anthony Minghella, who seems to thrive on these big bloated s...|\n",
      "|                                Translate English to French: This is just about one of the dumbest things I've ever seen|\n",
      "|Translate English to French: And you know why? Because they thought (or at least made horror fans think) that a bunch...|\n",
      "|Translate English to French: Having spent all of her money caring for her terminally ill spouse, recently widowed Kar...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e7e4af8-b815-4375-b851-8368309ee8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 881 µs, total: 13.5 ms\n",
      "Wall time: 6.57 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b0aefb0-a96b-4791-a23c-1ce9b24eb20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 ms, sys: 4.94 ms, total: 20.7 ms\n",
      "Wall time: 5.95 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1214b75b-a373-4579-b4c6-0cb8627da776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 ms, sys: 1.27 ms, total: 22.2 ms\n",
      "Wall time: 5.94 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9dbd21f-9e37-4221-b765-80ba8c80b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                               Translate English to French: |                                                           :|\n",
      "|Translate English to French: I found myself getting incre...|  Je me suis rendu de plus en plus en colère à mesure que ce|\n",
      "|Translate English to French: The comparisons between the ...|Les comparaisons entre la version de 1995 et cette versio...|\n",
      "|Translate English to French: Doesn't anyone bother to che...|          Ne s'agit-il pas de vérifier où viennent ces boues|\n",
      "|Translate English to French: Don't get me wrong, I love t...|Ne m'oubliez pas, je m'aime la série de télévision de League|\n",
      "|Translate English to French: Made it through the first ha...|                     l’issue de la première demi-heure, il a|\n",
      "|Translate English to French: This movie seems a little cl...|      Ce film semble un peu cloné autour des bords, comme il|\n",
      "|          Translate English to French: Oh but this is woeful|                           l'heure actuelle, il n'y a pas de|\n",
      "|Translate English to French: Terry Cunningham directs thi...|    Terry Cunningham dirige cette originale du réseau Sci-Fi|\n",
      "|Translate English to French: First the easy part: this mo...|Premièrement, la partie facile : ce film est pretentious ...|\n",
      "|Translate English to French: Tycus is one of the worst fi...|                Tycus est l'un des pires films directs à des|\n",
      "|                        Translate English to French: Edge Vs|                                                     Edge Vs|\n",
      "|Translate English to French: If you like bad movies (and ...|Si vous aimez des films mauvais (et vous devez regarder c...|\n",
      "|Translate English to French: Ed Gein, one of the most fam...|                  Ed Gein, l'un des assassinats en série les|\n",
      "|Translate English to French: I was Stan in the movie \"Dre...|                  Je l'étais dans le film \"Dreams Come True\"|\n",
      "|                         Translate English to French: this 2|                                                     Cette 2|\n",
      "|Translate English to French: Another tiresome bore from A...|                       Un autre ennui abusif d'Antonio Mingh|\n",
      "|Translate English to French: This is just about one of th...|                 Voilà l'un des plus dommageables que je n'a|\n",
      "|Translate English to French: And you know why? Because th...| Et vous savez pourquoi? Parce qu'ils pensaient (ou du moins|\n",
      "|Translate English to French: Having spent all of her mone...|Après avoir dépensé toute son argent pour s'occuper de so...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e3113-64dd-482a-9233-6607b3f63c1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "425d3b28-7705-45ba-8a18-ad34fc895219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dec80ca-7a7c-46a9-97c0-7afb1572f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1ecd4-e218-4553-821d-675ed7058113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
